{
  "dataset_revision": "3d96e36e10a88d5b7a3f617cf8362d997504494b",
  "task_name": "KorSarcasmClassification",
  "mteb_version": "1.34.4",
  "scores": {
    "train": [
      {
        "accuracy": 0.5396,
        "f1": 0.532777,
        "f1_weighted": 0.532804,
        "ap": 0.521803,
        "ap_weighted": 0.521803,
        "scores_per_experiment": [
          {
            "accuracy": 0.589355,
            "f1": 0.5874,
            "f1_weighted": 0.587455,
            "ap": 0.552864,
            "ap_weighted": 0.552864
          },
          {
            "accuracy": 0.511719,
            "f1": 0.510896,
            "f1_weighted": 0.510935,
            "ap": 0.504991,
            "ap_weighted": 0.504991
          },
          {
            "accuracy": 0.503418,
            "f1": 0.487494,
            "f1_weighted": 0.48767,
            "ap": 0.500576,
            "ap_weighted": 0.500576
          },
          {
            "accuracy": 0.496582,
            "f1": 0.494116,
            "f1_weighted": 0.494185,
            "ap": 0.497262,
            "ap_weighted": 0.497262
          },
          {
            "accuracy": 0.574219,
            "f1": 0.561106,
            "f1_weighted": 0.560957,
            "ap": 0.540436,
            "ap_weighted": 0.540436
          },
          {
            "accuracy": 0.527832,
            "f1": 0.526232,
            "f1_weighted": 0.526286,
            "ap": 0.513753,
            "ap_weighted": 0.513753
          },
          {
            "accuracy": 0.611328,
            "f1": 0.610764,
            "f1_weighted": 0.610735,
            "ap": 0.56626,
            "ap_weighted": 0.56626
          },
          {
            "accuracy": 0.549316,
            "f1": 0.53782,
            "f1_weighted": 0.537963,
            "ap": 0.527034,
            "ap_weighted": 0.527034
          },
          {
            "accuracy": 0.527832,
            "f1": 0.511452,
            "f1_weighted": 0.511277,
            "ap": 0.513701,
            "ap_weighted": 0.513701
          },
          {
            "accuracy": 0.504395,
            "f1": 0.500493,
            "f1_weighted": 0.500579,
            "ap": 0.501157,
            "ap_weighted": 0.501157
          }
        ],
        "main_score": 0.5396,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ]
      }
    ]
  },
  "evaluation_time": 0.44245004653930664,
  "kg_co2_emissions": null
}