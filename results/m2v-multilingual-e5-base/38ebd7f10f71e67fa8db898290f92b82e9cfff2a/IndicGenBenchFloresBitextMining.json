{
  "dataset_revision": "f8650438298df086750ff4973661bb58a201a5ee",
  "task_name": "IndicGenBenchFloresBitextMining",
  "mteb_version": "1.34.4",
  "scores": {
    "validation": [
      {
        "precision": 0.004866,
        "recall": 0.009027,
        "f1": 0.005217,
        "accuracy": 0.009027,
        "main_score": 0.005217,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005611,
        "recall": 0.008024,
        "f1": 0.005864,
        "accuracy": 0.008024,
        "main_score": 0.005864,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002006,
        "f1": 0.001005,
        "accuracy": 0.002006,
        "main_score": 0.001005,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004012,
        "recall": 0.005015,
        "f1": 0.004346,
        "accuracy": 0.005015,
        "main_score": 0.004346,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.019114,
        "recall": 0.031093,
        "f1": 0.02132,
        "accuracy": 0.031093,
        "main_score": 0.02132,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00865,
        "recall": 0.018054,
        "f1": 0.010041,
        "accuracy": 0.018054,
        "main_score": 0.010041,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001007,
        "recall": 0.003009,
        "f1": 0.001011,
        "accuracy": 0.003009,
        "main_score": 0.001011,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00301,
        "recall": 0.004012,
        "f1": 0.003011,
        "accuracy": 0.004012,
        "main_score": 0.003011,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001007,
        "recall": 0.003009,
        "f1": 0.001012,
        "accuracy": 0.003009,
        "main_score": 0.001012,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.01563,
        "recall": 0.023069,
        "f1": 0.017506,
        "accuracy": 0.023069,
        "main_score": 0.017506,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005821,
        "recall": 0.01003,
        "f1": 0.006646,
        "accuracy": 0.01003,
        "main_score": 0.006646,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003218,
        "recall": 0.006018,
        "f1": 0.003376,
        "accuracy": 0.006018,
        "main_score": 0.003376,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004515,
        "recall": 0.006018,
        "f1": 0.004683,
        "accuracy": 0.006018,
        "main_score": 0.004683,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.02313,
        "recall": 0.031093,
        "f1": 0.024918,
        "accuracy": 0.031093,
        "main_score": 0.024918,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007927,
        "recall": 0.011033,
        "f1": 0.008324,
        "accuracy": 0.011033,
        "main_score": 0.008324,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.034029,
        "recall": 0.055165,
        "f1": 0.039207,
        "accuracy": 0.055165,
        "main_score": 0.039207,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026342,
        "recall": 0.051153,
        "f1": 0.031268,
        "accuracy": 0.051153,
        "main_score": 0.031268,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000269,
        "recall": 0.003009,
        "f1": 0.000437,
        "accuracy": 0.003009,
        "main_score": 0.000437,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002007,
        "recall": 0.003009,
        "f1": 0.002008,
        "accuracy": 0.003009,
        "main_score": 0.002008,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.023143,
        "recall": 0.035105,
        "f1": 0.025271,
        "accuracy": 0.035105,
        "main_score": 0.025271,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013843,
        "recall": 0.02006,
        "f1": 0.015045,
        "accuracy": 0.02006,
        "main_score": 0.015045,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.017057,
        "recall": 0.027081,
        "f1": 0.018589,
        "accuracy": 0.027081,
        "main_score": 0.018589,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005774,
        "recall": 0.013039,
        "f1": 0.006775,
        "accuracy": 0.013039,
        "main_score": 0.006775,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.003083,
        "recall": 0.005015,
        "f1": 0.003147,
        "accuracy": 0.005015,
        "main_score": 0.003147,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00204,
        "recall": 0.005015,
        "f1": 0.00251,
        "accuracy": 0.005015,
        "main_score": 0.00251,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010826,
        "recall": 0.019057,
        "f1": 0.012111,
        "accuracy": 0.019057,
        "main_score": 0.012111,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003843,
        "recall": 0.01003,
        "f1": 0.0047,
        "accuracy": 0.01003,
        "main_score": 0.0047,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.02111,
        "recall": 0.031093,
        "f1": 0.022998,
        "accuracy": 0.031093,
        "main_score": 0.022998,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.025964,
        "recall": 0.043129,
        "f1": 0.029191,
        "accuracy": 0.043129,
        "main_score": 0.029191,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.010764,
        "recall": 0.021063,
        "f1": 0.012399,
        "accuracy": 0.021063,
        "main_score": 0.012399,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010118,
        "recall": 0.017051,
        "f1": 0.01071,
        "accuracy": 0.017051,
        "main_score": 0.01071,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.012132,
        "recall": 0.02006,
        "f1": 0.013446,
        "accuracy": 0.02006,
        "main_score": 0.013446,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005302,
        "recall": 0.01003,
        "f1": 0.005978,
        "accuracy": 0.01003,
        "main_score": 0.005978,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.02019,
        "recall": 0.033099,
        "f1": 0.0232,
        "accuracy": 0.033099,
        "main_score": 0.0232,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008015,
        "recall": 0.02006,
        "f1": 0.010032,
        "accuracy": 0.02006,
        "main_score": 0.010032,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.006355,
        "recall": 0.014042,
        "f1": 0.007621,
        "accuracy": 0.014042,
        "main_score": 0.007621,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006053,
        "recall": 0.008024,
        "f1": 0.006419,
        "accuracy": 0.008024,
        "main_score": 0.006419,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.006232,
        "recall": 0.01003,
        "f1": 0.006413,
        "accuracy": 0.01003,
        "main_score": 0.006413,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00272,
        "recall": 0.007021,
        "f1": 0.003049,
        "accuracy": 0.007021,
        "main_score": 0.003049,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.01398,
        "recall": 0.023069,
        "f1": 0.015652,
        "accuracy": 0.023069,
        "main_score": 0.015652,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005726,
        "recall": 0.012036,
        "f1": 0.006687,
        "accuracy": 0.012036,
        "main_score": 0.006687,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.029258,
        "recall": 0.036108,
        "f1": 0.030825,
        "accuracy": 0.036108,
        "main_score": 0.030825,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011962,
        "recall": 0.023069,
        "f1": 0.013434,
        "accuracy": 0.023069,
        "main_score": 0.013434,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.015752,
        "recall": 0.029087,
        "f1": 0.017973,
        "accuracy": 0.029087,
        "main_score": 0.017973,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006977,
        "recall": 0.012036,
        "f1": 0.007857,
        "accuracy": 0.012036,
        "main_score": 0.007857,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.02322,
        "recall": 0.036108,
        "f1": 0.025608,
        "accuracy": 0.036108,
        "main_score": 0.025608,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010674,
        "recall": 0.023069,
        "f1": 0.012825,
        "accuracy": 0.023069,
        "main_score": 0.012825,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.025123,
        "recall": 0.033099,
        "f1": 0.027139,
        "accuracy": 0.033099,
        "main_score": 0.027139,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012394,
        "recall": 0.022066,
        "f1": 0.013581,
        "accuracy": 0.022066,
        "main_score": 0.013581,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.003024,
        "recall": 0.005015,
        "f1": 0.003038,
        "accuracy": 0.005015,
        "main_score": 0.003038,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002509,
        "recall": 0.005015,
        "f1": 0.002796,
        "accuracy": 0.005015,
        "main_score": 0.002796,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.024299,
        "recall": 0.031093,
        "f1": 0.025847,
        "accuracy": 0.031093,
        "main_score": 0.025847,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009629,
        "recall": 0.016048,
        "f1": 0.010726,
        "accuracy": 0.016048,
        "main_score": 0.010726,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.022456,
        "recall": 0.034102,
        "f1": 0.024806,
        "accuracy": 0.034102,
        "main_score": 0.024806,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009188,
        "recall": 0.016048,
        "f1": 0.010255,
        "accuracy": 0.016048,
        "main_score": 0.010255,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.001003,
        "f1": 2e-06,
        "accuracy": 0.001003,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00262,
        "recall": 0.005015,
        "f1": 0.002877,
        "accuracy": 0.005015,
        "main_score": 0.002877,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ],
    "test": [
      {
        "precision": 0.00297,
        "recall": 0.004941,
        "f1": 0.002975,
        "accuracy": 0.004941,
        "main_score": 0.002975,
        "hf_subset": "ben-eng",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.001976,
        "f1": 0.000681,
        "accuracy": 0.001976,
        "main_score": 0.000681,
        "hf_subset": "eng-ben",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "guj-eng",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001236,
        "recall": 0.002964,
        "f1": 0.001385,
        "accuracy": 0.002964,
        "main_score": 0.001385,
        "hf_subset": "eng-guj",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.02967,
        "recall": 0.044466,
        "f1": 0.033014,
        "accuracy": 0.044466,
        "main_score": 0.033014,
        "hf_subset": "hin-eng",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008864,
        "recall": 0.019763,
        "f1": 0.010321,
        "accuracy": 0.019763,
        "main_score": 0.010321,
        "hf_subset": "eng-hin",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "kan-eng",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001199,
        "recall": 0.004941,
        "f1": 0.001371,
        "accuracy": 0.004941,
        "main_score": 0.001371,
        "hf_subset": "eng-kan",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000199,
        "recall": 0.001976,
        "f1": 0.000331,
        "accuracy": 0.001976,
        "main_score": 0.000331,
        "hf_subset": "mal-eng",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000247,
        "recall": 0.000988,
        "f1": 0.000395,
        "accuracy": 0.000988,
        "main_score": 0.000395,
        "hf_subset": "eng-mal",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.013509,
        "recall": 0.023715,
        "f1": 0.015508,
        "accuracy": 0.023715,
        "main_score": 0.015508,
        "hf_subset": "mar-eng",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005392,
        "recall": 0.01087,
        "f1": 0.006063,
        "accuracy": 0.01087,
        "main_score": 0.006063,
        "hf_subset": "eng-mar",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.001991,
        "recall": 0.003953,
        "f1": 0.002006,
        "accuracy": 0.003953,
        "main_score": 0.002006,
        "hf_subset": "tam-eng",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00149,
        "recall": 0.003953,
        "f1": 0.001662,
        "accuracy": 0.003953,
        "main_score": 0.001662,
        "hf_subset": "eng-tam",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.01596,
        "recall": 0.02668,
        "f1": 0.01846,
        "accuracy": 0.02668,
        "main_score": 0.01846,
        "hf_subset": "tel-eng",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006064,
        "recall": 0.01581,
        "f1": 0.00751,
        "accuracy": 0.01581,
        "main_score": 0.00751,
        "hf_subset": "eng-tel",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.035362,
        "recall": 0.050395,
        "f1": 0.038824,
        "accuracy": 0.050395,
        "main_score": 0.038824,
        "hf_subset": "urd-eng",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024381,
        "recall": 0.043478,
        "f1": 0.028545,
        "accuracy": 0.043478,
        "main_score": 0.028545,
        "hf_subset": "eng-urd",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000999,
        "recall": 0.002964,
        "f1": 0.00101,
        "accuracy": 0.002964,
        "main_score": 0.00101,
        "hf_subset": "asm-eng",
        "languages": [
          "asm-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "eng-asm",
        "languages": [
          "eng-Latn",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.026506,
        "recall": 0.037549,
        "f1": 0.02903,
        "accuracy": 0.037549,
        "main_score": 0.02903,
        "hf_subset": "bho-eng",
        "languages": [
          "bho-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00732,
        "recall": 0.017787,
        "f1": 0.009296,
        "accuracy": 0.017787,
        "main_score": 0.009296,
        "hf_subset": "eng-bho",
        "languages": [
          "eng-Latn",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.030044,
        "recall": 0.041502,
        "f1": 0.032219,
        "accuracy": 0.041502,
        "main_score": 0.032219,
        "hf_subset": "nep-eng",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010388,
        "recall": 0.017787,
        "f1": 0.011533,
        "accuracy": 0.017787,
        "main_score": 0.011533,
        "hf_subset": "eng-nep",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.0001,
        "recall": 0.001976,
        "f1": 0.000182,
        "accuracy": 0.001976,
        "main_score": 0.000182,
        "hf_subset": "ory-eng",
        "languages": [
          "ory-Orya",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002718,
        "recall": 0.004941,
        "f1": 0.003032,
        "accuracy": 0.004941,
        "main_score": 0.003032,
        "hf_subset": "eng-ory",
        "languages": [
          "eng-Latn",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.018509,
        "recall": 0.028656,
        "f1": 0.020534,
        "accuracy": 0.028656,
        "main_score": 0.020534,
        "hf_subset": "pan-eng",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00498,
        "recall": 0.012846,
        "f1": 0.006399,
        "accuracy": 0.012846,
        "main_score": 0.006399,
        "hf_subset": "eng-pan",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.03443,
        "recall": 0.043478,
        "f1": 0.036761,
        "accuracy": 0.043478,
        "main_score": 0.036761,
        "hf_subset": "pus-eng",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.022209,
        "recall": 0.043478,
        "f1": 0.02641,
        "accuracy": 0.043478,
        "main_score": 0.02641,
        "hf_subset": "eng-pus",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.010364,
        "recall": 0.021739,
        "f1": 0.012263,
        "accuracy": 0.021739,
        "main_score": 0.012263,
        "hf_subset": "san-eng",
        "languages": [
          "san-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004069,
        "recall": 0.011858,
        "f1": 0.004995,
        "accuracy": 0.011858,
        "main_score": 0.004995,
        "hf_subset": "eng-san",
        "languages": [
          "eng-Latn",
          "san-Deva"
        ]
      },
      {
        "precision": 0.013743,
        "recall": 0.024704,
        "f1": 0.015537,
        "accuracy": 0.024704,
        "main_score": 0.015537,
        "hf_subset": "awa-eng",
        "languages": [
          "awa-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0085,
        "recall": 0.014822,
        "f1": 0.009703,
        "accuracy": 0.014822,
        "main_score": 0.009703,
        "hf_subset": "eng-awa",
        "languages": [
          "eng-Latn",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.029153,
        "recall": 0.039526,
        "f1": 0.031122,
        "accuracy": 0.039526,
        "main_score": 0.031122,
        "hf_subset": "bgc-eng",
        "languages": [
          "bgc-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00963,
        "recall": 0.01581,
        "f1": 0.010502,
        "accuracy": 0.01581,
        "main_score": 0.010502,
        "hf_subset": "eng-bgc",
        "languages": [
          "eng-Latn",
          "bgc-Deva"
        ]
      },
      {
        "precision": 0.008009,
        "recall": 0.011858,
        "f1": 0.008837,
        "accuracy": 0.011858,
        "main_score": 0.008837,
        "hf_subset": "bod-eng",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004374,
        "recall": 0.011858,
        "f1": 0.005382,
        "accuracy": 0.011858,
        "main_score": 0.005382,
        "hf_subset": "eng-bod",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.007712,
        "recall": 0.013834,
        "f1": 0.00822,
        "accuracy": 0.013834,
        "main_score": 0.00822,
        "hf_subset": "boy-eng",
        "languages": [
          "boy-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002801,
        "recall": 0.005929,
        "f1": 0.003462,
        "accuracy": 0.005929,
        "main_score": 0.003462,
        "hf_subset": "eng-boy",
        "languages": [
          "eng-Latn",
          "boy-Deva"
        ]
      },
      {
        "precision": 0.011348,
        "recall": 0.017787,
        "f1": 0.012746,
        "accuracy": 0.017787,
        "main_score": 0.012746,
        "hf_subset": "gbm-eng",
        "languages": [
          "gbm-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003504,
        "recall": 0.01087,
        "f1": 0.004751,
        "accuracy": 0.01087,
        "main_score": 0.004751,
        "hf_subset": "eng-gbm",
        "languages": [
          "eng-Latn",
          "gbm-Deva"
        ]
      },
      {
        "precision": 0.02138,
        "recall": 0.032609,
        "f1": 0.023763,
        "accuracy": 0.032609,
        "main_score": 0.023763,
        "hf_subset": "gom-eng",
        "languages": [
          "gom-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004654,
        "recall": 0.011858,
        "f1": 0.005486,
        "accuracy": 0.011858,
        "main_score": 0.005486,
        "hf_subset": "eng-gom",
        "languages": [
          "eng-Latn",
          "gom-Deva"
        ]
      },
      {
        "precision": 0.0253,
        "recall": 0.034585,
        "f1": 0.027251,
        "accuracy": 0.034585,
        "main_score": 0.027251,
        "hf_subset": "hne-eng",
        "languages": [
          "hne-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004103,
        "recall": 0.01087,
        "f1": 0.005069,
        "accuracy": 0.01087,
        "main_score": 0.005069,
        "hf_subset": "eng-hne",
        "languages": [
          "eng-Latn",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.025271,
        "recall": 0.036561,
        "f1": 0.027446,
        "accuracy": 0.036561,
        "main_score": 0.027446,
        "hf_subset": "raj-eng",
        "languages": [
          "raj-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011524,
        "recall": 0.022727,
        "f1": 0.013292,
        "accuracy": 0.022727,
        "main_score": 0.013292,
        "hf_subset": "eng-raj",
        "languages": [
          "eng-Latn",
          "raj-Deva"
        ]
      },
      {
        "precision": 0.016837,
        "recall": 0.023715,
        "f1": 0.017795,
        "accuracy": 0.023715,
        "main_score": 0.017795,
        "hf_subset": "mai-eng",
        "languages": [
          "mai-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00795,
        "recall": 0.013834,
        "f1": 0.009099,
        "accuracy": 0.013834,
        "main_score": 0.009099,
        "hf_subset": "eng-mai",
        "languages": [
          "eng-Latn",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.000994,
        "recall": 0.002964,
        "f1": 0.000999,
        "accuracy": 0.002964,
        "main_score": 0.000999,
        "hf_subset": "mni-eng",
        "languages": [
          "mni-Mtei",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00066,
        "recall": 0.002964,
        "f1": 0.00099,
        "accuracy": 0.002964,
        "main_score": 0.00099,
        "hf_subset": "eng-mni",
        "languages": [
          "eng-Latn",
          "mni-Mtei"
        ]
      },
      {
        "precision": 0.026342,
        "recall": 0.033597,
        "f1": 0.02788,
        "accuracy": 0.033597,
        "main_score": 0.02788,
        "hf_subset": "mup-eng",
        "languages": [
          "mup-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008568,
        "recall": 0.019763,
        "f1": 0.010382,
        "accuracy": 0.019763,
        "main_score": 0.010382,
        "hf_subset": "eng-mup",
        "languages": [
          "eng-Latn",
          "mup-Deva"
        ]
      },
      {
        "precision": 0.02685,
        "recall": 0.040514,
        "f1": 0.029753,
        "accuracy": 0.040514,
        "main_score": 0.029753,
        "hf_subset": "mwr-eng",
        "languages": [
          "mwr-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01507,
        "recall": 0.02668,
        "f1": 0.016638,
        "accuracy": 0.02668,
        "main_score": 0.016638,
        "hf_subset": "eng-mwr",
        "languages": [
          "eng-Latn",
          "mwr-Deva"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "sat-eng",
        "languages": [
          "sat-Olck",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001976,
        "recall": 0.001976,
        "f1": 0.001976,
        "accuracy": 0.001976,
        "main_score": 0.001976,
        "hf_subset": "eng-sat",
        "languages": [
          "eng-Latn",
          "sat-Olck"
        ]
      }
    ]
  },
  "evaluation_time": 25.245033025741577,
  "kg_co2_emissions": null
}