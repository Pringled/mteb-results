{
  "dataset_revision": "ed9a4403ed4adbfaf4aab56d5b2709e9f6c3ba33",
  "task_name": "NTREXBitextMining",
  "mteb_version": "1.34.4",
  "scores": {
    "test": [
      {
        "precision": 0.053857,
        "recall": 0.086129,
        "f1": 0.061643,
        "accuracy": 0.086129,
        "main_score": 0.061643,
        "hf_subset": "afr_Latn-dan_Latn",
        "languages": [
          "afr-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.050548,
        "recall": 0.076114,
        "f1": 0.056418,
        "accuracy": 0.076114,
        "main_score": 0.056418,
        "hf_subset": "afr_Latn-deu_Latn",
        "languages": [
          "afr-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.065998,
        "recall": 0.098147,
        "f1": 0.073939,
        "accuracy": 0.098147,
        "main_score": 0.073939,
        "hf_subset": "afr_Latn-eng_Latn",
        "languages": [
          "afr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027284,
        "recall": 0.050075,
        "f1": 0.032022,
        "accuracy": 0.050075,
        "main_score": 0.032022,
        "hf_subset": "afr_Latn-fao_Latn",
        "languages": [
          "afr-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.012778,
        "recall": 0.028543,
        "f1": 0.01564,
        "accuracy": 0.028543,
        "main_score": 0.01564,
        "hf_subset": "afr_Latn-isl_Latn",
        "languages": [
          "afr-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.04039,
        "recall": 0.063595,
        "f1": 0.045722,
        "accuracy": 0.063595,
        "main_score": 0.045722,
        "hf_subset": "afr_Latn-ltz_Latn",
        "languages": [
          "afr-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.089655,
        "recall": 0.126189,
        "f1": 0.098694,
        "accuracy": 0.126189,
        "main_score": 0.098694,
        "hf_subset": "afr_Latn-nld_Latn",
        "languages": [
          "afr-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.043947,
        "recall": 0.070606,
        "f1": 0.050415,
        "accuracy": 0.070606,
        "main_score": 0.050415,
        "hf_subset": "afr_Latn-nno_Latn",
        "languages": [
          "afr-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.052843,
        "recall": 0.083625,
        "f1": 0.060077,
        "accuracy": 0.083625,
        "main_score": 0.060077,
        "hf_subset": "afr_Latn-nob_Latn",
        "languages": [
          "afr-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.051458,
        "recall": 0.082624,
        "f1": 0.058835,
        "accuracy": 0.082624,
        "main_score": 0.058835,
        "hf_subset": "afr_Latn-swe_Latn",
        "languages": [
          "afr-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001122,
        "recall": 0.003505,
        "f1": 0.001219,
        "accuracy": 0.003505,
        "main_score": 0.001219,
        "hf_subset": "amh_Ethi-eng_Latn",
        "languages": [
          "amh-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "amh_Ethi-hau_Latn",
        "languages": [
          "amh-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001502,
        "f1": 0.000504,
        "accuracy": 0.001502,
        "main_score": 0.000504,
        "hf_subset": "amh_Ethi-ibo_Latn",
        "languages": [
          "amh-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.000574,
        "recall": 0.002003,
        "f1": 0.000629,
        "accuracy": 0.002003,
        "main_score": 0.000629,
        "hf_subset": "amh_Ethi-nso_Latn",
        "languages": [
          "amh-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "amh_Ethi-orm_Ethi",
        "languages": [
          "amh-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "amh_Ethi-som_Latn",
        "languages": [
          "amh-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.001006,
        "recall": 0.002504,
        "f1": 0.00101,
        "accuracy": 0.002504,
        "main_score": 0.00101,
        "hf_subset": "amh_Ethi-ssw_Latn",
        "languages": [
          "amh-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.000626,
        "recall": 0.001002,
        "f1": 0.000701,
        "accuracy": 0.001002,
        "main_score": 0.000701,
        "hf_subset": "amh_Ethi-swa_Latn",
        "languages": [
          "amh-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.027864,
        "recall": 0.04657,
        "f1": 0.03108,
        "accuracy": 0.04657,
        "main_score": 0.03108,
        "hf_subset": "amh_Ethi-tir_Ethi",
        "languages": [
          "amh-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "amh_Ethi-tsn_Latn",
        "languages": [
          "amh-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "amh_Ethi-wol_Latn",
        "languages": [
          "amh-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "amh_Ethi-xho_Latn",
        "languages": [
          "amh-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "amh_Ethi-yor_Latn",
        "languages": [
          "amh-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.000558,
        "recall": 0.002003,
        "f1": 0.000603,
        "accuracy": 0.002003,
        "main_score": 0.000603,
        "hf_subset": "amh_Ethi-zul_Latn",
        "languages": [
          "amh-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.003356,
        "recall": 0.00651,
        "f1": 0.003976,
        "accuracy": 0.00651,
        "main_score": 0.003976,
        "hf_subset": "arb_Arab-ben_Beng",
        "languages": [
          "arb-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000423,
        "recall": 0.001502,
        "f1": 0.000596,
        "accuracy": 0.001502,
        "main_score": 0.000596,
        "hf_subset": "arb_Arab-ckb_Arab",
        "languages": [
          "arb-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.0103,
        "recall": 0.015023,
        "f1": 0.011361,
        "accuracy": 0.015023,
        "main_score": 0.011361,
        "hf_subset": "arb_Arab-deu_Latn",
        "languages": [
          "arb-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.005317,
        "recall": 0.011517,
        "f1": 0.006483,
        "accuracy": 0.011517,
        "main_score": 0.006483,
        "hf_subset": "arb_Arab-ell_Grek",
        "languages": [
          "arb-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.017109,
        "recall": 0.028042,
        "f1": 0.019379,
        "accuracy": 0.028042,
        "main_score": 0.019379,
        "hf_subset": "arb_Arab-eng_Latn",
        "languages": [
          "arb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013322,
        "recall": 0.019529,
        "f1": 0.014554,
        "accuracy": 0.019529,
        "main_score": 0.014554,
        "hf_subset": "arb_Arab-fas_Arab",
        "languages": [
          "arb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.008599,
        "recall": 0.015023,
        "f1": 0.010144,
        "accuracy": 0.015023,
        "main_score": 0.010144,
        "hf_subset": "arb_Arab-fin_Latn",
        "languages": [
          "arb-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.008577,
        "recall": 0.015023,
        "f1": 0.009823,
        "accuracy": 0.015023,
        "main_score": 0.009823,
        "hf_subset": "arb_Arab-fra_Latn",
        "languages": [
          "arb-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.008728,
        "recall": 0.01302,
        "f1": 0.009487,
        "accuracy": 0.01302,
        "main_score": 0.009487,
        "hf_subset": "arb_Arab-heb_Hebr",
        "languages": [
          "arb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.006107,
        "recall": 0.011517,
        "f1": 0.007129,
        "accuracy": 0.011517,
        "main_score": 0.007129,
        "hf_subset": "arb_Arab-hin_Deva",
        "languages": [
          "arb-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012521,
        "recall": 0.016024,
        "f1": 0.013322,
        "accuracy": 0.016024,
        "main_score": 0.013322,
        "hf_subset": "arb_Arab-hun_Latn",
        "languages": [
          "arb-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.015586,
        "recall": 0.024036,
        "f1": 0.017472,
        "accuracy": 0.024036,
        "main_score": 0.017472,
        "hf_subset": "arb_Arab-ind_Latn",
        "languages": [
          "arb-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.003958,
        "recall": 0.008012,
        "f1": 0.004695,
        "accuracy": 0.008012,
        "main_score": 0.004695,
        "hf_subset": "arb_Arab-jpn_Jpan",
        "languages": [
          "arb-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.003934,
        "recall": 0.009014,
        "f1": 0.004898,
        "accuracy": 0.009014,
        "main_score": 0.004898,
        "hf_subset": "arb_Arab-kmr_Latn",
        "languages": [
          "arb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.005281,
        "recall": 0.009014,
        "f1": 0.006095,
        "accuracy": 0.009014,
        "main_score": 0.006095,
        "hf_subset": "arb_Arab-kor_Hang",
        "languages": [
          "arb-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.012087,
        "recall": 0.017026,
        "f1": 0.01307,
        "accuracy": 0.017026,
        "main_score": 0.01307,
        "hf_subset": "arb_Arab-lit_Latn",
        "languages": [
          "arb-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.089922,
        "recall": 0.129695,
        "f1": 0.0995,
        "accuracy": 0.129695,
        "main_score": 0.0995,
        "hf_subset": "arb_Arab-mey_Arab",
        "languages": [
          "arb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.012061,
        "recall": 0.019529,
        "f1": 0.01369,
        "accuracy": 0.019529,
        "main_score": 0.01369,
        "hf_subset": "arb_Arab-nld_Latn",
        "languages": [
          "arb-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.006795,
        "recall": 0.012018,
        "f1": 0.007984,
        "accuracy": 0.012018,
        "main_score": 0.007984,
        "hf_subset": "arb_Arab-pol_Latn",
        "languages": [
          "arb-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.012623,
        "recall": 0.021032,
        "f1": 0.0145,
        "accuracy": 0.021032,
        "main_score": 0.0145,
        "hf_subset": "arb_Arab-por_Latn",
        "languages": [
          "arb-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.017489,
        "recall": 0.025038,
        "f1": 0.019099,
        "accuracy": 0.025038,
        "main_score": 0.019099,
        "hf_subset": "arb_Arab-prs_Arab",
        "languages": [
          "arb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.006405,
        "recall": 0.01302,
        "f1": 0.007668,
        "accuracy": 0.01302,
        "main_score": 0.007668,
        "hf_subset": "arb_Arab-pus_Arab",
        "languages": [
          "arb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.008929,
        "recall": 0.014522,
        "f1": 0.010065,
        "accuracy": 0.014522,
        "main_score": 0.010065,
        "hf_subset": "arb_Arab-rus_Cyrl",
        "languages": [
          "arb-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.024347,
        "recall": 0.042063,
        "f1": 0.028242,
        "accuracy": 0.042063,
        "main_score": 0.028242,
        "hf_subset": "arb_Arab-shi_Arab",
        "languages": [
          "arb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.013989,
        "recall": 0.019029,
        "f1": 0.015165,
        "accuracy": 0.019029,
        "main_score": 0.015165,
        "hf_subset": "arb_Arab-spa_Latn",
        "languages": [
          "arb-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.01313,
        "recall": 0.021032,
        "f1": 0.014726,
        "accuracy": 0.021032,
        "main_score": 0.014726,
        "hf_subset": "arb_Arab-swa_Latn",
        "languages": [
          "arb-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.010169,
        "recall": 0.016525,
        "f1": 0.011571,
        "accuracy": 0.016525,
        "main_score": 0.011571,
        "hf_subset": "arb_Arab-swe_Latn",
        "languages": [
          "arb-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002938,
        "recall": 0.004507,
        "f1": 0.003314,
        "accuracy": 0.004507,
        "main_score": 0.003314,
        "hf_subset": "arb_Arab-tam_Taml",
        "languages": [
          "arb-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00445,
        "recall": 0.007011,
        "f1": 0.004749,
        "accuracy": 0.007011,
        "main_score": 0.004749,
        "hf_subset": "arb_Arab-tgk_Cyrl",
        "languages": [
          "arb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.012975,
        "recall": 0.020531,
        "f1": 0.014913,
        "accuracy": 0.020531,
        "main_score": 0.014913,
        "hf_subset": "arb_Arab-tur_Latn",
        "languages": [
          "arb-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.011224,
        "recall": 0.016024,
        "f1": 0.012297,
        "accuracy": 0.016024,
        "main_score": 0.012297,
        "hf_subset": "arb_Arab-vie_Latn",
        "languages": [
          "arb-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.009122,
        "recall": 0.01302,
        "f1": 0.010032,
        "accuracy": 0.01302,
        "main_score": 0.010032,
        "hf_subset": "arb_Arab-zho_Hant",
        "languages": [
          "arb-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.004039,
        "recall": 0.008012,
        "f1": 0.004967,
        "accuracy": 0.008012,
        "main_score": 0.004967,
        "hf_subset": "arb_Arab-zul_Latn",
        "languages": [
          "arb-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001205,
        "recall": 0.002504,
        "f1": 0.00135,
        "accuracy": 0.002504,
        "main_score": 0.00135,
        "hf_subset": "aze_Latn-bak_Cyrl",
        "languages": [
          "aze-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.027523,
        "recall": 0.05358,
        "f1": 0.032816,
        "accuracy": 0.05358,
        "main_score": 0.032816,
        "hf_subset": "aze_Latn-eng_Latn",
        "languages": [
          "aze-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011813,
        "recall": 0.022534,
        "f1": 0.014055,
        "accuracy": 0.022534,
        "main_score": 0.014055,
        "hf_subset": "aze_Latn-kaz_Cyrl",
        "languages": [
          "aze-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.011472,
        "recall": 0.022033,
        "f1": 0.013555,
        "accuracy": 0.022033,
        "main_score": 0.013555,
        "hf_subset": "aze_Latn-kir_Cyrl",
        "languages": [
          "aze-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.003019,
        "recall": 0.007011,
        "f1": 0.003701,
        "accuracy": 0.007011,
        "main_score": 0.003701,
        "hf_subset": "aze_Latn-tat_Cyrl",
        "languages": [
          "aze-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.009228,
        "recall": 0.02003,
        "f1": 0.011097,
        "accuracy": 0.02003,
        "main_score": 0.011097,
        "hf_subset": "aze_Latn-tuk_Latn",
        "languages": [
          "aze-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.037653,
        "recall": 0.055083,
        "f1": 0.041378,
        "accuracy": 0.055083,
        "main_score": 0.041378,
        "hf_subset": "aze_Latn-tur_Latn",
        "languages": [
          "aze-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.004385,
        "recall": 0.007511,
        "f1": 0.004828,
        "accuracy": 0.007511,
        "main_score": 0.004828,
        "hf_subset": "aze_Latn-uig_Arab",
        "languages": [
          "aze-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.017999,
        "recall": 0.034552,
        "f1": 0.021243,
        "accuracy": 0.034552,
        "main_score": 0.021243,
        "hf_subset": "aze_Latn-uzb_Latn",
        "languages": [
          "aze-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.001065,
        "recall": 0.004006,
        "f1": 0.001354,
        "accuracy": 0.004006,
        "main_score": 0.001354,
        "hf_subset": "bak_Cyrl-aze_Latn",
        "languages": [
          "bak-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.001187,
        "recall": 0.003505,
        "f1": 0.001288,
        "accuracy": 0.003505,
        "main_score": 0.001288,
        "hf_subset": "bak_Cyrl-eng_Latn",
        "languages": [
          "bak-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003066,
        "recall": 0.004006,
        "f1": 0.003118,
        "accuracy": 0.004006,
        "main_score": 0.003118,
        "hf_subset": "bak_Cyrl-kaz_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.003112,
        "recall": 0.004006,
        "f1": 0.003196,
        "accuracy": 0.004006,
        "main_score": 0.003196,
        "hf_subset": "bak_Cyrl-kir_Cyrl",
        "languages": [
          "bak-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.024739,
        "recall": 0.038558,
        "f1": 0.027129,
        "accuracy": 0.038558,
        "main_score": 0.027129,
        "hf_subset": "bak_Cyrl-tat_Cyrl",
        "languages": [
          "bak-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.000254,
        "recall": 0.001002,
        "f1": 0.00034,
        "accuracy": 0.001002,
        "main_score": 0.00034,
        "hf_subset": "bak_Cyrl-tuk_Latn",
        "languages": [
          "bak-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.000501,
        "f1": 0.000501,
        "accuracy": 0.000501,
        "main_score": 0.000501,
        "hf_subset": "bak_Cyrl-tur_Latn",
        "languages": [
          "bak-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001006,
        "recall": 0.002003,
        "f1": 0.00101,
        "accuracy": 0.002003,
        "main_score": 0.00101,
        "hf_subset": "bak_Cyrl-uig_Arab",
        "languages": [
          "bak-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.000797,
        "recall": 0.002003,
        "f1": 0.000919,
        "accuracy": 0.002003,
        "main_score": 0.000919,
        "hf_subset": "bak_Cyrl-uzb_Latn",
        "languages": [
          "bak-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.006118,
        "recall": 0.012519,
        "f1": 0.007084,
        "accuracy": 0.012519,
        "main_score": 0.007084,
        "hf_subset": "bel_Cyrl-bos_Latn",
        "languages": [
          "bel-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.019558,
        "recall": 0.029044,
        "f1": 0.021505,
        "accuracy": 0.029044,
        "main_score": 0.021505,
        "hf_subset": "bel_Cyrl-bul_Cyrl",
        "languages": [
          "bel-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.008829,
        "recall": 0.016024,
        "f1": 0.010204,
        "accuracy": 0.016024,
        "main_score": 0.010204,
        "hf_subset": "bel_Cyrl-ces_Latn",
        "languages": [
          "bel-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.011191,
        "recall": 0.015023,
        "f1": 0.011799,
        "accuracy": 0.015023,
        "main_score": 0.011799,
        "hf_subset": "bel_Cyrl-eng_Latn",
        "languages": [
          "bel-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008514,
        "recall": 0.015523,
        "f1": 0.009619,
        "accuracy": 0.015523,
        "main_score": 0.009619,
        "hf_subset": "bel_Cyrl-hrv_Latn",
        "languages": [
          "bel-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.008772,
        "recall": 0.017526,
        "f1": 0.010482,
        "accuracy": 0.017526,
        "main_score": 0.010482,
        "hf_subset": "bel_Cyrl-mkd_Cyrl",
        "languages": [
          "bel-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.011132,
        "recall": 0.017526,
        "f1": 0.012421,
        "accuracy": 0.017526,
        "main_score": 0.012421,
        "hf_subset": "bel_Cyrl-pol_Latn",
        "languages": [
          "bel-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.023393,
        "recall": 0.039059,
        "f1": 0.026584,
        "accuracy": 0.039059,
        "main_score": 0.026584,
        "hf_subset": "bel_Cyrl-rus_Cyrl",
        "languages": [
          "bel-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.008393,
        "recall": 0.015023,
        "f1": 0.009396,
        "accuracy": 0.015023,
        "main_score": 0.009396,
        "hf_subset": "bel_Cyrl-slk_Latn",
        "languages": [
          "bel-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.010706,
        "recall": 0.017026,
        "f1": 0.011719,
        "accuracy": 0.017026,
        "main_score": 0.011719,
        "hf_subset": "bel_Cyrl-slv_Latn",
        "languages": [
          "bel-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.013605,
        "recall": 0.025038,
        "f1": 0.016133,
        "accuracy": 0.025038,
        "main_score": 0.016133,
        "hf_subset": "bel_Cyrl-srp_Cyrl",
        "languages": [
          "bel-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.007861,
        "recall": 0.014522,
        "f1": 0.009133,
        "accuracy": 0.014522,
        "main_score": 0.009133,
        "hf_subset": "bel_Cyrl-srp_Latn",
        "languages": [
          "bel-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.048237,
        "recall": 0.07311,
        "f1": 0.053699,
        "accuracy": 0.07311,
        "main_score": 0.053699,
        "hf_subset": "bel_Cyrl-ukr_Cyrl",
        "languages": [
          "bel-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.051486,
        "recall": 0.070606,
        "f1": 0.055927,
        "accuracy": 0.070606,
        "main_score": 0.055927,
        "hf_subset": "bem_Latn-eng_Latn",
        "languages": [
          "bem-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002635,
        "recall": 0.00651,
        "f1": 0.003163,
        "accuracy": 0.00651,
        "main_score": 0.003163,
        "hf_subset": "bem_Latn-ewe_Latn",
        "languages": [
          "bem-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.050136,
        "recall": 0.072108,
        "f1": 0.055575,
        "accuracy": 0.072108,
        "main_score": 0.055575,
        "hf_subset": "bem_Latn-fuc_Latn",
        "languages": [
          "bem-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.026616,
        "recall": 0.037056,
        "f1": 0.029031,
        "accuracy": 0.037056,
        "main_score": 0.029031,
        "hf_subset": "bem_Latn-kin_Latn",
        "languages": [
          "bem-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.01675,
        "recall": 0.024537,
        "f1": 0.018421,
        "accuracy": 0.024537,
        "main_score": 0.018421,
        "hf_subset": "bem_Latn-nde_Latn",
        "languages": [
          "bem-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.033797,
        "recall": 0.044066,
        "f1": 0.03663,
        "accuracy": 0.044066,
        "main_score": 0.03663,
        "hf_subset": "bem_Latn-nya_Latn",
        "languages": [
          "bem-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.029977,
        "recall": 0.041062,
        "f1": 0.032813,
        "accuracy": 0.041062,
        "main_score": 0.032813,
        "hf_subset": "bem_Latn-sna_Latn",
        "languages": [
          "bem-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.039536,
        "recall": 0.058588,
        "f1": 0.043844,
        "accuracy": 0.058588,
        "main_score": 0.043844,
        "hf_subset": "bem_Latn-ven_Latn",
        "languages": [
          "bem-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.002883,
        "recall": 0.007511,
        "f1": 0.003479,
        "accuracy": 0.007511,
        "main_score": 0.003479,
        "hf_subset": "ben_Beng-arb_Arab",
        "languages": [
          "ben-Beng",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002022,
        "recall": 0.004507,
        "f1": 0.002356,
        "accuracy": 0.004507,
        "main_score": 0.002356,
        "hf_subset": "ben_Beng-deu_Latn",
        "languages": [
          "ben-Beng",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.002257,
        "recall": 0.007011,
        "f1": 0.003054,
        "accuracy": 0.007011,
        "main_score": 0.003054,
        "hf_subset": "ben_Beng-div_Thaa",
        "languages": [
          "ben-Beng",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.004738,
        "recall": 0.008513,
        "f1": 0.005499,
        "accuracy": 0.008513,
        "main_score": 0.005499,
        "hf_subset": "ben_Beng-ell_Grek",
        "languages": [
          "ben-Beng",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.005706,
        "recall": 0.008513,
        "f1": 0.006017,
        "accuracy": 0.008513,
        "main_score": 0.006017,
        "hf_subset": "ben_Beng-eng_Latn",
        "languages": [
          "ben-Beng",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003223,
        "recall": 0.005008,
        "f1": 0.003517,
        "accuracy": 0.005008,
        "main_score": 0.003517,
        "hf_subset": "ben_Beng-eus_Latn",
        "languages": [
          "ben-Beng",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.003078,
        "recall": 0.004507,
        "f1": 0.00314,
        "accuracy": 0.004507,
        "main_score": 0.00314,
        "hf_subset": "ben_Beng-fas_Arab",
        "languages": [
          "ben-Beng",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.003761,
        "recall": 0.007011,
        "f1": 0.003941,
        "accuracy": 0.007011,
        "main_score": 0.003941,
        "hf_subset": "ben_Beng-fin_Latn",
        "languages": [
          "ben-Beng",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.004369,
        "recall": 0.007511,
        "f1": 0.004952,
        "accuracy": 0.007511,
        "main_score": 0.004952,
        "hf_subset": "ben_Beng-fra_Latn",
        "languages": [
          "ben-Beng",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.017456,
        "recall": 0.026039,
        "f1": 0.019371,
        "accuracy": 0.026039,
        "main_score": 0.019371,
        "hf_subset": "ben_Beng-guj_Gujr",
        "languages": [
          "ben-Beng",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.003966,
        "recall": 0.007511,
        "f1": 0.0045,
        "accuracy": 0.007511,
        "main_score": 0.0045,
        "hf_subset": "ben_Beng-heb_Hebr",
        "languages": [
          "ben-Beng",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.010518,
        "recall": 0.016525,
        "f1": 0.011398,
        "accuracy": 0.016525,
        "main_score": 0.011398,
        "hf_subset": "ben_Beng-hin_Deva",
        "languages": [
          "ben-Beng",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002238,
        "recall": 0.004507,
        "f1": 0.002574,
        "accuracy": 0.004507,
        "main_score": 0.002574,
        "hf_subset": "ben_Beng-hun_Latn",
        "languages": [
          "ben-Beng",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.002741,
        "recall": 0.005008,
        "f1": 0.002916,
        "accuracy": 0.005008,
        "main_score": 0.002916,
        "hf_subset": "ben_Beng-ind_Latn",
        "languages": [
          "ben-Beng",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.005187,
        "recall": 0.011017,
        "f1": 0.006057,
        "accuracy": 0.011017,
        "main_score": 0.006057,
        "hf_subset": "ben_Beng-jpn_Jpan",
        "languages": [
          "ben-Beng",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.019958,
        "recall": 0.031547,
        "f1": 0.021925,
        "accuracy": 0.031547,
        "main_score": 0.021925,
        "hf_subset": "ben_Beng-kan_Knda",
        "languages": [
          "ben-Beng",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.0033,
        "recall": 0.007511,
        "f1": 0.003967,
        "accuracy": 0.007511,
        "main_score": 0.003967,
        "hf_subset": "ben_Beng-kor_Hang",
        "languages": [
          "ben-Beng",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.002631,
        "recall": 0.005508,
        "f1": 0.003175,
        "accuracy": 0.005508,
        "main_score": 0.003175,
        "hf_subset": "ben_Beng-lit_Latn",
        "languages": [
          "ben-Beng",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.009433,
        "recall": 0.017526,
        "f1": 0.01113,
        "accuracy": 0.017526,
        "main_score": 0.01113,
        "hf_subset": "ben_Beng-mar_Deva",
        "languages": [
          "ben-Beng",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.007225,
        "recall": 0.011017,
        "f1": 0.008016,
        "accuracy": 0.011017,
        "main_score": 0.008016,
        "hf_subset": "ben_Beng-nep_Deva",
        "languages": [
          "ben-Beng",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.002589,
        "recall": 0.00651,
        "f1": 0.002925,
        "accuracy": 0.00651,
        "main_score": 0.002925,
        "hf_subset": "ben_Beng-nld_Latn",
        "languages": [
          "ben-Beng",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.005689,
        "recall": 0.008012,
        "f1": 0.006202,
        "accuracy": 0.008012,
        "main_score": 0.006202,
        "hf_subset": "ben_Beng-pan_Guru",
        "languages": [
          "ben-Beng",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.001922,
        "recall": 0.005508,
        "f1": 0.002409,
        "accuracy": 0.005508,
        "main_score": 0.002409,
        "hf_subset": "ben_Beng-pol_Latn",
        "languages": [
          "ben-Beng",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.003626,
        "recall": 0.009014,
        "f1": 0.004353,
        "accuracy": 0.009014,
        "main_score": 0.004353,
        "hf_subset": "ben_Beng-por_Latn",
        "languages": [
          "ben-Beng",
          "por-Latn"
        ]
      },
      {
        "precision": 0.004366,
        "recall": 0.007511,
        "f1": 0.004544,
        "accuracy": 0.007511,
        "main_score": 0.004544,
        "hf_subset": "ben_Beng-rus_Cyrl",
        "languages": [
          "ben-Beng",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.00834,
        "recall": 0.01352,
        "f1": 0.009194,
        "accuracy": 0.01352,
        "main_score": 0.009194,
        "hf_subset": "ben_Beng-sin_Sinh",
        "languages": [
          "ben-Beng",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002374,
        "recall": 0.005008,
        "f1": 0.002851,
        "accuracy": 0.005008,
        "main_score": 0.002851,
        "hf_subset": "ben_Beng-snd_Arab",
        "languages": [
          "ben-Beng",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002437,
        "recall": 0.003505,
        "f1": 0.002647,
        "accuracy": 0.003505,
        "main_score": 0.002647,
        "hf_subset": "ben_Beng-spa_Latn",
        "languages": [
          "ben-Beng",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004269,
        "recall": 0.00651,
        "f1": 0.004699,
        "accuracy": 0.00651,
        "main_score": 0.004699,
        "hf_subset": "ben_Beng-swa_Latn",
        "languages": [
          "ben-Beng",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.006411,
        "recall": 0.010516,
        "f1": 0.007057,
        "accuracy": 0.010516,
        "main_score": 0.007057,
        "hf_subset": "ben_Beng-swe_Latn",
        "languages": [
          "ben-Beng",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.008347,
        "recall": 0.017526,
        "f1": 0.009723,
        "accuracy": 0.017526,
        "main_score": 0.009723,
        "hf_subset": "ben_Beng-tam_Taml",
        "languages": [
          "ben-Beng",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004688,
        "recall": 0.009514,
        "f1": 0.005795,
        "accuracy": 0.009514,
        "main_score": 0.005795,
        "hf_subset": "ben_Beng-tel_Telu",
        "languages": [
          "ben-Beng",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007008,
        "recall": 0.011017,
        "f1": 0.007654,
        "accuracy": 0.011017,
        "main_score": 0.007654,
        "hf_subset": "ben_Beng-tur_Latn",
        "languages": [
          "ben-Beng",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.00202,
        "recall": 0.004006,
        "f1": 0.002202,
        "accuracy": 0.004006,
        "main_score": 0.002202,
        "hf_subset": "ben_Beng-urd_Arab",
        "languages": [
          "ben-Beng",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.004649,
        "recall": 0.00651,
        "f1": 0.004959,
        "accuracy": 0.00651,
        "main_score": 0.004959,
        "hf_subset": "ben_Beng-vie_Latn",
        "languages": [
          "ben-Beng",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.004363,
        "recall": 0.006009,
        "f1": 0.004528,
        "accuracy": 0.006009,
        "main_score": 0.004528,
        "hf_subset": "ben_Beng-zho_Hant",
        "languages": [
          "ben-Beng",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.002813,
        "recall": 0.004507,
        "f1": 0.003015,
        "accuracy": 0.004507,
        "main_score": 0.003015,
        "hf_subset": "ben_Beng-zul_Latn",
        "languages": [
          "ben-Beng",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002519,
        "recall": 0.004507,
        "f1": 0.002951,
        "accuracy": 0.004507,
        "main_score": 0.002951,
        "hf_subset": "bod_Tibt-dzo_Tibt",
        "languages": [
          "bod-Tibt",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.018164,
        "recall": 0.025538,
        "f1": 0.01987,
        "accuracy": 0.025538,
        "main_score": 0.01987,
        "hf_subset": "bod_Tibt-eng_Latn",
        "languages": [
          "bod-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002504,
        "f1": 0.001837,
        "accuracy": 0.002504,
        "main_score": 0.001837,
        "hf_subset": "bod_Tibt-khm_Khmr",
        "languages": [
          "bod-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.00078,
        "recall": 0.002003,
        "f1": 0.000942,
        "accuracy": 0.002003,
        "main_score": 0.000942,
        "hf_subset": "bod_Tibt-lao_Laoo",
        "languages": [
          "bod-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.002698,
        "recall": 0.005508,
        "f1": 0.003007,
        "accuracy": 0.005508,
        "main_score": 0.003007,
        "hf_subset": "bod_Tibt-mon_Mong",
        "languages": [
          "bod-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002003,
        "f1": 0.001836,
        "accuracy": 0.002003,
        "main_score": 0.001836,
        "hf_subset": "bod_Tibt-mya_Mymr",
        "languages": [
          "bod-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.007763,
        "recall": 0.012519,
        "f1": 0.008595,
        "accuracy": 0.012519,
        "main_score": 0.008595,
        "hf_subset": "bod_Tibt-tha_Thai",
        "languages": [
          "bod-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.005164,
        "recall": 0.009014,
        "f1": 0.005781,
        "accuracy": 0.009014,
        "main_score": 0.005781,
        "hf_subset": "bos_Latn-bel_Cyrl",
        "languages": [
          "bos-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.018896,
        "recall": 0.03355,
        "f1": 0.021887,
        "accuracy": 0.03355,
        "main_score": 0.021887,
        "hf_subset": "bos_Latn-bul_Cyrl",
        "languages": [
          "bos-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.043598,
        "recall": 0.070105,
        "f1": 0.05012,
        "accuracy": 0.070105,
        "main_score": 0.05012,
        "hf_subset": "bos_Latn-ces_Latn",
        "languages": [
          "bos-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.0443,
        "recall": 0.068603,
        "f1": 0.049651,
        "accuracy": 0.068603,
        "main_score": 0.049651,
        "hf_subset": "bos_Latn-eng_Latn",
        "languages": [
          "bos-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.228032,
        "recall": 0.303455,
        "f1": 0.248607,
        "accuracy": 0.303455,
        "main_score": 0.248607,
        "hf_subset": "bos_Latn-hrv_Latn",
        "languages": [
          "bos-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.017175,
        "recall": 0.031047,
        "f1": 0.019943,
        "accuracy": 0.031047,
        "main_score": 0.019943,
        "hf_subset": "bos_Latn-mkd_Cyrl",
        "languages": [
          "bos-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.0245,
        "recall": 0.042564,
        "f1": 0.028286,
        "accuracy": 0.042564,
        "main_score": 0.028286,
        "hf_subset": "bos_Latn-pol_Latn",
        "languages": [
          "bos-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.015662,
        "recall": 0.029044,
        "f1": 0.018405,
        "accuracy": 0.029044,
        "main_score": 0.018405,
        "hf_subset": "bos_Latn-rus_Cyrl",
        "languages": [
          "bos-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.031948,
        "recall": 0.059089,
        "f1": 0.037433,
        "accuracy": 0.059089,
        "main_score": 0.037433,
        "hf_subset": "bos_Latn-slk_Latn",
        "languages": [
          "bos-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.064327,
        "recall": 0.096144,
        "f1": 0.071839,
        "accuracy": 0.096144,
        "main_score": 0.071839,
        "hf_subset": "bos_Latn-slv_Latn",
        "languages": [
          "bos-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.009068,
        "recall": 0.020531,
        "f1": 0.011028,
        "accuracy": 0.020531,
        "main_score": 0.011028,
        "hf_subset": "bos_Latn-srp_Cyrl",
        "languages": [
          "bos-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.255829,
        "recall": 0.335003,
        "f1": 0.277651,
        "accuracy": 0.335003,
        "main_score": 0.277651,
        "hf_subset": "bos_Latn-srp_Latn",
        "languages": [
          "bos-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.013468,
        "recall": 0.022534,
        "f1": 0.015195,
        "accuracy": 0.022534,
        "main_score": 0.015195,
        "hf_subset": "bos_Latn-ukr_Cyrl",
        "languages": [
          "bos-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.015074,
        "recall": 0.024537,
        "f1": 0.016999,
        "accuracy": 0.024537,
        "main_score": 0.016999,
        "hf_subset": "bul_Cyrl-bel_Cyrl",
        "languages": [
          "bul-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.015343,
        "recall": 0.028042,
        "f1": 0.01802,
        "accuracy": 0.028042,
        "main_score": 0.01802,
        "hf_subset": "bul_Cyrl-bos_Latn",
        "languages": [
          "bul-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.022188,
        "recall": 0.041562,
        "f1": 0.026403,
        "accuracy": 0.041562,
        "main_score": 0.026403,
        "hf_subset": "bul_Cyrl-ces_Latn",
        "languages": [
          "bul-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.026885,
        "recall": 0.04657,
        "f1": 0.031018,
        "accuracy": 0.04657,
        "main_score": 0.031018,
        "hf_subset": "bul_Cyrl-eng_Latn",
        "languages": [
          "bul-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.01855,
        "recall": 0.036054,
        "f1": 0.022198,
        "accuracy": 0.036054,
        "main_score": 0.022198,
        "hf_subset": "bul_Cyrl-hrv_Latn",
        "languages": [
          "bul-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.079359,
        "recall": 0.112669,
        "f1": 0.087446,
        "accuracy": 0.112669,
        "main_score": 0.087446,
        "hf_subset": "bul_Cyrl-mkd_Cyrl",
        "languages": [
          "bul-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.011024,
        "recall": 0.023535,
        "f1": 0.013586,
        "accuracy": 0.023535,
        "main_score": 0.013586,
        "hf_subset": "bul_Cyrl-pol_Latn",
        "languages": [
          "bul-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.067327,
        "recall": 0.098147,
        "f1": 0.074493,
        "accuracy": 0.098147,
        "main_score": 0.074493,
        "hf_subset": "bul_Cyrl-rus_Cyrl",
        "languages": [
          "bul-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.017631,
        "recall": 0.032048,
        "f1": 0.020449,
        "accuracy": 0.032048,
        "main_score": 0.020449,
        "hf_subset": "bul_Cyrl-slk_Latn",
        "languages": [
          "bul-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.019767,
        "recall": 0.03305,
        "f1": 0.02311,
        "accuracy": 0.03305,
        "main_score": 0.02311,
        "hf_subset": "bul_Cyrl-slv_Latn",
        "languages": [
          "bul-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.020331,
        "recall": 0.031547,
        "f1": 0.02268,
        "accuracy": 0.031547,
        "main_score": 0.02268,
        "hf_subset": "bul_Cyrl-srp_Cyrl",
        "languages": [
          "bul-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.015725,
        "recall": 0.029544,
        "f1": 0.018756,
        "accuracy": 0.029544,
        "main_score": 0.018756,
        "hf_subset": "bul_Cyrl-srp_Latn",
        "languages": [
          "bul-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.03296,
        "recall": 0.051077,
        "f1": 0.036906,
        "accuracy": 0.051077,
        "main_score": 0.036906,
        "hf_subset": "bul_Cyrl-ukr_Cyrl",
        "languages": [
          "bul-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.047768,
        "recall": 0.079619,
        "f1": 0.054628,
        "accuracy": 0.079619,
        "main_score": 0.054628,
        "hf_subset": "cat_Latn-eng_Latn",
        "languages": [
          "cat-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027882,
        "recall": 0.049574,
        "f1": 0.032397,
        "accuracy": 0.049574,
        "main_score": 0.032397,
        "hf_subset": "cat_Latn-fra_Latn",
        "languages": [
          "cat-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.061726,
        "recall": 0.10015,
        "f1": 0.070547,
        "accuracy": 0.10015,
        "main_score": 0.070547,
        "hf_subset": "cat_Latn-glg_Latn",
        "languages": [
          "cat-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.051557,
        "recall": 0.083625,
        "f1": 0.058892,
        "accuracy": 0.083625,
        "main_score": 0.058892,
        "hf_subset": "cat_Latn-ita_Latn",
        "languages": [
          "cat-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.008764,
        "recall": 0.018027,
        "f1": 0.009966,
        "accuracy": 0.018027,
        "main_score": 0.009966,
        "hf_subset": "cat_Latn-mlt_Latn",
        "languages": [
          "cat-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.070079,
        "recall": 0.104156,
        "f1": 0.078832,
        "accuracy": 0.104156,
        "main_score": 0.078832,
        "hf_subset": "cat_Latn-por_Latn",
        "languages": [
          "cat-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.040294,
        "recall": 0.064597,
        "f1": 0.045518,
        "accuracy": 0.064597,
        "main_score": 0.045518,
        "hf_subset": "cat_Latn-ron_Latn",
        "languages": [
          "cat-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.074199,
        "recall": 0.108663,
        "f1": 0.082107,
        "accuracy": 0.108663,
        "main_score": 0.082107,
        "hf_subset": "cat_Latn-spa_Latn",
        "languages": [
          "cat-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006715,
        "recall": 0.011017,
        "f1": 0.007332,
        "accuracy": 0.011017,
        "main_score": 0.007332,
        "hf_subset": "ces_Latn-bel_Cyrl",
        "languages": [
          "ces-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.039081,
        "recall": 0.063595,
        "f1": 0.044418,
        "accuracy": 0.063595,
        "main_score": 0.044418,
        "hf_subset": "ces_Latn-bos_Latn",
        "languages": [
          "ces-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.019465,
        "recall": 0.038558,
        "f1": 0.023409,
        "accuracy": 0.038558,
        "main_score": 0.023409,
        "hf_subset": "ces_Latn-bul_Cyrl",
        "languages": [
          "ces-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.043214,
        "recall": 0.068603,
        "f1": 0.049011,
        "accuracy": 0.068603,
        "main_score": 0.049011,
        "hf_subset": "ces_Latn-eng_Latn",
        "languages": [
          "ces-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.034246,
        "recall": 0.061092,
        "f1": 0.040313,
        "accuracy": 0.061092,
        "main_score": 0.040313,
        "hf_subset": "ces_Latn-hrv_Latn",
        "languages": [
          "ces-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.013237,
        "recall": 0.024537,
        "f1": 0.015109,
        "accuracy": 0.024537,
        "main_score": 0.015109,
        "hf_subset": "ces_Latn-mkd_Cyrl",
        "languages": [
          "ces-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.031085,
        "recall": 0.052078,
        "f1": 0.035542,
        "accuracy": 0.052078,
        "main_score": 0.035542,
        "hf_subset": "ces_Latn-pol_Latn",
        "languages": [
          "ces-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.012887,
        "recall": 0.025038,
        "f1": 0.014924,
        "accuracy": 0.025038,
        "main_score": 0.014924,
        "hf_subset": "ces_Latn-rus_Cyrl",
        "languages": [
          "ces-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.08793,
        "recall": 0.132699,
        "f1": 0.098065,
        "accuracy": 0.132699,
        "main_score": 0.098065,
        "hf_subset": "ces_Latn-slk_Latn",
        "languages": [
          "ces-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.04232,
        "recall": 0.064597,
        "f1": 0.047665,
        "accuracy": 0.064597,
        "main_score": 0.047665,
        "hf_subset": "ces_Latn-slv_Latn",
        "languages": [
          "ces-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.004852,
        "recall": 0.011017,
        "f1": 0.00579,
        "accuracy": 0.011017,
        "main_score": 0.00579,
        "hf_subset": "ces_Latn-srp_Cyrl",
        "languages": [
          "ces-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.036309,
        "recall": 0.060591,
        "f1": 0.041571,
        "accuracy": 0.060591,
        "main_score": 0.041571,
        "hf_subset": "ces_Latn-srp_Latn",
        "languages": [
          "ces-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.009295,
        "recall": 0.014522,
        "f1": 0.01021,
        "accuracy": 0.014522,
        "main_score": 0.01021,
        "hf_subset": "ces_Latn-ukr_Cyrl",
        "languages": [
          "ces-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "ckb_Arab-arb_Arab",
        "languages": [
          "ckb-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 3e-06,
        "accuracy": 0.000501,
        "main_score": 3e-06,
        "hf_subset": "ckb_Arab-eng_Latn",
        "languages": [
          "ckb-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.001002,
        "f1": 5e-06,
        "accuracy": 0.001002,
        "main_score": 5e-06,
        "hf_subset": "ckb_Arab-fas_Arab",
        "languages": [
          "ckb-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.000168,
        "recall": 0.001502,
        "f1": 0.000253,
        "accuracy": 0.001502,
        "main_score": 0.000253,
        "hf_subset": "ckb_Arab-heb_Hebr",
        "languages": [
          "ckb-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.000419,
        "recall": 0.001502,
        "f1": 0.000588,
        "accuracy": 0.001502,
        "main_score": 0.000588,
        "hf_subset": "ckb_Arab-kmr_Latn",
        "languages": [
          "ckb-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.000614,
        "recall": 0.002003,
        "f1": 0.000693,
        "accuracy": 0.002003,
        "main_score": 0.000693,
        "hf_subset": "ckb_Arab-mey_Arab",
        "languages": [
          "ckb-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.000252,
        "recall": 0.001502,
        "f1": 0.000336,
        "accuracy": 0.001502,
        "main_score": 0.000336,
        "hf_subset": "ckb_Arab-prs_Arab",
        "languages": [
          "ckb-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.001252,
        "recall": 0.002504,
        "f1": 0.001396,
        "accuracy": 0.002504,
        "main_score": 0.001396,
        "hf_subset": "ckb_Arab-pus_Arab",
        "languages": [
          "ckb-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001002,
        "f1": 0.001002,
        "accuracy": 0.001002,
        "main_score": 0.001002,
        "hf_subset": "ckb_Arab-shi_Arab",
        "languages": [
          "ckb-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000336,
        "accuracy": 0.001002,
        "main_score": 0.000336,
        "hf_subset": "ckb_Arab-tgk_Cyrl",
        "languages": [
          "ckb-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.04859,
        "recall": 0.065598,
        "f1": 0.052586,
        "accuracy": 0.065598,
        "main_score": 0.052586,
        "hf_subset": "cym_Latn-eng_Latn",
        "languages": [
          "cym-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020132,
        "recall": 0.031547,
        "f1": 0.022746,
        "accuracy": 0.031547,
        "main_score": 0.022746,
        "hf_subset": "cym_Latn-gle_Latn",
        "languages": [
          "cym-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.049243,
        "recall": 0.081622,
        "f1": 0.056569,
        "accuracy": 0.081622,
        "main_score": 0.056569,
        "hf_subset": "dan_Latn-afr_Latn",
        "languages": [
          "dan-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.055644,
        "recall": 0.088633,
        "f1": 0.063487,
        "accuracy": 0.088633,
        "main_score": 0.063487,
        "hf_subset": "dan_Latn-deu_Latn",
        "languages": [
          "dan-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.077757,
        "recall": 0.115674,
        "f1": 0.087335,
        "accuracy": 0.115674,
        "main_score": 0.087335,
        "hf_subset": "dan_Latn-eng_Latn",
        "languages": [
          "dan-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.033986,
        "recall": 0.056585,
        "f1": 0.038937,
        "accuracy": 0.056585,
        "main_score": 0.038937,
        "hf_subset": "dan_Latn-fao_Latn",
        "languages": [
          "dan-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.021444,
        "recall": 0.037556,
        "f1": 0.024845,
        "accuracy": 0.037556,
        "main_score": 0.024845,
        "hf_subset": "dan_Latn-isl_Latn",
        "languages": [
          "dan-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.047804,
        "recall": 0.074612,
        "f1": 0.054015,
        "accuracy": 0.074612,
        "main_score": 0.054015,
        "hf_subset": "dan_Latn-ltz_Latn",
        "languages": [
          "dan-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.056373,
        "recall": 0.09314,
        "f1": 0.065305,
        "accuracy": 0.09314,
        "main_score": 0.065305,
        "hf_subset": "dan_Latn-nld_Latn",
        "languages": [
          "dan-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.086404,
        "recall": 0.129695,
        "f1": 0.097776,
        "accuracy": 0.129695,
        "main_score": 0.097776,
        "hf_subset": "dan_Latn-nno_Latn",
        "languages": [
          "dan-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.143292,
        "recall": 0.191287,
        "f1": 0.156051,
        "accuracy": 0.191287,
        "main_score": 0.156051,
        "hf_subset": "dan_Latn-nob_Latn",
        "languages": [
          "dan-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.104236,
        "recall": 0.149224,
        "f1": 0.11509,
        "accuracy": 0.149224,
        "main_score": 0.11509,
        "hf_subset": "dan_Latn-swe_Latn",
        "languages": [
          "dan-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.036213,
        "recall": 0.067101,
        "f1": 0.042571,
        "accuracy": 0.067101,
        "main_score": 0.042571,
        "hf_subset": "deu_Latn-afr_Latn",
        "languages": [
          "deu-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.006699,
        "recall": 0.012519,
        "f1": 0.007893,
        "accuracy": 0.012519,
        "main_score": 0.007893,
        "hf_subset": "deu_Latn-arb_Arab",
        "languages": [
          "deu-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002061,
        "recall": 0.004507,
        "f1": 0.002281,
        "accuracy": 0.004507,
        "main_score": 0.002281,
        "hf_subset": "deu_Latn-ben_Beng",
        "languages": [
          "deu-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.045064,
        "recall": 0.078117,
        "f1": 0.052212,
        "accuracy": 0.078117,
        "main_score": 0.052212,
        "hf_subset": "deu_Latn-dan_Latn",
        "languages": [
          "deu-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.010102,
        "recall": 0.019029,
        "f1": 0.011663,
        "accuracy": 0.019029,
        "main_score": 0.011663,
        "hf_subset": "deu_Latn-ell_Grek",
        "languages": [
          "deu-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.049704,
        "recall": 0.074612,
        "f1": 0.054969,
        "accuracy": 0.074612,
        "main_score": 0.054969,
        "hf_subset": "deu_Latn-eng_Latn",
        "languages": [
          "deu-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027179,
        "recall": 0.05358,
        "f1": 0.032362,
        "accuracy": 0.05358,
        "main_score": 0.032362,
        "hf_subset": "deu_Latn-fao_Latn",
        "languages": [
          "deu-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.023991,
        "recall": 0.04657,
        "f1": 0.02821,
        "accuracy": 0.04657,
        "main_score": 0.02821,
        "hf_subset": "deu_Latn-fas_Arab",
        "languages": [
          "deu-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.027995,
        "recall": 0.05308,
        "f1": 0.033035,
        "accuracy": 0.05308,
        "main_score": 0.033035,
        "hf_subset": "deu_Latn-fin_Latn",
        "languages": [
          "deu-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.011493,
        "recall": 0.022033,
        "f1": 0.013489,
        "accuracy": 0.022033,
        "main_score": 0.013489,
        "hf_subset": "deu_Latn-fra_Latn",
        "languages": [
          "deu-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.003637,
        "recall": 0.011017,
        "f1": 0.004339,
        "accuracy": 0.011017,
        "main_score": 0.004339,
        "hf_subset": "deu_Latn-heb_Hebr",
        "languages": [
          "deu-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.006605,
        "recall": 0.010015,
        "f1": 0.00724,
        "accuracy": 0.010015,
        "main_score": 0.00724,
        "hf_subset": "deu_Latn-hin_Deva",
        "languages": [
          "deu-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032334,
        "recall": 0.058588,
        "f1": 0.038008,
        "accuracy": 0.058588,
        "main_score": 0.038008,
        "hf_subset": "deu_Latn-hun_Latn",
        "languages": [
          "deu-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.059386,
        "recall": 0.088132,
        "f1": 0.066022,
        "accuracy": 0.088132,
        "main_score": 0.066022,
        "hf_subset": "deu_Latn-ind_Latn",
        "languages": [
          "deu-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.016633,
        "recall": 0.036054,
        "f1": 0.01988,
        "accuracy": 0.036054,
        "main_score": 0.01988,
        "hf_subset": "deu_Latn-isl_Latn",
        "languages": [
          "deu-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.003359,
        "recall": 0.008513,
        "f1": 0.003824,
        "accuracy": 0.008513,
        "main_score": 0.003824,
        "hf_subset": "deu_Latn-jpn_Jpan",
        "languages": [
          "deu-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.006272,
        "recall": 0.015023,
        "f1": 0.007315,
        "accuracy": 0.015023,
        "main_score": 0.007315,
        "hf_subset": "deu_Latn-kor_Hang",
        "languages": [
          "deu-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.033069,
        "recall": 0.056084,
        "f1": 0.038264,
        "accuracy": 0.056084,
        "main_score": 0.038264,
        "hf_subset": "deu_Latn-lit_Latn",
        "languages": [
          "deu-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.079339,
        "recall": 0.109164,
        "f1": 0.086774,
        "accuracy": 0.109164,
        "main_score": 0.086774,
        "hf_subset": "deu_Latn-ltz_Latn",
        "languages": [
          "deu-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.04309,
        "recall": 0.071107,
        "f1": 0.050057,
        "accuracy": 0.071107,
        "main_score": 0.050057,
        "hf_subset": "deu_Latn-nld_Latn",
        "languages": [
          "deu-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.041755,
        "recall": 0.069104,
        "f1": 0.048229,
        "accuracy": 0.069104,
        "main_score": 0.048229,
        "hf_subset": "deu_Latn-nno_Latn",
        "languages": [
          "deu-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.047682,
        "recall": 0.07311,
        "f1": 0.053569,
        "accuracy": 0.07311,
        "main_score": 0.053569,
        "hf_subset": "deu_Latn-nob_Latn",
        "languages": [
          "deu-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.022465,
        "recall": 0.046069,
        "f1": 0.026792,
        "accuracy": 0.046069,
        "main_score": 0.026792,
        "hf_subset": "deu_Latn-pol_Latn",
        "languages": [
          "deu-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.031017,
        "recall": 0.054081,
        "f1": 0.03575,
        "accuracy": 0.054081,
        "main_score": 0.03575,
        "hf_subset": "deu_Latn-por_Latn",
        "languages": [
          "deu-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.011301,
        "recall": 0.023035,
        "f1": 0.013173,
        "accuracy": 0.023035,
        "main_score": 0.013173,
        "hf_subset": "deu_Latn-rus_Cyrl",
        "languages": [
          "deu-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.040238,
        "recall": 0.0666,
        "f1": 0.046224,
        "accuracy": 0.0666,
        "main_score": 0.046224,
        "hf_subset": "deu_Latn-spa_Latn",
        "languages": [
          "deu-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.033504,
        "recall": 0.06009,
        "f1": 0.039126,
        "accuracy": 0.06009,
        "main_score": 0.039126,
        "hf_subset": "deu_Latn-swa_Latn",
        "languages": [
          "deu-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.052536,
        "recall": 0.081622,
        "f1": 0.059538,
        "accuracy": 0.081622,
        "main_score": 0.059538,
        "hf_subset": "deu_Latn-swe_Latn",
        "languages": [
          "deu-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.003088,
        "recall": 0.004006,
        "f1": 0.003338,
        "accuracy": 0.004006,
        "main_score": 0.003338,
        "hf_subset": "deu_Latn-tam_Taml",
        "languages": [
          "deu-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.028168,
        "recall": 0.051577,
        "f1": 0.033003,
        "accuracy": 0.051577,
        "main_score": 0.033003,
        "hf_subset": "deu_Latn-tur_Latn",
        "languages": [
          "deu-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.042347,
        "recall": 0.077616,
        "f1": 0.049741,
        "accuracy": 0.077616,
        "main_score": 0.049741,
        "hf_subset": "deu_Latn-vie_Latn",
        "languages": [
          "deu-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.016391,
        "recall": 0.028543,
        "f1": 0.018623,
        "accuracy": 0.028543,
        "main_score": 0.018623,
        "hf_subset": "deu_Latn-zho_Hant",
        "languages": [
          "deu-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.014011,
        "recall": 0.029044,
        "f1": 0.016584,
        "accuracy": 0.029044,
        "main_score": 0.016584,
        "hf_subset": "deu_Latn-zul_Latn",
        "languages": [
          "deu-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.000501,
        "f1": 1.3e-05,
        "accuracy": 0.000501,
        "main_score": 1.3e-05,
        "hf_subset": "div_Thaa-ben_Beng",
        "languages": [
          "div-Thaa",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000335,
        "accuracy": 0.001002,
        "main_score": 0.000335,
        "hf_subset": "div_Thaa-eng_Latn",
        "languages": [
          "div-Thaa",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "div_Thaa-eus_Latn",
        "languages": [
          "div-Thaa",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.002254,
        "recall": 0.003005,
        "f1": 0.002337,
        "accuracy": 0.003005,
        "main_score": 0.002337,
        "hf_subset": "div_Thaa-guj_Gujr",
        "languages": [
          "div-Thaa",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.000125,
        "recall": 0.001002,
        "f1": 0.000201,
        "accuracy": 0.001002,
        "main_score": 0.000201,
        "hf_subset": "div_Thaa-hin_Deva",
        "languages": [
          "div-Thaa",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00219,
        "recall": 0.004006,
        "f1": 0.002458,
        "accuracy": 0.004006,
        "main_score": 0.002458,
        "hf_subset": "div_Thaa-kan_Knda",
        "languages": [
          "div-Thaa",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.000372,
        "recall": 0.002504,
        "f1": 0.000553,
        "accuracy": 0.002504,
        "main_score": 0.000553,
        "hf_subset": "div_Thaa-mar_Deva",
        "languages": [
          "div-Thaa",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.000626,
        "recall": 0.001002,
        "f1": 0.000701,
        "accuracy": 0.001002,
        "main_score": 0.000701,
        "hf_subset": "div_Thaa-nep_Deva",
        "languages": [
          "div-Thaa",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.00063,
        "recall": 0.001502,
        "f1": 0.000708,
        "accuracy": 0.001502,
        "main_score": 0.000708,
        "hf_subset": "div_Thaa-pan_Guru",
        "languages": [
          "div-Thaa",
          "pan-Guru"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.000501,
        "f1": 1e-05,
        "accuracy": 0.000501,
        "main_score": 1e-05,
        "hf_subset": "div_Thaa-sin_Sinh",
        "languages": [
          "div-Thaa",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000506,
        "accuracy": 0.001502,
        "main_score": 0.000506,
        "hf_subset": "div_Thaa-snd_Arab",
        "languages": [
          "div-Thaa",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002509,
        "recall": 0.003505,
        "f1": 0.002515,
        "accuracy": 0.003505,
        "main_score": 0.002515,
        "hf_subset": "div_Thaa-tam_Taml",
        "languages": [
          "div-Thaa",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000296,
        "recall": 0.001502,
        "f1": 0.000419,
        "accuracy": 0.001502,
        "main_score": 0.000419,
        "hf_subset": "div_Thaa-tel_Telu",
        "languages": [
          "div-Thaa",
          "tel-Telu"
        ]
      },
      {
        "precision": 2e-05,
        "recall": 0.001502,
        "f1": 4e-05,
        "accuracy": 0.001502,
        "main_score": 4e-05,
        "hf_subset": "div_Thaa-urd_Arab",
        "languages": [
          "div-Thaa",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001113,
        "recall": 0.003505,
        "f1": 0.001366,
        "accuracy": 0.003505,
        "main_score": 0.001366,
        "hf_subset": "dzo_Tibt-bod_Tibt",
        "languages": [
          "dzo-Tibt",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.002188,
        "recall": 0.004006,
        "f1": 0.002311,
        "accuracy": 0.004006,
        "main_score": 0.002311,
        "hf_subset": "dzo_Tibt-eng_Latn",
        "languages": [
          "dzo-Tibt",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00192,
        "recall": 0.003005,
        "f1": 0.002113,
        "accuracy": 0.003005,
        "main_score": 0.002113,
        "hf_subset": "dzo_Tibt-khm_Khmr",
        "languages": [
          "dzo-Tibt",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.002087,
        "recall": 0.004006,
        "f1": 0.002374,
        "accuracy": 0.004006,
        "main_score": 0.002374,
        "hf_subset": "dzo_Tibt-lao_Laoo",
        "languages": [
          "dzo-Tibt",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.00205,
        "recall": 0.004006,
        "f1": 0.002312,
        "accuracy": 0.004006,
        "main_score": 0.002312,
        "hf_subset": "dzo_Tibt-mon_Mong",
        "languages": [
          "dzo-Tibt",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.000709,
        "recall": 0.002504,
        "f1": 0.000851,
        "accuracy": 0.002504,
        "main_score": 0.000851,
        "hf_subset": "dzo_Tibt-mya_Mymr",
        "languages": [
          "dzo-Tibt",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.001891,
        "recall": 0.004507,
        "f1": 0.002148,
        "accuracy": 0.004507,
        "main_score": 0.002148,
        "hf_subset": "dzo_Tibt-tha_Thai",
        "languages": [
          "dzo-Tibt",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.011098,
        "recall": 0.018528,
        "f1": 0.012553,
        "accuracy": 0.018528,
        "main_score": 0.012553,
        "hf_subset": "ell_Grek-arb_Arab",
        "languages": [
          "ell-Grek",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.004129,
        "recall": 0.007011,
        "f1": 0.004617,
        "accuracy": 0.007011,
        "main_score": 0.004617,
        "hf_subset": "ell_Grek-ben_Beng",
        "languages": [
          "ell-Grek",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.017848,
        "recall": 0.025038,
        "f1": 0.019748,
        "accuracy": 0.025038,
        "main_score": 0.019748,
        "hf_subset": "ell_Grek-deu_Latn",
        "languages": [
          "ell-Grek",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.022824,
        "recall": 0.036555,
        "f1": 0.025951,
        "accuracy": 0.036555,
        "main_score": 0.025951,
        "hf_subset": "ell_Grek-eng_Latn",
        "languages": [
          "ell-Grek",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012335,
        "recall": 0.018528,
        "f1": 0.013734,
        "accuracy": 0.018528,
        "main_score": 0.013734,
        "hf_subset": "ell_Grek-fas_Arab",
        "languages": [
          "ell-Grek",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.013423,
        "recall": 0.022033,
        "f1": 0.015308,
        "accuracy": 0.022033,
        "main_score": 0.015308,
        "hf_subset": "ell_Grek-fin_Latn",
        "languages": [
          "ell-Grek",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.008683,
        "recall": 0.014021,
        "f1": 0.009717,
        "accuracy": 0.014021,
        "main_score": 0.009717,
        "hf_subset": "ell_Grek-fra_Latn",
        "languages": [
          "ell-Grek",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.006637,
        "recall": 0.011517,
        "f1": 0.007529,
        "accuracy": 0.011517,
        "main_score": 0.007529,
        "hf_subset": "ell_Grek-heb_Hebr",
        "languages": [
          "ell-Grek",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.01032,
        "recall": 0.015523,
        "f1": 0.011526,
        "accuracy": 0.015523,
        "main_score": 0.011526,
        "hf_subset": "ell_Grek-hin_Deva",
        "languages": [
          "ell-Grek",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.015315,
        "recall": 0.022534,
        "f1": 0.016722,
        "accuracy": 0.022534,
        "main_score": 0.016722,
        "hf_subset": "ell_Grek-hun_Latn",
        "languages": [
          "ell-Grek",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.005863,
        "recall": 0.007511,
        "f1": 0.006237,
        "accuracy": 0.007511,
        "main_score": 0.006237,
        "hf_subset": "ell_Grek-hye_Armn",
        "languages": [
          "ell-Grek",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.022379,
        "recall": 0.031547,
        "f1": 0.0246,
        "accuracy": 0.031547,
        "main_score": 0.0246,
        "hf_subset": "ell_Grek-ind_Latn",
        "languages": [
          "ell-Grek",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.005026,
        "recall": 0.011017,
        "f1": 0.006362,
        "accuracy": 0.011017,
        "main_score": 0.006362,
        "hf_subset": "ell_Grek-jpn_Jpan",
        "languages": [
          "ell-Grek",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.005045,
        "recall": 0.008012,
        "f1": 0.005642,
        "accuracy": 0.008012,
        "main_score": 0.005642,
        "hf_subset": "ell_Grek-kat_Geor",
        "languages": [
          "ell-Grek",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.007852,
        "recall": 0.01302,
        "f1": 0.008696,
        "accuracy": 0.01302,
        "main_score": 0.008696,
        "hf_subset": "ell_Grek-kor_Hang",
        "languages": [
          "ell-Grek",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.012215,
        "recall": 0.018528,
        "f1": 0.013511,
        "accuracy": 0.018528,
        "main_score": 0.013511,
        "hf_subset": "ell_Grek-lit_Latn",
        "languages": [
          "ell-Grek",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.020463,
        "recall": 0.029044,
        "f1": 0.022452,
        "accuracy": 0.029044,
        "main_score": 0.022452,
        "hf_subset": "ell_Grek-nld_Latn",
        "languages": [
          "ell-Grek",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.011155,
        "recall": 0.017526,
        "f1": 0.012239,
        "accuracy": 0.017526,
        "main_score": 0.012239,
        "hf_subset": "ell_Grek-pol_Latn",
        "languages": [
          "ell-Grek",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.017923,
        "recall": 0.027541,
        "f1": 0.020144,
        "accuracy": 0.027541,
        "main_score": 0.020144,
        "hf_subset": "ell_Grek-por_Latn",
        "languages": [
          "ell-Grek",
          "por-Latn"
        ]
      },
      {
        "precision": 0.011806,
        "recall": 0.019029,
        "f1": 0.013489,
        "accuracy": 0.019029,
        "main_score": 0.013489,
        "hf_subset": "ell_Grek-rus_Cyrl",
        "languages": [
          "ell-Grek",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.019935,
        "recall": 0.027041,
        "f1": 0.021599,
        "accuracy": 0.027041,
        "main_score": 0.021599,
        "hf_subset": "ell_Grek-spa_Latn",
        "languages": [
          "ell-Grek",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.014835,
        "recall": 0.027541,
        "f1": 0.017257,
        "accuracy": 0.027541,
        "main_score": 0.017257,
        "hf_subset": "ell_Grek-sqi_Latn",
        "languages": [
          "ell-Grek",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.019002,
        "recall": 0.029044,
        "f1": 0.020891,
        "accuracy": 0.029044,
        "main_score": 0.020891,
        "hf_subset": "ell_Grek-swa_Latn",
        "languages": [
          "ell-Grek",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.018485,
        "recall": 0.02654,
        "f1": 0.020169,
        "accuracy": 0.02654,
        "main_score": 0.020169,
        "hf_subset": "ell_Grek-swe_Latn",
        "languages": [
          "ell-Grek",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.003447,
        "recall": 0.006009,
        "f1": 0.003845,
        "accuracy": 0.006009,
        "main_score": 0.003845,
        "hf_subset": "ell_Grek-tam_Taml",
        "languages": [
          "ell-Grek",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.016267,
        "recall": 0.025038,
        "f1": 0.018299,
        "accuracy": 0.025038,
        "main_score": 0.018299,
        "hf_subset": "ell_Grek-tur_Latn",
        "languages": [
          "ell-Grek",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.015716,
        "recall": 0.024537,
        "f1": 0.017651,
        "accuracy": 0.024537,
        "main_score": 0.017651,
        "hf_subset": "ell_Grek-vie_Latn",
        "languages": [
          "ell-Grek",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.009363,
        "recall": 0.016024,
        "f1": 0.010544,
        "accuracy": 0.016024,
        "main_score": 0.010544,
        "hf_subset": "ell_Grek-zho_Hant",
        "languages": [
          "ell-Grek",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006851,
        "recall": 0.011517,
        "f1": 0.007721,
        "accuracy": 0.011517,
        "main_score": 0.007721,
        "hf_subset": "ell_Grek-zul_Latn",
        "languages": [
          "ell-Grek",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.048021,
        "recall": 0.083625,
        "f1": 0.055744,
        "accuracy": 0.083625,
        "main_score": 0.055744,
        "hf_subset": "eng_Latn-afr_Latn",
        "languages": [
          "eng-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.002129,
        "recall": 0.003505,
        "f1": 0.002206,
        "accuracy": 0.003505,
        "main_score": 0.002206,
        "hf_subset": "eng_Latn-amh_Ethi",
        "languages": [
          "eng-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.008175,
        "recall": 0.016525,
        "f1": 0.009599,
        "accuracy": 0.016525,
        "main_score": 0.009599,
        "hf_subset": "eng_Latn-arb_Arab",
        "languages": [
          "eng-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.014171,
        "recall": 0.027541,
        "f1": 0.016715,
        "accuracy": 0.027541,
        "main_score": 0.016715,
        "hf_subset": "eng_Latn-aze_Latn",
        "languages": [
          "eng-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.002504,
        "recall": 0.003005,
        "f1": 0.002671,
        "accuracy": 0.003005,
        "main_score": 0.002671,
        "hf_subset": "eng_Latn-bak_Cyrl",
        "languages": [
          "eng-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.005979,
        "recall": 0.01302,
        "f1": 0.006929,
        "accuracy": 0.01302,
        "main_score": 0.006929,
        "hf_subset": "eng_Latn-bel_Cyrl",
        "languages": [
          "eng-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.042682,
        "recall": 0.0666,
        "f1": 0.047648,
        "accuracy": 0.0666,
        "main_score": 0.047648,
        "hf_subset": "eng_Latn-bem_Latn",
        "languages": [
          "eng-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.001798,
        "recall": 0.005508,
        "f1": 0.002202,
        "accuracy": 0.005508,
        "main_score": 0.002202,
        "hf_subset": "eng_Latn-ben_Beng",
        "languages": [
          "eng-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.009876,
        "recall": 0.021532,
        "f1": 0.011829,
        "accuracy": 0.021532,
        "main_score": 0.011829,
        "hf_subset": "eng_Latn-bod_Tibt",
        "languages": [
          "eng-Latn",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.027331,
        "recall": 0.050075,
        "f1": 0.031586,
        "accuracy": 0.050075,
        "main_score": 0.031586,
        "hf_subset": "eng_Latn-bos_Latn",
        "languages": [
          "eng-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.017485,
        "recall": 0.035053,
        "f1": 0.020652,
        "accuracy": 0.035053,
        "main_score": 0.020652,
        "hf_subset": "eng_Latn-bul_Cyrl",
        "languages": [
          "eng-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.030941,
        "recall": 0.054081,
        "f1": 0.035649,
        "accuracy": 0.054081,
        "main_score": 0.035649,
        "hf_subset": "eng_Latn-cat_Latn",
        "languages": [
          "eng-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.03851,
        "recall": 0.063095,
        "f1": 0.043402,
        "accuracy": 0.063095,
        "main_score": 0.043402,
        "hf_subset": "eng_Latn-ces_Latn",
        "languages": [
          "eng-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.000337,
        "recall": 0.003505,
        "f1": 0.000492,
        "accuracy": 0.003505,
        "main_score": 0.000492,
        "hf_subset": "eng_Latn-ckb_Arab",
        "languages": [
          "eng-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.018986,
        "recall": 0.037556,
        "f1": 0.022418,
        "accuracy": 0.037556,
        "main_score": 0.022418,
        "hf_subset": "eng_Latn-cym_Latn",
        "languages": [
          "eng-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.065905,
        "recall": 0.104657,
        "f1": 0.074784,
        "accuracy": 0.104657,
        "main_score": 0.074784,
        "hf_subset": "eng_Latn-dan_Latn",
        "languages": [
          "eng-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.046728,
        "recall": 0.069604,
        "f1": 0.052011,
        "accuracy": 0.069604,
        "main_score": 0.052011,
        "hf_subset": "eng_Latn-deu_Latn",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.002039,
        "recall": 0.003005,
        "f1": 0.00207,
        "accuracy": 0.003005,
        "main_score": 0.00207,
        "hf_subset": "eng_Latn-div_Thaa",
        "languages": [
          "eng-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.001625,
        "recall": 0.003005,
        "f1": 0.001712,
        "accuracy": 0.003005,
        "main_score": 0.001712,
        "hf_subset": "eng_Latn-dzo_Tibt",
        "languages": [
          "eng-Latn",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.011134,
        "recall": 0.020531,
        "f1": 0.012517,
        "accuracy": 0.020531,
        "main_score": 0.012517,
        "hf_subset": "eng_Latn-ell_Grek",
        "languages": [
          "eng-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.045496,
        "recall": 0.075113,
        "f1": 0.052253,
        "accuracy": 0.075113,
        "main_score": 0.052253,
        "hf_subset": "eng_Latn-eus_Latn",
        "languages": [
          "eng-Latn",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.004326,
        "recall": 0.010015,
        "f1": 0.004961,
        "accuracy": 0.010015,
        "main_score": 0.004961,
        "hf_subset": "eng_Latn-ewe_Latn",
        "languages": [
          "eng-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.031997,
        "recall": 0.055583,
        "f1": 0.036576,
        "accuracy": 0.055583,
        "main_score": 0.036576,
        "hf_subset": "eng_Latn-fao_Latn",
        "languages": [
          "eng-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.02424,
        "recall": 0.045068,
        "f1": 0.028649,
        "accuracy": 0.045068,
        "main_score": 0.028649,
        "hf_subset": "eng_Latn-fas_Arab",
        "languages": [
          "eng-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.048624,
        "recall": 0.083625,
        "f1": 0.056199,
        "accuracy": 0.083625,
        "main_score": 0.056199,
        "hf_subset": "eng_Latn-fij_Latn",
        "languages": [
          "eng-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.095791,
        "recall": 0.13971,
        "f1": 0.106251,
        "accuracy": 0.13971,
        "main_score": 0.106251,
        "hf_subset": "eng_Latn-fil_Latn",
        "languages": [
          "eng-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.025282,
        "recall": 0.050576,
        "f1": 0.030327,
        "accuracy": 0.050576,
        "main_score": 0.030327,
        "hf_subset": "eng_Latn-fin_Latn",
        "languages": [
          "eng-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.016117,
        "recall": 0.030546,
        "f1": 0.018641,
        "accuracy": 0.030546,
        "main_score": 0.018641,
        "hf_subset": "eng_Latn-fra_Latn",
        "languages": [
          "eng-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.06852,
        "recall": 0.105158,
        "f1": 0.07747,
        "accuracy": 0.105158,
        "main_score": 0.07747,
        "hf_subset": "eng_Latn-fuc_Latn",
        "languages": [
          "eng-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.015786,
        "recall": 0.029544,
        "f1": 0.018274,
        "accuracy": 0.029544,
        "main_score": 0.018274,
        "hf_subset": "eng_Latn-gle_Latn",
        "languages": [
          "eng-Latn",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.053428,
        "recall": 0.085128,
        "f1": 0.0602,
        "accuracy": 0.085128,
        "main_score": 0.0602,
        "hf_subset": "eng_Latn-glg_Latn",
        "languages": [
          "eng-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.001171,
        "recall": 0.002504,
        "f1": 0.001257,
        "accuracy": 0.002504,
        "main_score": 0.001257,
        "hf_subset": "eng_Latn-guj_Gujr",
        "languages": [
          "eng-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.041647,
        "recall": 0.074612,
        "f1": 0.04873,
        "accuracy": 0.074612,
        "main_score": 0.04873,
        "hf_subset": "eng_Latn-hau_Latn",
        "languages": [
          "eng-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.005534,
        "recall": 0.015023,
        "f1": 0.00683,
        "accuracy": 0.015023,
        "main_score": 0.00683,
        "hf_subset": "eng_Latn-heb_Hebr",
        "languages": [
          "eng-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.01015,
        "recall": 0.021532,
        "f1": 0.011873,
        "accuracy": 0.021532,
        "main_score": 0.011873,
        "hf_subset": "eng_Latn-hin_Deva",
        "languages": [
          "eng-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.039293,
        "recall": 0.064096,
        "f1": 0.044801,
        "accuracy": 0.064096,
        "main_score": 0.044801,
        "hf_subset": "eng_Latn-hmn_Latn",
        "languages": [
          "eng-Latn",
          "hmn-Latn"
        ]
      },
      {
        "precision": 0.026253,
        "recall": 0.045568,
        "f1": 0.029789,
        "accuracy": 0.045568,
        "main_score": 0.029789,
        "hf_subset": "eng_Latn-hrv_Latn",
        "languages": [
          "eng-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.028077,
        "recall": 0.047071,
        "f1": 0.032026,
        "accuracy": 0.047071,
        "main_score": 0.032026,
        "hf_subset": "eng_Latn-hun_Latn",
        "languages": [
          "eng-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.001861,
        "recall": 0.004006,
        "f1": 0.002193,
        "accuracy": 0.004006,
        "main_score": 0.002193,
        "hf_subset": "eng_Latn-hye_Armn",
        "languages": [
          "eng-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.056665,
        "recall": 0.085128,
        "f1": 0.062913,
        "accuracy": 0.085128,
        "main_score": 0.062913,
        "hf_subset": "eng_Latn-ibo_Latn",
        "languages": [
          "eng-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.10098,
        "recall": 0.145218,
        "f1": 0.111891,
        "accuracy": 0.145218,
        "main_score": 0.111891,
        "hf_subset": "eng_Latn-ind_Latn",
        "languages": [
          "eng-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.019261,
        "recall": 0.035053,
        "f1": 0.022161,
        "accuracy": 0.035053,
        "main_score": 0.022161,
        "hf_subset": "eng_Latn-isl_Latn",
        "languages": [
          "eng-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.067613,
        "recall": 0.103655,
        "f1": 0.07586,
        "accuracy": 0.103655,
        "main_score": 0.07586,
        "hf_subset": "eng_Latn-ita_Latn",
        "languages": [
          "eng-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.004278,
        "recall": 0.009014,
        "f1": 0.004873,
        "accuracy": 0.009014,
        "main_score": 0.004873,
        "hf_subset": "eng_Latn-jpn_Jpan",
        "languages": [
          "eng-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.002315,
        "recall": 0.004006,
        "f1": 0.002454,
        "accuracy": 0.004006,
        "main_score": 0.002454,
        "hf_subset": "eng_Latn-kan_Knda",
        "languages": [
          "eng-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001129,
        "recall": 0.002504,
        "f1": 0.001221,
        "accuracy": 0.002504,
        "main_score": 0.001221,
        "hf_subset": "eng_Latn-kat_Geor",
        "languages": [
          "eng-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.008108,
        "recall": 0.018027,
        "f1": 0.009713,
        "accuracy": 0.018027,
        "main_score": 0.009713,
        "hf_subset": "eng_Latn-kaz_Cyrl",
        "languages": [
          "eng-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.001276,
        "recall": 0.002504,
        "f1": 0.001381,
        "accuracy": 0.002504,
        "main_score": 0.001381,
        "hf_subset": "eng_Latn-khm_Khmr",
        "languages": [
          "eng-Latn",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.036343,
        "recall": 0.064096,
        "f1": 0.041694,
        "accuracy": 0.064096,
        "main_score": 0.041694,
        "hf_subset": "eng_Latn-kin_Latn",
        "languages": [
          "eng-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.006507,
        "recall": 0.012519,
        "f1": 0.007457,
        "accuracy": 0.012519,
        "main_score": 0.007457,
        "hf_subset": "eng_Latn-kir_Cyrl",
        "languages": [
          "eng-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.009273,
        "recall": 0.028042,
        "f1": 0.011962,
        "accuracy": 0.028042,
        "main_score": 0.011962,
        "hf_subset": "eng_Latn-kmr_Latn",
        "languages": [
          "eng-Latn",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.006721,
        "recall": 0.01352,
        "f1": 0.007554,
        "accuracy": 0.01352,
        "main_score": 0.007554,
        "hf_subset": "eng_Latn-kor_Hang",
        "languages": [
          "eng-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.001622,
        "recall": 0.003005,
        "f1": 0.001707,
        "accuracy": 0.003005,
        "main_score": 0.001707,
        "hf_subset": "eng_Latn-lao_Laoo",
        "languages": [
          "eng-Latn",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.033985,
        "recall": 0.05358,
        "f1": 0.038597,
        "accuracy": 0.05358,
        "main_score": 0.038597,
        "hf_subset": "eng_Latn-lav_Latn",
        "languages": [
          "eng-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.029103,
        "recall": 0.046069,
        "f1": 0.033264,
        "accuracy": 0.046069,
        "main_score": 0.033264,
        "hf_subset": "eng_Latn-lit_Latn",
        "languages": [
          "eng-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.051265,
        "recall": 0.077616,
        "f1": 0.057105,
        "accuracy": 0.077616,
        "main_score": 0.057105,
        "hf_subset": "eng_Latn-ltz_Latn",
        "languages": [
          "eng-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.000692,
        "recall": 0.002003,
        "f1": 0.000798,
        "accuracy": 0.002003,
        "main_score": 0.000798,
        "hf_subset": "eng_Latn-mal_Mlym",
        "languages": [
          "eng-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.003299,
        "recall": 0.010015,
        "f1": 0.004351,
        "accuracy": 0.010015,
        "main_score": 0.004351,
        "hf_subset": "eng_Latn-mar_Deva",
        "languages": [
          "eng-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005601,
        "recall": 0.014522,
        "f1": 0.006612,
        "accuracy": 0.014522,
        "main_score": 0.006612,
        "hf_subset": "eng_Latn-mey_Arab",
        "languages": [
          "eng-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.012949,
        "recall": 0.024036,
        "f1": 0.014818,
        "accuracy": 0.024036,
        "main_score": 0.014818,
        "hf_subset": "eng_Latn-mkd_Cyrl",
        "languages": [
          "eng-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.027287,
        "recall": 0.050576,
        "f1": 0.032222,
        "accuracy": 0.050576,
        "main_score": 0.032222,
        "hf_subset": "eng_Latn-mlg_Latn",
        "languages": [
          "eng-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.010339,
        "recall": 0.020531,
        "f1": 0.012307,
        "accuracy": 0.020531,
        "main_score": 0.012307,
        "hf_subset": "eng_Latn-mlt_Latn",
        "languages": [
          "eng-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.007327,
        "recall": 0.01352,
        "f1": 0.008088,
        "accuracy": 0.01352,
        "main_score": 0.008088,
        "hf_subset": "eng_Latn-mon_Mong",
        "languages": [
          "eng-Latn",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.055187,
        "recall": 0.087631,
        "f1": 0.062168,
        "accuracy": 0.087631,
        "main_score": 0.062168,
        "hf_subset": "eng_Latn-mri_Latn",
        "languages": [
          "eng-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.099306,
        "recall": 0.141212,
        "f1": 0.109886,
        "accuracy": 0.141212,
        "main_score": 0.109886,
        "hf_subset": "eng_Latn-msa_Latn",
        "languages": [
          "eng-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.000918,
        "recall": 0.002003,
        "f1": 0.001252,
        "accuracy": 0.002003,
        "main_score": 0.001252,
        "hf_subset": "eng_Latn-mya_Mymr",
        "languages": [
          "eng-Latn",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.015157,
        "recall": 0.029544,
        "f1": 0.01782,
        "accuracy": 0.029544,
        "main_score": 0.01782,
        "hf_subset": "eng_Latn-nde_Latn",
        "languages": [
          "eng-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.01167,
        "recall": 0.028543,
        "f1": 0.013951,
        "accuracy": 0.028543,
        "main_score": 0.013951,
        "hf_subset": "eng_Latn-nep_Deva",
        "languages": [
          "eng-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.053789,
        "recall": 0.084126,
        "f1": 0.06089,
        "accuracy": 0.084126,
        "main_score": 0.06089,
        "hf_subset": "eng_Latn-nld_Latn",
        "languages": [
          "eng-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.049466,
        "recall": 0.079619,
        "f1": 0.056038,
        "accuracy": 0.079619,
        "main_score": 0.056038,
        "hf_subset": "eng_Latn-nno_Latn",
        "languages": [
          "eng-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.060803,
        "recall": 0.090135,
        "f1": 0.067727,
        "accuracy": 0.090135,
        "main_score": 0.067727,
        "hf_subset": "eng_Latn-nob_Latn",
        "languages": [
          "eng-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.044532,
        "recall": 0.076114,
        "f1": 0.051354,
        "accuracy": 0.076114,
        "main_score": 0.051354,
        "hf_subset": "eng_Latn-nso_Latn",
        "languages": [
          "eng-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.040801,
        "recall": 0.072609,
        "f1": 0.04779,
        "accuracy": 0.072609,
        "main_score": 0.04779,
        "hf_subset": "eng_Latn-nya_Latn",
        "languages": [
          "eng-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.018587,
        "recall": 0.036054,
        "f1": 0.022117,
        "accuracy": 0.036054,
        "main_score": 0.022117,
        "hf_subset": "eng_Latn-orm_Ethi",
        "languages": [
          "eng-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.004012,
        "recall": 0.010015,
        "f1": 0.004786,
        "accuracy": 0.010015,
        "main_score": 0.004786,
        "hf_subset": "eng_Latn-pan_Guru",
        "languages": [
          "eng-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.017647,
        "recall": 0.035553,
        "f1": 0.020816,
        "accuracy": 0.035553,
        "main_score": 0.020816,
        "hf_subset": "eng_Latn-pol_Latn",
        "languages": [
          "eng-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.039276,
        "recall": 0.063095,
        "f1": 0.044562,
        "accuracy": 0.063095,
        "main_score": 0.044562,
        "hf_subset": "eng_Latn-por_Latn",
        "languages": [
          "eng-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.028208,
        "recall": 0.047571,
        "f1": 0.032063,
        "accuracy": 0.047571,
        "main_score": 0.032063,
        "hf_subset": "eng_Latn-prs_Arab",
        "languages": [
          "eng-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.007548,
        "recall": 0.021032,
        "f1": 0.009814,
        "accuracy": 0.021032,
        "main_score": 0.009814,
        "hf_subset": "eng_Latn-pus_Arab",
        "languages": [
          "eng-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.042599,
        "recall": 0.067601,
        "f1": 0.047925,
        "accuracy": 0.067601,
        "main_score": 0.047925,
        "hf_subset": "eng_Latn-ron_Latn",
        "languages": [
          "eng-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.013621,
        "recall": 0.028543,
        "f1": 0.015907,
        "accuracy": 0.028543,
        "main_score": 0.015907,
        "hf_subset": "eng_Latn-rus_Cyrl",
        "languages": [
          "eng-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.006713,
        "recall": 0.014021,
        "f1": 0.007791,
        "accuracy": 0.014021,
        "main_score": 0.007791,
        "hf_subset": "eng_Latn-shi_Arab",
        "languages": [
          "eng-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.000194,
        "recall": 0.002003,
        "f1": 0.000304,
        "accuracy": 0.002003,
        "main_score": 0.000304,
        "hf_subset": "eng_Latn-sin_Sinh",
        "languages": [
          "eng-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.021521,
        "recall": 0.043065,
        "f1": 0.025666,
        "accuracy": 0.043065,
        "main_score": 0.025666,
        "hf_subset": "eng_Latn-slk_Latn",
        "languages": [
          "eng-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.034784,
        "recall": 0.06009,
        "f1": 0.039997,
        "accuracy": 0.06009,
        "main_score": 0.039997,
        "hf_subset": "eng_Latn-slv_Latn",
        "languages": [
          "eng-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.042501,
        "recall": 0.071607,
        "f1": 0.048602,
        "accuracy": 0.071607,
        "main_score": 0.048602,
        "hf_subset": "eng_Latn-smo_Latn",
        "languages": [
          "eng-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.02774,
        "recall": 0.050075,
        "f1": 0.032338,
        "accuracy": 0.050075,
        "main_score": 0.032338,
        "hf_subset": "eng_Latn-sna_Latn",
        "languages": [
          "eng-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.005383,
        "recall": 0.009514,
        "f1": 0.006129,
        "accuracy": 0.009514,
        "main_score": 0.006129,
        "hf_subset": "eng_Latn-snd_Arab",
        "languages": [
          "eng-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.023777,
        "recall": 0.047571,
        "f1": 0.028304,
        "accuracy": 0.047571,
        "main_score": 0.028304,
        "hf_subset": "eng_Latn-som_Latn",
        "languages": [
          "eng-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.053626,
        "recall": 0.089134,
        "f1": 0.061485,
        "accuracy": 0.089134,
        "main_score": 0.061485,
        "hf_subset": "eng_Latn-spa_Latn",
        "languages": [
          "eng-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.035526,
        "recall": 0.061092,
        "f1": 0.040512,
        "accuracy": 0.061092,
        "main_score": 0.040512,
        "hf_subset": "eng_Latn-sqi_Latn",
        "languages": [
          "eng-Latn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.005632,
        "recall": 0.011017,
        "f1": 0.006325,
        "accuracy": 0.011017,
        "main_score": 0.006325,
        "hf_subset": "eng_Latn-srp_Cyrl",
        "languages": [
          "eng-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.023742,
        "recall": 0.046069,
        "f1": 0.028174,
        "accuracy": 0.046069,
        "main_score": 0.028174,
        "hf_subset": "eng_Latn-srp_Latn",
        "languages": [
          "eng-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.026055,
        "recall": 0.048072,
        "f1": 0.030389,
        "accuracy": 0.048072,
        "main_score": 0.030389,
        "hf_subset": "eng_Latn-ssw_Latn",
        "languages": [
          "eng-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.054768,
        "recall": 0.091637,
        "f1": 0.063047,
        "accuracy": 0.091637,
        "main_score": 0.063047,
        "hf_subset": "eng_Latn-swa_Latn",
        "languages": [
          "eng-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.055838,
        "recall": 0.088633,
        "f1": 0.063501,
        "accuracy": 0.088633,
        "main_score": 0.063501,
        "hf_subset": "eng_Latn-swe_Latn",
        "languages": [
          "eng-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.037514,
        "recall": 0.063095,
        "f1": 0.043454,
        "accuracy": 0.063095,
        "main_score": 0.043454,
        "hf_subset": "eng_Latn-tah_Latn",
        "languages": [
          "eng-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.002646,
        "recall": 0.004006,
        "f1": 0.002904,
        "accuracy": 0.004006,
        "main_score": 0.002904,
        "hf_subset": "eng_Latn-tam_Taml",
        "languages": [
          "eng-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.004258,
        "recall": 0.011517,
        "f1": 0.004941,
        "accuracy": 0.011517,
        "main_score": 0.004941,
        "hf_subset": "eng_Latn-tat_Cyrl",
        "languages": [
          "eng-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.007542,
        "recall": 0.016024,
        "f1": 0.008878,
        "accuracy": 0.016024,
        "main_score": 0.008878,
        "hf_subset": "eng_Latn-tel_Telu",
        "languages": [
          "eng-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004686,
        "recall": 0.009014,
        "f1": 0.00521,
        "accuracy": 0.009014,
        "main_score": 0.00521,
        "hf_subset": "eng_Latn-tgk_Cyrl",
        "languages": [
          "eng-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.016881,
        "recall": 0.031547,
        "f1": 0.019417,
        "accuracy": 0.031547,
        "main_score": 0.019417,
        "hf_subset": "eng_Latn-tha_Thai",
        "languages": [
          "eng-Latn",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.002379,
        "recall": 0.003505,
        "f1": 0.002538,
        "accuracy": 0.003505,
        "main_score": 0.002538,
        "hf_subset": "eng_Latn-tir_Ethi",
        "languages": [
          "eng-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.003724,
        "recall": 0.007011,
        "f1": 0.004188,
        "accuracy": 0.007011,
        "main_score": 0.004188,
        "hf_subset": "eng_Latn-ton_Latn",
        "languages": [
          "eng-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.047154,
        "recall": 0.078117,
        "f1": 0.053686,
        "accuracy": 0.078117,
        "main_score": 0.053686,
        "hf_subset": "eng_Latn-tsn_Latn",
        "languages": [
          "eng-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.013035,
        "recall": 0.024036,
        "f1": 0.015058,
        "accuracy": 0.024036,
        "main_score": 0.015058,
        "hf_subset": "eng_Latn-tuk_Latn",
        "languages": [
          "eng-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.044661,
        "recall": 0.07361,
        "f1": 0.051298,
        "accuracy": 0.07361,
        "main_score": 0.051298,
        "hf_subset": "eng_Latn-tur_Latn",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.002177,
        "recall": 0.004006,
        "f1": 0.002321,
        "accuracy": 0.004006,
        "main_score": 0.002321,
        "hf_subset": "eng_Latn-uig_Arab",
        "languages": [
          "eng-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.010248,
        "recall": 0.022033,
        "f1": 0.012047,
        "accuracy": 0.022033,
        "main_score": 0.012047,
        "hf_subset": "eng_Latn-ukr_Cyrl",
        "languages": [
          "eng-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.016002,
        "recall": 0.029544,
        "f1": 0.018671,
        "accuracy": 0.029544,
        "main_score": 0.018671,
        "hf_subset": "eng_Latn-urd_Arab",
        "languages": [
          "eng-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.015268,
        "recall": 0.027041,
        "f1": 0.017622,
        "accuracy": 0.027041,
        "main_score": 0.017622,
        "hf_subset": "eng_Latn-uzb_Latn",
        "languages": [
          "eng-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.039823,
        "recall": 0.065098,
        "f1": 0.044795,
        "accuracy": 0.065098,
        "main_score": 0.044795,
        "hf_subset": "eng_Latn-ven_Latn",
        "languages": [
          "eng-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.044303,
        "recall": 0.074612,
        "f1": 0.051132,
        "accuracy": 0.074612,
        "main_score": 0.051132,
        "hf_subset": "eng_Latn-vie_Latn",
        "languages": [
          "eng-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.027801,
        "recall": 0.051577,
        "f1": 0.032346,
        "accuracy": 0.051577,
        "main_score": 0.032346,
        "hf_subset": "eng_Latn-wol_Latn",
        "languages": [
          "eng-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.019675,
        "recall": 0.039559,
        "f1": 0.023275,
        "accuracy": 0.039559,
        "main_score": 0.023275,
        "hf_subset": "eng_Latn-xho_Latn",
        "languages": [
          "eng-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.01565,
        "recall": 0.035053,
        "f1": 0.018401,
        "accuracy": 0.035053,
        "main_score": 0.018401,
        "hf_subset": "eng_Latn-yor_Latn",
        "languages": [
          "eng-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.005767,
        "recall": 0.01302,
        "f1": 0.0072,
        "accuracy": 0.01302,
        "main_score": 0.0072,
        "hf_subset": "eng_Latn-yue_Hant",
        "languages": [
          "eng-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.011993,
        "recall": 0.02654,
        "f1": 0.014562,
        "accuracy": 0.02654,
        "main_score": 0.014562,
        "hf_subset": "eng_Latn-zho_Hans",
        "languages": [
          "eng-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.017917,
        "recall": 0.031047,
        "f1": 0.020499,
        "accuracy": 0.031047,
        "main_score": 0.020499,
        "hf_subset": "eng_Latn-zho_Hant",
        "languages": [
          "eng-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.024096,
        "recall": 0.050576,
        "f1": 0.028873,
        "accuracy": 0.050576,
        "main_score": 0.028873,
        "hf_subset": "eng_Latn-zul_Latn",
        "languages": [
          "eng-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002237,
        "recall": 0.004006,
        "f1": 0.00238,
        "accuracy": 0.004006,
        "main_score": 0.00238,
        "hf_subset": "eus_Latn-ben_Beng",
        "languages": [
          "eus-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.00192,
        "recall": 0.003005,
        "f1": 0.002087,
        "accuracy": 0.003005,
        "main_score": 0.002087,
        "hf_subset": "eus_Latn-div_Thaa",
        "languages": [
          "eus-Latn",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.046929,
        "recall": 0.072108,
        "f1": 0.052917,
        "accuracy": 0.072108,
        "main_score": 0.052917,
        "hf_subset": "eus_Latn-eng_Latn",
        "languages": [
          "eus-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "eus_Latn-guj_Gujr",
        "languages": [
          "eus-Latn",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.007799,
        "recall": 0.017026,
        "f1": 0.009189,
        "accuracy": 0.017026,
        "main_score": 0.009189,
        "hf_subset": "eus_Latn-hin_Deva",
        "languages": [
          "eus-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.00304,
        "recall": 0.003505,
        "f1": 0.003071,
        "accuracy": 0.003505,
        "main_score": 0.003071,
        "hf_subset": "eus_Latn-kan_Knda",
        "languages": [
          "eus-Latn",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003059,
        "recall": 0.009014,
        "f1": 0.003761,
        "accuracy": 0.009014,
        "main_score": 0.003761,
        "hf_subset": "eus_Latn-mar_Deva",
        "languages": [
          "eus-Latn",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.004463,
        "recall": 0.01352,
        "f1": 0.00583,
        "accuracy": 0.01352,
        "main_score": 0.00583,
        "hf_subset": "eus_Latn-nep_Deva",
        "languages": [
          "eus-Latn",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.002699,
        "recall": 0.00651,
        "f1": 0.003289,
        "accuracy": 0.00651,
        "main_score": 0.003289,
        "hf_subset": "eus_Latn-pan_Guru",
        "languages": [
          "eus-Latn",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002635,
        "recall": 0.003505,
        "f1": 0.002715,
        "accuracy": 0.003505,
        "main_score": 0.002715,
        "hf_subset": "eus_Latn-sin_Sinh",
        "languages": [
          "eus-Latn",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.003449,
        "recall": 0.008012,
        "f1": 0.003945,
        "accuracy": 0.008012,
        "main_score": 0.003945,
        "hf_subset": "eus_Latn-snd_Arab",
        "languages": [
          "eus-Latn",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.003444,
        "recall": 0.005008,
        "f1": 0.003631,
        "accuracy": 0.005008,
        "main_score": 0.003631,
        "hf_subset": "eus_Latn-tam_Taml",
        "languages": [
          "eus-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.005571,
        "recall": 0.016024,
        "f1": 0.007158,
        "accuracy": 0.016024,
        "main_score": 0.007158,
        "hf_subset": "eus_Latn-tel_Telu",
        "languages": [
          "eus-Latn",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.01378,
        "recall": 0.027541,
        "f1": 0.016628,
        "accuracy": 0.027541,
        "main_score": 0.016628,
        "hf_subset": "eus_Latn-urd_Arab",
        "languages": [
          "eus-Latn",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.00414,
        "recall": 0.005508,
        "f1": 0.00439,
        "accuracy": 0.005508,
        "main_score": 0.00439,
        "hf_subset": "ewe_Latn-bem_Latn",
        "languages": [
          "ewe-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.010025,
        "recall": 0.011017,
        "f1": 0.010201,
        "accuracy": 0.011017,
        "main_score": 0.010201,
        "hf_subset": "ewe_Latn-eng_Latn",
        "languages": [
          "ewe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003005,
        "recall": 0.004006,
        "f1": 0.003172,
        "accuracy": 0.004006,
        "main_score": 0.003172,
        "hf_subset": "ewe_Latn-fuc_Latn",
        "languages": [
          "ewe-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.00426,
        "recall": 0.005008,
        "f1": 0.004347,
        "accuracy": 0.005008,
        "main_score": 0.004347,
        "hf_subset": "ewe_Latn-kin_Latn",
        "languages": [
          "ewe-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.001319,
        "recall": 0.003005,
        "f1": 0.001511,
        "accuracy": 0.003005,
        "main_score": 0.001511,
        "hf_subset": "ewe_Latn-nde_Latn",
        "languages": [
          "ewe-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.003305,
        "recall": 0.004006,
        "f1": 0.003429,
        "accuracy": 0.004006,
        "main_score": 0.003429,
        "hf_subset": "ewe_Latn-nya_Latn",
        "languages": [
          "ewe-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.003541,
        "recall": 0.005008,
        "f1": 0.003573,
        "accuracy": 0.005008,
        "main_score": 0.003573,
        "hf_subset": "ewe_Latn-sna_Latn",
        "languages": [
          "ewe-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.004459,
        "recall": 0.007011,
        "f1": 0.00491,
        "accuracy": 0.007011,
        "main_score": 0.00491,
        "hf_subset": "ewe_Latn-ven_Latn",
        "languages": [
          "ewe-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.02442,
        "recall": 0.039059,
        "f1": 0.027538,
        "accuracy": 0.039059,
        "main_score": 0.027538,
        "hf_subset": "fao_Latn-afr_Latn",
        "languages": [
          "fao-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.037065,
        "recall": 0.052579,
        "f1": 0.040468,
        "accuracy": 0.052579,
        "main_score": 0.040468,
        "hf_subset": "fao_Latn-dan_Latn",
        "languages": [
          "fao-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.038113,
        "recall": 0.056585,
        "f1": 0.042781,
        "accuracy": 0.056585,
        "main_score": 0.042781,
        "hf_subset": "fao_Latn-deu_Latn",
        "languages": [
          "fao-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.04216,
        "recall": 0.063595,
        "f1": 0.046956,
        "accuracy": 0.063595,
        "main_score": 0.046956,
        "hf_subset": "fao_Latn-eng_Latn",
        "languages": [
          "fao-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037445,
        "recall": 0.056585,
        "f1": 0.041755,
        "accuracy": 0.056585,
        "main_score": 0.041755,
        "hf_subset": "fao_Latn-isl_Latn",
        "languages": [
          "fao-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.039419,
        "recall": 0.060591,
        "f1": 0.043956,
        "accuracy": 0.060591,
        "main_score": 0.043956,
        "hf_subset": "fao_Latn-ltz_Latn",
        "languages": [
          "fao-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.035365,
        "recall": 0.052078,
        "f1": 0.039186,
        "accuracy": 0.052078,
        "main_score": 0.039186,
        "hf_subset": "fao_Latn-nld_Latn",
        "languages": [
          "fao-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.040876,
        "recall": 0.059589,
        "f1": 0.045069,
        "accuracy": 0.059589,
        "main_score": 0.045069,
        "hf_subset": "fao_Latn-nno_Latn",
        "languages": [
          "fao-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.048679,
        "recall": 0.0666,
        "f1": 0.052946,
        "accuracy": 0.0666,
        "main_score": 0.052946,
        "hf_subset": "fao_Latn-nob_Latn",
        "languages": [
          "fao-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.04277,
        "recall": 0.060591,
        "f1": 0.04692,
        "accuracy": 0.060591,
        "main_score": 0.04692,
        "hf_subset": "fao_Latn-swe_Latn",
        "languages": [
          "fao-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.006238,
        "recall": 0.018027,
        "f1": 0.007889,
        "accuracy": 0.018027,
        "main_score": 0.007889,
        "hf_subset": "fas_Arab-arb_Arab",
        "languages": [
          "fas-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000818,
        "recall": 0.003505,
        "f1": 0.000963,
        "accuracy": 0.003505,
        "main_score": 0.000963,
        "hf_subset": "fas_Arab-ben_Beng",
        "languages": [
          "fas-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000288,
        "recall": 0.002003,
        "f1": 0.000404,
        "accuracy": 0.002003,
        "main_score": 0.000404,
        "hf_subset": "fas_Arab-ckb_Arab",
        "languages": [
          "fas-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.022309,
        "recall": 0.035553,
        "f1": 0.025276,
        "accuracy": 0.035553,
        "main_score": 0.025276,
        "hf_subset": "fas_Arab-deu_Latn",
        "languages": [
          "fas-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.004874,
        "recall": 0.009514,
        "f1": 0.005529,
        "accuracy": 0.009514,
        "main_score": 0.005529,
        "hf_subset": "fas_Arab-ell_Grek",
        "languages": [
          "fas-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.028763,
        "recall": 0.044066,
        "f1": 0.032101,
        "accuracy": 0.044066,
        "main_score": 0.032101,
        "hf_subset": "fas_Arab-eng_Latn",
        "languages": [
          "fas-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017307,
        "recall": 0.031547,
        "f1": 0.020248,
        "accuracy": 0.031547,
        "main_score": 0.020248,
        "hf_subset": "fas_Arab-fin_Latn",
        "languages": [
          "fas-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.003639,
        "recall": 0.008012,
        "f1": 0.004373,
        "accuracy": 0.008012,
        "main_score": 0.004373,
        "hf_subset": "fas_Arab-fra_Latn",
        "languages": [
          "fas-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.003617,
        "recall": 0.007511,
        "f1": 0.004133,
        "accuracy": 0.007511,
        "main_score": 0.004133,
        "hf_subset": "fas_Arab-heb_Hebr",
        "languages": [
          "fas-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004511,
        "recall": 0.009014,
        "f1": 0.005079,
        "accuracy": 0.009014,
        "main_score": 0.005079,
        "hf_subset": "fas_Arab-hin_Deva",
        "languages": [
          "fas-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.011214,
        "recall": 0.021032,
        "f1": 0.013165,
        "accuracy": 0.021032,
        "main_score": 0.013165,
        "hf_subset": "fas_Arab-hun_Latn",
        "languages": [
          "fas-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.036511,
        "recall": 0.052078,
        "f1": 0.040074,
        "accuracy": 0.052078,
        "main_score": 0.040074,
        "hf_subset": "fas_Arab-ind_Latn",
        "languages": [
          "fas-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00211,
        "recall": 0.00651,
        "f1": 0.002444,
        "accuracy": 0.00651,
        "main_score": 0.002444,
        "hf_subset": "fas_Arab-jpn_Jpan",
        "languages": [
          "fas-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00429,
        "recall": 0.009014,
        "f1": 0.004902,
        "accuracy": 0.009014,
        "main_score": 0.004902,
        "hf_subset": "fas_Arab-kmr_Latn",
        "languages": [
          "fas-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.002663,
        "recall": 0.008513,
        "f1": 0.003299,
        "accuracy": 0.008513,
        "main_score": 0.003299,
        "hf_subset": "fas_Arab-kor_Hang",
        "languages": [
          "fas-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.015142,
        "recall": 0.024537,
        "f1": 0.01711,
        "accuracy": 0.024537,
        "main_score": 0.01711,
        "hf_subset": "fas_Arab-lit_Latn",
        "languages": [
          "fas-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.003898,
        "recall": 0.008513,
        "f1": 0.00439,
        "accuracy": 0.008513,
        "main_score": 0.00439,
        "hf_subset": "fas_Arab-mey_Arab",
        "languages": [
          "fas-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.017243,
        "recall": 0.029544,
        "f1": 0.019545,
        "accuracy": 0.029544,
        "main_score": 0.019545,
        "hf_subset": "fas_Arab-nld_Latn",
        "languages": [
          "fas-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.008006,
        "recall": 0.015023,
        "f1": 0.009354,
        "accuracy": 0.015023,
        "main_score": 0.009354,
        "hf_subset": "fas_Arab-pol_Latn",
        "languages": [
          "fas-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.011158,
        "recall": 0.021532,
        "f1": 0.012929,
        "accuracy": 0.021532,
        "main_score": 0.012929,
        "hf_subset": "fas_Arab-por_Latn",
        "languages": [
          "fas-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.074408,
        "recall": 0.103655,
        "f1": 0.0814,
        "accuracy": 0.103655,
        "main_score": 0.0814,
        "hf_subset": "fas_Arab-prs_Arab",
        "languages": [
          "fas-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.012975,
        "recall": 0.020531,
        "f1": 0.014711,
        "accuracy": 0.020531,
        "main_score": 0.014711,
        "hf_subset": "fas_Arab-pus_Arab",
        "languages": [
          "fas-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.009439,
        "recall": 0.018528,
        "f1": 0.010951,
        "accuracy": 0.018528,
        "main_score": 0.010951,
        "hf_subset": "fas_Arab-rus_Cyrl",
        "languages": [
          "fas-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.004422,
        "recall": 0.010015,
        "f1": 0.005324,
        "accuracy": 0.010015,
        "main_score": 0.005324,
        "hf_subset": "fas_Arab-shi_Arab",
        "languages": [
          "fas-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.01764,
        "recall": 0.030045,
        "f1": 0.020065,
        "accuracy": 0.030045,
        "main_score": 0.020065,
        "hf_subset": "fas_Arab-spa_Latn",
        "languages": [
          "fas-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.022286,
        "recall": 0.042564,
        "f1": 0.026668,
        "accuracy": 0.042564,
        "main_score": 0.026668,
        "hf_subset": "fas_Arab-swa_Latn",
        "languages": [
          "fas-Arab",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.017607,
        "recall": 0.027041,
        "f1": 0.019935,
        "accuracy": 0.027041,
        "main_score": 0.019935,
        "hf_subset": "fas_Arab-swe_Latn",
        "languages": [
          "fas-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "fas_Arab-tam_Taml",
        "languages": [
          "fas-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00416,
        "recall": 0.006009,
        "f1": 0.004428,
        "accuracy": 0.006009,
        "main_score": 0.004428,
        "hf_subset": "fas_Arab-tgk_Cyrl",
        "languages": [
          "fas-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.019378,
        "recall": 0.032549,
        "f1": 0.021576,
        "accuracy": 0.032549,
        "main_score": 0.021576,
        "hf_subset": "fas_Arab-tur_Latn",
        "languages": [
          "fas-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.030078,
        "recall": 0.04657,
        "f1": 0.033785,
        "accuracy": 0.04657,
        "main_score": 0.033785,
        "hf_subset": "fas_Arab-vie_Latn",
        "languages": [
          "fas-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.009852,
        "recall": 0.015523,
        "f1": 0.010657,
        "accuracy": 0.015523,
        "main_score": 0.010657,
        "hf_subset": "fas_Arab-zho_Hant",
        "languages": [
          "fas-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.011596,
        "recall": 0.02003,
        "f1": 0.013019,
        "accuracy": 0.02003,
        "main_score": 0.013019,
        "hf_subset": "fas_Arab-zul_Latn",
        "languages": [
          "fas-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.040746,
        "recall": 0.060591,
        "f1": 0.045368,
        "accuracy": 0.060591,
        "main_score": 0.045368,
        "hf_subset": "fij_Latn-eng_Latn",
        "languages": [
          "fij-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.046237,
        "recall": 0.069104,
        "f1": 0.051719,
        "accuracy": 0.069104,
        "main_score": 0.051719,
        "hf_subset": "fij_Latn-fil_Latn",
        "languages": [
          "fij-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.050279,
        "recall": 0.074111,
        "f1": 0.056381,
        "accuracy": 0.074111,
        "main_score": 0.056381,
        "hf_subset": "fij_Latn-ind_Latn",
        "languages": [
          "fij-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000507,
        "accuracy": 0.001502,
        "main_score": 0.000507,
        "hf_subset": "fij_Latn-mal_Mlym",
        "languages": [
          "fij-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.019314,
        "recall": 0.03355,
        "f1": 0.022322,
        "accuracy": 0.03355,
        "main_score": 0.022322,
        "hf_subset": "fij_Latn-mlg_Latn",
        "languages": [
          "fij-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.057643,
        "recall": 0.082123,
        "f1": 0.063559,
        "accuracy": 0.082123,
        "main_score": 0.063559,
        "hf_subset": "fij_Latn-mri_Latn",
        "languages": [
          "fij-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.045607,
        "recall": 0.068102,
        "f1": 0.051056,
        "accuracy": 0.068102,
        "main_score": 0.051056,
        "hf_subset": "fij_Latn-msa_Latn",
        "languages": [
          "fij-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.029009,
        "recall": 0.048573,
        "f1": 0.033151,
        "accuracy": 0.048573,
        "main_score": 0.033151,
        "hf_subset": "fij_Latn-smo_Latn",
        "languages": [
          "fij-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.024005,
        "recall": 0.037556,
        "f1": 0.026929,
        "accuracy": 0.037556,
        "main_score": 0.026929,
        "hf_subset": "fij_Latn-tah_Latn",
        "languages": [
          "fij-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001641,
        "recall": 0.003005,
        "f1": 0.001744,
        "accuracy": 0.003005,
        "main_score": 0.001744,
        "hf_subset": "fij_Latn-ton_Latn",
        "languages": [
          "fij-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.11269,
        "recall": 0.152729,
        "f1": 0.122693,
        "accuracy": 0.152729,
        "main_score": 0.122693,
        "hf_subset": "fil_Latn-eng_Latn",
        "languages": [
          "fil-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060197,
        "recall": 0.092138,
        "f1": 0.067873,
        "accuracy": 0.092138,
        "main_score": 0.067873,
        "hf_subset": "fil_Latn-fij_Latn",
        "languages": [
          "fil-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.08614,
        "recall": 0.125689,
        "f1": 0.096278,
        "accuracy": 0.125689,
        "main_score": 0.096278,
        "hf_subset": "fil_Latn-ind_Latn",
        "languages": [
          "fil-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.002381,
        "recall": 0.004006,
        "f1": 0.002543,
        "accuracy": 0.004006,
        "main_score": 0.002543,
        "hf_subset": "fil_Latn-mal_Mlym",
        "languages": [
          "fil-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024546,
        "recall": 0.044066,
        "f1": 0.028756,
        "accuracy": 0.044066,
        "main_score": 0.028756,
        "hf_subset": "fil_Latn-mlg_Latn",
        "languages": [
          "fil-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.058152,
        "recall": 0.09364,
        "f1": 0.066512,
        "accuracy": 0.09364,
        "main_score": 0.066512,
        "hf_subset": "fil_Latn-mri_Latn",
        "languages": [
          "fil-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.07713,
        "recall": 0.117176,
        "f1": 0.087234,
        "accuracy": 0.117176,
        "main_score": 0.087234,
        "hf_subset": "fil_Latn-msa_Latn",
        "languages": [
          "fil-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.03336,
        "recall": 0.060591,
        "f1": 0.039105,
        "accuracy": 0.060591,
        "main_score": 0.039105,
        "hf_subset": "fil_Latn-smo_Latn",
        "languages": [
          "fil-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.031322,
        "recall": 0.049574,
        "f1": 0.035246,
        "accuracy": 0.049574,
        "main_score": 0.035246,
        "hf_subset": "fil_Latn-tah_Latn",
        "languages": [
          "fil-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.00344,
        "recall": 0.006009,
        "f1": 0.003654,
        "accuracy": 0.006009,
        "main_score": 0.003654,
        "hf_subset": "fil_Latn-ton_Latn",
        "languages": [
          "fil-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.004454,
        "recall": 0.008012,
        "f1": 0.005125,
        "accuracy": 0.008012,
        "main_score": 0.005125,
        "hf_subset": "fin_Latn-arb_Arab",
        "languages": [
          "fin-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002551,
        "recall": 0.005508,
        "f1": 0.002981,
        "accuracy": 0.005508,
        "main_score": 0.002981,
        "hf_subset": "fin_Latn-ben_Beng",
        "languages": [
          "fin-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.035603,
        "recall": 0.055083,
        "f1": 0.04034,
        "accuracy": 0.055083,
        "main_score": 0.04034,
        "hf_subset": "fin_Latn-deu_Latn",
        "languages": [
          "fin-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.009128,
        "recall": 0.015523,
        "f1": 0.01035,
        "accuracy": 0.015523,
        "main_score": 0.01035,
        "hf_subset": "fin_Latn-ell_Grek",
        "languages": [
          "fin-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.03843,
        "recall": 0.059089,
        "f1": 0.042981,
        "accuracy": 0.059089,
        "main_score": 0.042981,
        "hf_subset": "fin_Latn-eng_Latn",
        "languages": [
          "fin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016541,
        "recall": 0.034051,
        "f1": 0.019823,
        "accuracy": 0.034051,
        "main_score": 0.019823,
        "hf_subset": "fin_Latn-fas_Arab",
        "languages": [
          "fin-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.012842,
        "recall": 0.022534,
        "f1": 0.014527,
        "accuracy": 0.022534,
        "main_score": 0.014527,
        "hf_subset": "fin_Latn-fra_Latn",
        "languages": [
          "fin-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005126,
        "recall": 0.012519,
        "f1": 0.006341,
        "accuracy": 0.012519,
        "main_score": 0.006341,
        "hf_subset": "fin_Latn-heb_Hebr",
        "languages": [
          "fin-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004553,
        "recall": 0.010516,
        "f1": 0.005544,
        "accuracy": 0.010516,
        "main_score": 0.005544,
        "hf_subset": "fin_Latn-hin_Deva",
        "languages": [
          "fin-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.028158,
        "recall": 0.049074,
        "f1": 0.032816,
        "accuracy": 0.049074,
        "main_score": 0.032816,
        "hf_subset": "fin_Latn-hun_Latn",
        "languages": [
          "fin-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.049331,
        "recall": 0.071607,
        "f1": 0.054581,
        "accuracy": 0.071607,
        "main_score": 0.054581,
        "hf_subset": "fin_Latn-ind_Latn",
        "languages": [
          "fin-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00373,
        "recall": 0.00651,
        "f1": 0.004066,
        "accuracy": 0.00651,
        "main_score": 0.004066,
        "hf_subset": "fin_Latn-jpn_Jpan",
        "languages": [
          "fin-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.006206,
        "recall": 0.01352,
        "f1": 0.00733,
        "accuracy": 0.01352,
        "main_score": 0.00733,
        "hf_subset": "fin_Latn-kor_Hang",
        "languages": [
          "fin-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.031462,
        "recall": 0.048573,
        "f1": 0.035355,
        "accuracy": 0.048573,
        "main_score": 0.035355,
        "hf_subset": "fin_Latn-lav_Latn",
        "languages": [
          "fin-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.029557,
        "recall": 0.041562,
        "f1": 0.032458,
        "accuracy": 0.041562,
        "main_score": 0.032458,
        "hf_subset": "fin_Latn-lit_Latn",
        "languages": [
          "fin-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.033859,
        "recall": 0.052579,
        "f1": 0.038522,
        "accuracy": 0.052579,
        "main_score": 0.038522,
        "hf_subset": "fin_Latn-nld_Latn",
        "languages": [
          "fin-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.017629,
        "recall": 0.035053,
        "f1": 0.020911,
        "accuracy": 0.035053,
        "main_score": 0.020911,
        "hf_subset": "fin_Latn-pol_Latn",
        "languages": [
          "fin-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.022671,
        "recall": 0.040561,
        "f1": 0.026612,
        "accuracy": 0.040561,
        "main_score": 0.026612,
        "hf_subset": "fin_Latn-por_Latn",
        "languages": [
          "fin-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.013449,
        "recall": 0.02654,
        "f1": 0.015814,
        "accuracy": 0.02654,
        "main_score": 0.015814,
        "hf_subset": "fin_Latn-rus_Cyrl",
        "languages": [
          "fin-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.039218,
        "recall": 0.061592,
        "f1": 0.044673,
        "accuracy": 0.061592,
        "main_score": 0.044673,
        "hf_subset": "fin_Latn-spa_Latn",
        "languages": [
          "fin-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.029769,
        "recall": 0.047071,
        "f1": 0.033824,
        "accuracy": 0.047071,
        "main_score": 0.033824,
        "hf_subset": "fin_Latn-swa_Latn",
        "languages": [
          "fin-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.042402,
        "recall": 0.061592,
        "f1": 0.046612,
        "accuracy": 0.061592,
        "main_score": 0.046612,
        "hf_subset": "fin_Latn-swe_Latn",
        "languages": [
          "fin-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001854,
        "recall": 0.003505,
        "f1": 0.002173,
        "accuracy": 0.003505,
        "main_score": 0.002173,
        "hf_subset": "fin_Latn-tam_Taml",
        "languages": [
          "fin-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.034912,
        "recall": 0.052078,
        "f1": 0.038722,
        "accuracy": 0.052078,
        "main_score": 0.038722,
        "hf_subset": "fin_Latn-tur_Latn",
        "languages": [
          "fin-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.035364,
        "recall": 0.055583,
        "f1": 0.039869,
        "accuracy": 0.055583,
        "main_score": 0.039869,
        "hf_subset": "fin_Latn-vie_Latn",
        "languages": [
          "fin-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.013474,
        "recall": 0.023535,
        "f1": 0.015101,
        "accuracy": 0.023535,
        "main_score": 0.015101,
        "hf_subset": "fin_Latn-zho_Hant",
        "languages": [
          "fin-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.016557,
        "recall": 0.028543,
        "f1": 0.018746,
        "accuracy": 0.028543,
        "main_score": 0.018746,
        "hf_subset": "fin_Latn-zul_Latn",
        "languages": [
          "fin-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.00801,
        "recall": 0.015023,
        "f1": 0.009261,
        "accuracy": 0.015023,
        "main_score": 0.009261,
        "hf_subset": "fra_Latn-arb_Arab",
        "languages": [
          "fra-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.004054,
        "recall": 0.011017,
        "f1": 0.005015,
        "accuracy": 0.011017,
        "main_score": 0.005015,
        "hf_subset": "fra_Latn-ben_Beng",
        "languages": [
          "fra-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.036436,
        "recall": 0.060591,
        "f1": 0.041925,
        "accuracy": 0.060591,
        "main_score": 0.041925,
        "hf_subset": "fra_Latn-cat_Latn",
        "languages": [
          "fra-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.021446,
        "recall": 0.035553,
        "f1": 0.024124,
        "accuracy": 0.035553,
        "main_score": 0.024124,
        "hf_subset": "fra_Latn-deu_Latn",
        "languages": [
          "fra-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.011798,
        "recall": 0.021532,
        "f1": 0.013739,
        "accuracy": 0.021532,
        "main_score": 0.013739,
        "hf_subset": "fra_Latn-ell_Grek",
        "languages": [
          "fra-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.028808,
        "recall": 0.045568,
        "f1": 0.032395,
        "accuracy": 0.045568,
        "main_score": 0.032395,
        "hf_subset": "fra_Latn-eng_Latn",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007568,
        "recall": 0.014522,
        "f1": 0.008892,
        "accuracy": 0.014522,
        "main_score": 0.008892,
        "hf_subset": "fra_Latn-fas_Arab",
        "languages": [
          "fra-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.014126,
        "recall": 0.026039,
        "f1": 0.016457,
        "accuracy": 0.026039,
        "main_score": 0.016457,
        "hf_subset": "fra_Latn-fin_Latn",
        "languages": [
          "fra-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.022206,
        "recall": 0.034552,
        "f1": 0.024656,
        "accuracy": 0.034552,
        "main_score": 0.024656,
        "hf_subset": "fra_Latn-glg_Latn",
        "languages": [
          "fra-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.004962,
        "recall": 0.012519,
        "f1": 0.006115,
        "accuracy": 0.012519,
        "main_score": 0.006115,
        "hf_subset": "fra_Latn-heb_Hebr",
        "languages": [
          "fra-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.009161,
        "recall": 0.015023,
        "f1": 0.01036,
        "accuracy": 0.015023,
        "main_score": 0.01036,
        "hf_subset": "fra_Latn-hin_Deva",
        "languages": [
          "fra-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020726,
        "recall": 0.030546,
        "f1": 0.022813,
        "accuracy": 0.030546,
        "main_score": 0.022813,
        "hf_subset": "fra_Latn-hun_Latn",
        "languages": [
          "fra-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.021992,
        "recall": 0.035553,
        "f1": 0.024682,
        "accuracy": 0.035553,
        "main_score": 0.024682,
        "hf_subset": "fra_Latn-ind_Latn",
        "languages": [
          "fra-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.02856,
        "recall": 0.042564,
        "f1": 0.031368,
        "accuracy": 0.042564,
        "main_score": 0.031368,
        "hf_subset": "fra_Latn-ita_Latn",
        "languages": [
          "fra-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.005857,
        "recall": 0.012018,
        "f1": 0.006889,
        "accuracy": 0.012018,
        "main_score": 0.006889,
        "hf_subset": "fra_Latn-jpn_Jpan",
        "languages": [
          "fra-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.005706,
        "recall": 0.011017,
        "f1": 0.006747,
        "accuracy": 0.011017,
        "main_score": 0.006747,
        "hf_subset": "fra_Latn-kor_Hang",
        "languages": [
          "fra-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.013885,
        "recall": 0.021532,
        "f1": 0.015533,
        "accuracy": 0.021532,
        "main_score": 0.015533,
        "hf_subset": "fra_Latn-lit_Latn",
        "languages": [
          "fra-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.005488,
        "recall": 0.012519,
        "f1": 0.006522,
        "accuracy": 0.012519,
        "main_score": 0.006522,
        "hf_subset": "fra_Latn-mlt_Latn",
        "languages": [
          "fra-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.02827,
        "recall": 0.045568,
        "f1": 0.031776,
        "accuracy": 0.045568,
        "main_score": 0.031776,
        "hf_subset": "fra_Latn-nld_Latn",
        "languages": [
          "fra-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.016094,
        "recall": 0.029044,
        "f1": 0.018747,
        "accuracy": 0.029044,
        "main_score": 0.018747,
        "hf_subset": "fra_Latn-pol_Latn",
        "languages": [
          "fra-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.031312,
        "recall": 0.052579,
        "f1": 0.03607,
        "accuracy": 0.052579,
        "main_score": 0.03607,
        "hf_subset": "fra_Latn-por_Latn",
        "languages": [
          "fra-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.028686,
        "recall": 0.042564,
        "f1": 0.031682,
        "accuracy": 0.042564,
        "main_score": 0.031682,
        "hf_subset": "fra_Latn-ron_Latn",
        "languages": [
          "fra-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.008477,
        "recall": 0.017026,
        "f1": 0.010033,
        "accuracy": 0.017026,
        "main_score": 0.010033,
        "hf_subset": "fra_Latn-rus_Cyrl",
        "languages": [
          "fra-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.023171,
        "recall": 0.039059,
        "f1": 0.026342,
        "accuracy": 0.039059,
        "main_score": 0.026342,
        "hf_subset": "fra_Latn-spa_Latn",
        "languages": [
          "fra-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.013498,
        "recall": 0.024036,
        "f1": 0.015573,
        "accuracy": 0.024036,
        "main_score": 0.015573,
        "hf_subset": "fra_Latn-swa_Latn",
        "languages": [
          "fra-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.020277,
        "recall": 0.034051,
        "f1": 0.023029,
        "accuracy": 0.034051,
        "main_score": 0.023029,
        "hf_subset": "fra_Latn-swe_Latn",
        "languages": [
          "fra-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.007111,
        "recall": 0.014021,
        "f1": 0.008261,
        "accuracy": 0.014021,
        "main_score": 0.008261,
        "hf_subset": "fra_Latn-tam_Taml",
        "languages": [
          "fra-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.019133,
        "recall": 0.03355,
        "f1": 0.021964,
        "accuracy": 0.03355,
        "main_score": 0.021964,
        "hf_subset": "fra_Latn-tur_Latn",
        "languages": [
          "fra-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.014177,
        "recall": 0.02654,
        "f1": 0.01674,
        "accuracy": 0.02654,
        "main_score": 0.01674,
        "hf_subset": "fra_Latn-vie_Latn",
        "languages": [
          "fra-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012691,
        "recall": 0.024537,
        "f1": 0.014942,
        "accuracy": 0.024537,
        "main_score": 0.014942,
        "hf_subset": "fra_Latn-zho_Hant",
        "languages": [
          "fra-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.007737,
        "recall": 0.016525,
        "f1": 0.009301,
        "accuracy": 0.016525,
        "main_score": 0.009301,
        "hf_subset": "fra_Latn-zul_Latn",
        "languages": [
          "fra-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.034261,
        "recall": 0.058588,
        "f1": 0.03991,
        "accuracy": 0.058588,
        "main_score": 0.03991,
        "hf_subset": "fuc_Latn-bem_Latn",
        "languages": [
          "fuc-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.075644,
        "recall": 0.102153,
        "f1": 0.082095,
        "accuracy": 0.102153,
        "main_score": 0.082095,
        "hf_subset": "fuc_Latn-eng_Latn",
        "languages": [
          "fuc-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003927,
        "recall": 0.007511,
        "f1": 0.004211,
        "accuracy": 0.007511,
        "main_score": 0.004211,
        "hf_subset": "fuc_Latn-ewe_Latn",
        "languages": [
          "fuc-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.03826,
        "recall": 0.056585,
        "f1": 0.042355,
        "accuracy": 0.056585,
        "main_score": 0.042355,
        "hf_subset": "fuc_Latn-kin_Latn",
        "languages": [
          "fuc-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.012236,
        "recall": 0.023535,
        "f1": 0.014653,
        "accuracy": 0.023535,
        "main_score": 0.014653,
        "hf_subset": "fuc_Latn-nde_Latn",
        "languages": [
          "fuc-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.037499,
        "recall": 0.065598,
        "f1": 0.044082,
        "accuracy": 0.065598,
        "main_score": 0.044082,
        "hf_subset": "fuc_Latn-nya_Latn",
        "languages": [
          "fuc-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.031171,
        "recall": 0.050075,
        "f1": 0.03513,
        "accuracy": 0.050075,
        "main_score": 0.03513,
        "hf_subset": "fuc_Latn-sna_Latn",
        "languages": [
          "fuc-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.036221,
        "recall": 0.058087,
        "f1": 0.041006,
        "accuracy": 0.058087,
        "main_score": 0.041006,
        "hf_subset": "fuc_Latn-ven_Latn",
        "languages": [
          "fuc-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.019704,
        "recall": 0.031047,
        "f1": 0.02201,
        "accuracy": 0.031047,
        "main_score": 0.02201,
        "hf_subset": "gle_Latn-cym_Latn",
        "languages": [
          "gle-Latn",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.036613,
        "recall": 0.05358,
        "f1": 0.040171,
        "accuracy": 0.05358,
        "main_score": 0.040171,
        "hf_subset": "gle_Latn-eng_Latn",
        "languages": [
          "gle-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.050554,
        "recall": 0.081122,
        "f1": 0.057413,
        "accuracy": 0.081122,
        "main_score": 0.057413,
        "hf_subset": "glg_Latn-cat_Latn",
        "languages": [
          "glg-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.062709,
        "recall": 0.098648,
        "f1": 0.07148,
        "accuracy": 0.098648,
        "main_score": 0.07148,
        "hf_subset": "glg_Latn-eng_Latn",
        "languages": [
          "glg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020802,
        "recall": 0.035053,
        "f1": 0.023096,
        "accuracy": 0.035053,
        "main_score": 0.023096,
        "hf_subset": "glg_Latn-fra_Latn",
        "languages": [
          "glg-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.071561,
        "recall": 0.105658,
        "f1": 0.080143,
        "accuracy": 0.105658,
        "main_score": 0.080143,
        "hf_subset": "glg_Latn-ita_Latn",
        "languages": [
          "glg-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.007322,
        "recall": 0.017026,
        "f1": 0.009003,
        "accuracy": 0.017026,
        "main_score": 0.009003,
        "hf_subset": "glg_Latn-mlt_Latn",
        "languages": [
          "glg-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.105575,
        "recall": 0.15974,
        "f1": 0.119172,
        "accuracy": 0.15974,
        "main_score": 0.119172,
        "hf_subset": "glg_Latn-por_Latn",
        "languages": [
          "glg-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.049167,
        "recall": 0.076615,
        "f1": 0.05574,
        "accuracy": 0.076615,
        "main_score": 0.05574,
        "hf_subset": "glg_Latn-ron_Latn",
        "languages": [
          "glg-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.163159,
        "recall": 0.224337,
        "f1": 0.179297,
        "accuracy": 0.224337,
        "main_score": 0.179297,
        "hf_subset": "glg_Latn-spa_Latn",
        "languages": [
          "glg-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001179,
        "recall": 0.004507,
        "f1": 0.001323,
        "accuracy": 0.004507,
        "main_score": 0.001323,
        "hf_subset": "guj_Gujr-ben_Beng",
        "languages": [
          "guj-Gujr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.001188,
        "recall": 0.005008,
        "f1": 0.001334,
        "accuracy": 0.005008,
        "main_score": 0.001334,
        "hf_subset": "guj_Gujr-div_Thaa",
        "languages": [
          "guj-Gujr",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000508,
        "accuracy": 0.001502,
        "main_score": 0.000508,
        "hf_subset": "guj_Gujr-eng_Latn",
        "languages": [
          "guj-Gujr",
          "eng-Latn"
        ]
      },
      {
        "precision": 4.6e-05,
        "recall": 0.001002,
        "f1": 8.4e-05,
        "accuracy": 0.001002,
        "main_score": 8.4e-05,
        "hf_subset": "guj_Gujr-eus_Latn",
        "languages": [
          "guj-Gujr",
          "eus-Latn"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.001002,
        "f1": 4e-06,
        "accuracy": 0.001002,
        "main_score": 4e-06,
        "hf_subset": "guj_Gujr-hin_Deva",
        "languages": [
          "guj-Gujr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.019899,
        "recall": 0.038057,
        "f1": 0.022144,
        "accuracy": 0.038057,
        "main_score": 0.022144,
        "hf_subset": "guj_Gujr-kan_Knda",
        "languages": [
          "guj-Gujr",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.001228,
        "recall": 0.004507,
        "f1": 0.001534,
        "accuracy": 0.004507,
        "main_score": 0.001534,
        "hf_subset": "guj_Gujr-mar_Deva",
        "languages": [
          "guj-Gujr",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.00142,
        "recall": 0.003005,
        "f1": 0.001589,
        "accuracy": 0.003005,
        "main_score": 0.001589,
        "hf_subset": "guj_Gujr-nep_Deva",
        "languages": [
          "guj-Gujr",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.002259,
        "recall": 0.004507,
        "f1": 0.002606,
        "accuracy": 0.004507,
        "main_score": 0.002606,
        "hf_subset": "guj_Gujr-pan_Guru",
        "languages": [
          "guj-Gujr",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.003778,
        "recall": 0.011517,
        "f1": 0.004458,
        "accuracy": 0.011517,
        "main_score": 0.004458,
        "hf_subset": "guj_Gujr-sin_Sinh",
        "languages": [
          "guj-Gujr",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.000505,
        "recall": 0.002003,
        "f1": 0.000509,
        "accuracy": 0.002003,
        "main_score": 0.000509,
        "hf_subset": "guj_Gujr-snd_Arab",
        "languages": [
          "guj-Gujr",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002444,
        "recall": 0.006009,
        "f1": 0.002663,
        "accuracy": 0.006009,
        "main_score": 0.002663,
        "hf_subset": "guj_Gujr-tam_Taml",
        "languages": [
          "guj-Gujr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000649,
        "recall": 0.004507,
        "f1": 0.000779,
        "accuracy": 0.004507,
        "main_score": 0.000779,
        "hf_subset": "guj_Gujr-tel_Telu",
        "languages": [
          "guj-Gujr",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000518,
        "recall": 0.001502,
        "f1": 0.000534,
        "accuracy": 0.001502,
        "main_score": 0.000534,
        "hf_subset": "guj_Gujr-urd_Arab",
        "languages": [
          "guj-Gujr",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001504,
        "recall": 0.002504,
        "f1": 0.001505,
        "accuracy": 0.002504,
        "main_score": 0.001505,
        "hf_subset": "hau_Latn-amh_Ethi",
        "languages": [
          "hau-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.053544,
        "recall": 0.079119,
        "f1": 0.059465,
        "accuracy": 0.079119,
        "main_score": 0.059465,
        "hf_subset": "hau_Latn-eng_Latn",
        "languages": [
          "hau-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.042266,
        "recall": 0.063095,
        "f1": 0.046688,
        "accuracy": 0.063095,
        "main_score": 0.046688,
        "hf_subset": "hau_Latn-ibo_Latn",
        "languages": [
          "hau-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.035416,
        "recall": 0.056585,
        "f1": 0.040061,
        "accuracy": 0.056585,
        "main_score": 0.040061,
        "hf_subset": "hau_Latn-nso_Latn",
        "languages": [
          "hau-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.019701,
        "recall": 0.032549,
        "f1": 0.022404,
        "accuracy": 0.032549,
        "main_score": 0.022404,
        "hf_subset": "hau_Latn-orm_Ethi",
        "languages": [
          "hau-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.019378,
        "recall": 0.03355,
        "f1": 0.022499,
        "accuracy": 0.03355,
        "main_score": 0.022499,
        "hf_subset": "hau_Latn-som_Latn",
        "languages": [
          "hau-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.023722,
        "recall": 0.038057,
        "f1": 0.026763,
        "accuracy": 0.038057,
        "main_score": 0.026763,
        "hf_subset": "hau_Latn-ssw_Latn",
        "languages": [
          "hau-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.046503,
        "recall": 0.067101,
        "f1": 0.051394,
        "accuracy": 0.067101,
        "main_score": 0.051394,
        "hf_subset": "hau_Latn-swa_Latn",
        "languages": [
          "hau-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002629,
        "recall": 0.003505,
        "f1": 0.002705,
        "accuracy": 0.003505,
        "main_score": 0.002705,
        "hf_subset": "hau_Latn-tir_Ethi",
        "languages": [
          "hau-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.040868,
        "recall": 0.065598,
        "f1": 0.046297,
        "accuracy": 0.065598,
        "main_score": 0.046297,
        "hf_subset": "hau_Latn-tsn_Latn",
        "languages": [
          "hau-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.022636,
        "recall": 0.038558,
        "f1": 0.02565,
        "accuracy": 0.038558,
        "main_score": 0.02565,
        "hf_subset": "hau_Latn-wol_Latn",
        "languages": [
          "hau-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.014626,
        "recall": 0.028042,
        "f1": 0.01733,
        "accuracy": 0.028042,
        "main_score": 0.01733,
        "hf_subset": "hau_Latn-xho_Latn",
        "languages": [
          "hau-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.01039,
        "recall": 0.026039,
        "f1": 0.01315,
        "accuracy": 0.026039,
        "main_score": 0.01315,
        "hf_subset": "hau_Latn-yor_Latn",
        "languages": [
          "hau-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.017345,
        "recall": 0.032048,
        "f1": 0.020259,
        "accuracy": 0.032048,
        "main_score": 0.020259,
        "hf_subset": "hau_Latn-zul_Latn",
        "languages": [
          "hau-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.007522,
        "recall": 0.009514,
        "f1": 0.007926,
        "accuracy": 0.009514,
        "main_score": 0.007926,
        "hf_subset": "heb_Hebr-arb_Arab",
        "languages": [
          "heb-Hebr",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.005152,
        "recall": 0.011017,
        "f1": 0.006118,
        "accuracy": 0.011017,
        "main_score": 0.006118,
        "hf_subset": "heb_Hebr-ben_Beng",
        "languages": [
          "heb-Hebr",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.000779,
        "recall": 0.001502,
        "f1": 0.000887,
        "accuracy": 0.001502,
        "main_score": 0.000887,
        "hf_subset": "heb_Hebr-ckb_Arab",
        "languages": [
          "heb-Hebr",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.012331,
        "recall": 0.016024,
        "f1": 0.01315,
        "accuracy": 0.016024,
        "main_score": 0.01315,
        "hf_subset": "heb_Hebr-deu_Latn",
        "languages": [
          "heb-Hebr",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.006423,
        "recall": 0.008513,
        "f1": 0.006821,
        "accuracy": 0.008513,
        "main_score": 0.006821,
        "hf_subset": "heb_Hebr-ell_Grek",
        "languages": [
          "heb-Hebr",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.016644,
        "recall": 0.021532,
        "f1": 0.017656,
        "accuracy": 0.021532,
        "main_score": 0.017656,
        "hf_subset": "heb_Hebr-eng_Latn",
        "languages": [
          "heb-Hebr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.0058,
        "recall": 0.007511,
        "f1": 0.006088,
        "accuracy": 0.007511,
        "main_score": 0.006088,
        "hf_subset": "heb_Hebr-fas_Arab",
        "languages": [
          "heb-Hebr",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.009604,
        "recall": 0.01352,
        "f1": 0.010468,
        "accuracy": 0.01352,
        "main_score": 0.010468,
        "hf_subset": "heb_Hebr-fin_Latn",
        "languages": [
          "heb-Hebr",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.008237,
        "recall": 0.012519,
        "f1": 0.009014,
        "accuracy": 0.012519,
        "main_score": 0.009014,
        "hf_subset": "heb_Hebr-fra_Latn",
        "languages": [
          "heb-Hebr",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.006116,
        "recall": 0.011017,
        "f1": 0.006963,
        "accuracy": 0.011017,
        "main_score": 0.006963,
        "hf_subset": "heb_Hebr-hin_Deva",
        "languages": [
          "heb-Hebr",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012924,
        "recall": 0.017026,
        "f1": 0.014063,
        "accuracy": 0.017026,
        "main_score": 0.014063,
        "hf_subset": "heb_Hebr-hun_Latn",
        "languages": [
          "heb-Hebr",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.012505,
        "recall": 0.015023,
        "f1": 0.013106,
        "accuracy": 0.015023,
        "main_score": 0.013106,
        "hf_subset": "heb_Hebr-ind_Latn",
        "languages": [
          "heb-Hebr",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.006104,
        "recall": 0.011017,
        "f1": 0.006916,
        "accuracy": 0.011017,
        "main_score": 0.006916,
        "hf_subset": "heb_Hebr-jpn_Jpan",
        "languages": [
          "heb-Hebr",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.006345,
        "recall": 0.01302,
        "f1": 0.007498,
        "accuracy": 0.01302,
        "main_score": 0.007498,
        "hf_subset": "heb_Hebr-kmr_Latn",
        "languages": [
          "heb-Hebr",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.007262,
        "recall": 0.011017,
        "f1": 0.008053,
        "accuracy": 0.011017,
        "main_score": 0.008053,
        "hf_subset": "heb_Hebr-kor_Hang",
        "languages": [
          "heb-Hebr",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.008406,
        "recall": 0.012018,
        "f1": 0.009275,
        "accuracy": 0.012018,
        "main_score": 0.009275,
        "hf_subset": "heb_Hebr-lit_Latn",
        "languages": [
          "heb-Hebr",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.004816,
        "recall": 0.007511,
        "f1": 0.005371,
        "accuracy": 0.007511,
        "main_score": 0.005371,
        "hf_subset": "heb_Hebr-mey_Arab",
        "languages": [
          "heb-Hebr",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.007382,
        "recall": 0.010516,
        "f1": 0.008157,
        "accuracy": 0.010516,
        "main_score": 0.008157,
        "hf_subset": "heb_Hebr-nld_Latn",
        "languages": [
          "heb-Hebr",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.008844,
        "recall": 0.01352,
        "f1": 0.009675,
        "accuracy": 0.01352,
        "main_score": 0.009675,
        "hf_subset": "heb_Hebr-pol_Latn",
        "languages": [
          "heb-Hebr",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.010509,
        "recall": 0.014522,
        "f1": 0.011201,
        "accuracy": 0.014522,
        "main_score": 0.011201,
        "hf_subset": "heb_Hebr-por_Latn",
        "languages": [
          "heb-Hebr",
          "por-Latn"
        ]
      },
      {
        "precision": 0.008807,
        "recall": 0.011517,
        "f1": 0.009327,
        "accuracy": 0.011517,
        "main_score": 0.009327,
        "hf_subset": "heb_Hebr-prs_Arab",
        "languages": [
          "heb-Hebr",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.005268,
        "recall": 0.008012,
        "f1": 0.005825,
        "accuracy": 0.008012,
        "main_score": 0.005825,
        "hf_subset": "heb_Hebr-pus_Arab",
        "languages": [
          "heb-Hebr",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.007868,
        "recall": 0.012519,
        "f1": 0.008826,
        "accuracy": 0.012519,
        "main_score": 0.008826,
        "hf_subset": "heb_Hebr-rus_Cyrl",
        "languages": [
          "heb-Hebr",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.005677,
        "recall": 0.009014,
        "f1": 0.006414,
        "accuracy": 0.009014,
        "main_score": 0.006414,
        "hf_subset": "heb_Hebr-shi_Arab",
        "languages": [
          "heb-Hebr",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.012477,
        "recall": 0.015023,
        "f1": 0.013089,
        "accuracy": 0.015023,
        "main_score": 0.013089,
        "hf_subset": "heb_Hebr-spa_Latn",
        "languages": [
          "heb-Hebr",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.013585,
        "recall": 0.017526,
        "f1": 0.014575,
        "accuracy": 0.017526,
        "main_score": 0.014575,
        "hf_subset": "heb_Hebr-swa_Latn",
        "languages": [
          "heb-Hebr",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.010727,
        "recall": 0.016024,
        "f1": 0.01213,
        "accuracy": 0.016024,
        "main_score": 0.01213,
        "hf_subset": "heb_Hebr-swe_Latn",
        "languages": [
          "heb-Hebr",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00341,
        "recall": 0.005508,
        "f1": 0.003828,
        "accuracy": 0.005508,
        "main_score": 0.003828,
        "hf_subset": "heb_Hebr-tam_Taml",
        "languages": [
          "heb-Hebr",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002636,
        "recall": 0.006009,
        "f1": 0.003201,
        "accuracy": 0.006009,
        "main_score": 0.003201,
        "hf_subset": "heb_Hebr-tgk_Cyrl",
        "languages": [
          "heb-Hebr",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.012731,
        "recall": 0.016525,
        "f1": 0.013671,
        "accuracy": 0.016525,
        "main_score": 0.013671,
        "hf_subset": "heb_Hebr-tur_Latn",
        "languages": [
          "heb-Hebr",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.011485,
        "recall": 0.015523,
        "f1": 0.012417,
        "accuracy": 0.015523,
        "main_score": 0.012417,
        "hf_subset": "heb_Hebr-vie_Latn",
        "languages": [
          "heb-Hebr",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.009573,
        "recall": 0.011517,
        "f1": 0.010048,
        "accuracy": 0.011517,
        "main_score": 0.010048,
        "hf_subset": "heb_Hebr-zho_Hant",
        "languages": [
          "heb-Hebr",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006244,
        "recall": 0.010015,
        "f1": 0.007005,
        "accuracy": 0.010015,
        "main_score": 0.007005,
        "hf_subset": "heb_Hebr-zul_Latn",
        "languages": [
          "heb-Hebr",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.009932,
        "recall": 0.017026,
        "f1": 0.011513,
        "accuracy": 0.017026,
        "main_score": 0.011513,
        "hf_subset": "hin_Deva-arb_Arab",
        "languages": [
          "hin-Deva",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.006966,
        "recall": 0.01302,
        "f1": 0.008061,
        "accuracy": 0.01302,
        "main_score": 0.008061,
        "hf_subset": "hin_Deva-ben_Beng",
        "languages": [
          "hin-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.013804,
        "recall": 0.02654,
        "f1": 0.016294,
        "accuracy": 0.02654,
        "main_score": 0.016294,
        "hf_subset": "hin_Deva-deu_Latn",
        "languages": [
          "hin-Deva",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.003093,
        "recall": 0.00651,
        "f1": 0.003774,
        "accuracy": 0.00651,
        "main_score": 0.003774,
        "hf_subset": "hin_Deva-div_Thaa",
        "languages": [
          "hin-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.008263,
        "recall": 0.017526,
        "f1": 0.009949,
        "accuracy": 0.017526,
        "main_score": 0.009949,
        "hf_subset": "hin_Deva-ell_Grek",
        "languages": [
          "hin-Deva",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.019416,
        "recall": 0.034051,
        "f1": 0.022101,
        "accuracy": 0.034051,
        "main_score": 0.022101,
        "hf_subset": "hin_Deva-eng_Latn",
        "languages": [
          "hin-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010617,
        "recall": 0.022033,
        "f1": 0.012692,
        "accuracy": 0.022033,
        "main_score": 0.012692,
        "hf_subset": "hin_Deva-eus_Latn",
        "languages": [
          "hin-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.013402,
        "recall": 0.021032,
        "f1": 0.014828,
        "accuracy": 0.021032,
        "main_score": 0.014828,
        "hf_subset": "hin_Deva-fas_Arab",
        "languages": [
          "hin-Deva",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.009469,
        "recall": 0.017026,
        "f1": 0.011244,
        "accuracy": 0.017026,
        "main_score": 0.011244,
        "hf_subset": "hin_Deva-fin_Latn",
        "languages": [
          "hin-Deva",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.011521,
        "recall": 0.019029,
        "f1": 0.013201,
        "accuracy": 0.019029,
        "main_score": 0.013201,
        "hf_subset": "hin_Deva-fra_Latn",
        "languages": [
          "hin-Deva",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005357,
        "recall": 0.009014,
        "f1": 0.005989,
        "accuracy": 0.009014,
        "main_score": 0.005989,
        "hf_subset": "hin_Deva-guj_Gujr",
        "languages": [
          "hin-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.006245,
        "recall": 0.014522,
        "f1": 0.00767,
        "accuracy": 0.014522,
        "main_score": 0.00767,
        "hf_subset": "hin_Deva-heb_Hebr",
        "languages": [
          "hin-Deva",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.010219,
        "recall": 0.017526,
        "f1": 0.011589,
        "accuracy": 0.017526,
        "main_score": 0.011589,
        "hf_subset": "hin_Deva-hun_Latn",
        "languages": [
          "hin-Deva",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.021815,
        "recall": 0.03355,
        "f1": 0.023894,
        "accuracy": 0.03355,
        "main_score": 0.023894,
        "hf_subset": "hin_Deva-ind_Latn",
        "languages": [
          "hin-Deva",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.008045,
        "recall": 0.01352,
        "f1": 0.009077,
        "accuracy": 0.01352,
        "main_score": 0.009077,
        "hf_subset": "hin_Deva-jpn_Jpan",
        "languages": [
          "hin-Deva",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.010346,
        "recall": 0.015023,
        "f1": 0.010977,
        "accuracy": 0.015023,
        "main_score": 0.010977,
        "hf_subset": "hin_Deva-kan_Knda",
        "languages": [
          "hin-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.00952,
        "recall": 0.018027,
        "f1": 0.011018,
        "accuracy": 0.018027,
        "main_score": 0.011018,
        "hf_subset": "hin_Deva-kor_Hang",
        "languages": [
          "hin-Deva",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.009819,
        "recall": 0.015523,
        "f1": 0.01097,
        "accuracy": 0.015523,
        "main_score": 0.01097,
        "hf_subset": "hin_Deva-lit_Latn",
        "languages": [
          "hin-Deva",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.03995,
        "recall": 0.0666,
        "f1": 0.046112,
        "accuracy": 0.0666,
        "main_score": 0.046112,
        "hf_subset": "hin_Deva-mar_Deva",
        "languages": [
          "hin-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.066561,
        "recall": 0.104657,
        "f1": 0.075456,
        "accuracy": 0.104657,
        "main_score": 0.075456,
        "hf_subset": "hin_Deva-nep_Deva",
        "languages": [
          "hin-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.01369,
        "recall": 0.022534,
        "f1": 0.015183,
        "accuracy": 0.022534,
        "main_score": 0.015183,
        "hf_subset": "hin_Deva-nld_Latn",
        "languages": [
          "hin-Deva",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.011587,
        "recall": 0.020531,
        "f1": 0.013214,
        "accuracy": 0.020531,
        "main_score": 0.013214,
        "hf_subset": "hin_Deva-pan_Guru",
        "languages": [
          "hin-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.005893,
        "recall": 0.010516,
        "f1": 0.00666,
        "accuracy": 0.010516,
        "main_score": 0.00666,
        "hf_subset": "hin_Deva-pol_Latn",
        "languages": [
          "hin-Deva",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.013409,
        "recall": 0.024537,
        "f1": 0.015529,
        "accuracy": 0.024537,
        "main_score": 0.015529,
        "hf_subset": "hin_Deva-por_Latn",
        "languages": [
          "hin-Deva",
          "por-Latn"
        ]
      },
      {
        "precision": 0.010304,
        "recall": 0.019529,
        "f1": 0.011892,
        "accuracy": 0.019529,
        "main_score": 0.011892,
        "hf_subset": "hin_Deva-rus_Cyrl",
        "languages": [
          "hin-Deva",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.005846,
        "recall": 0.012018,
        "f1": 0.00675,
        "accuracy": 0.012018,
        "main_score": 0.00675,
        "hf_subset": "hin_Deva-sin_Sinh",
        "languages": [
          "hin-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.003825,
        "recall": 0.007011,
        "f1": 0.004562,
        "accuracy": 0.007011,
        "main_score": 0.004562,
        "hf_subset": "hin_Deva-snd_Arab",
        "languages": [
          "hin-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.012934,
        "recall": 0.024036,
        "f1": 0.015121,
        "accuracy": 0.024036,
        "main_score": 0.015121,
        "hf_subset": "hin_Deva-spa_Latn",
        "languages": [
          "hin-Deva",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.021238,
        "recall": 0.034051,
        "f1": 0.023723,
        "accuracy": 0.034051,
        "main_score": 0.023723,
        "hf_subset": "hin_Deva-swa_Latn",
        "languages": [
          "hin-Deva",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.014517,
        "recall": 0.022033,
        "f1": 0.016473,
        "accuracy": 0.022033,
        "main_score": 0.016473,
        "hf_subset": "hin_Deva-swe_Latn",
        "languages": [
          "hin-Deva",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.005725,
        "recall": 0.009514,
        "f1": 0.006479,
        "accuracy": 0.009514,
        "main_score": 0.006479,
        "hf_subset": "hin_Deva-tam_Taml",
        "languages": [
          "hin-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010063,
        "recall": 0.017526,
        "f1": 0.011294,
        "accuracy": 0.017526,
        "main_score": 0.011294,
        "hf_subset": "hin_Deva-tel_Telu",
        "languages": [
          "hin-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.015888,
        "recall": 0.024537,
        "f1": 0.017986,
        "accuracy": 0.024537,
        "main_score": 0.017986,
        "hf_subset": "hin_Deva-tur_Latn",
        "languages": [
          "hin-Deva",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.017991,
        "recall": 0.024537,
        "f1": 0.019533,
        "accuracy": 0.024537,
        "main_score": 0.019533,
        "hf_subset": "hin_Deva-urd_Arab",
        "languages": [
          "hin-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.013239,
        "recall": 0.019529,
        "f1": 0.014417,
        "accuracy": 0.019529,
        "main_score": 0.014417,
        "hf_subset": "hin_Deva-vie_Latn",
        "languages": [
          "hin-Deva",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.013907,
        "recall": 0.02003,
        "f1": 0.015414,
        "accuracy": 0.02003,
        "main_score": 0.015414,
        "hf_subset": "hin_Deva-zho_Hant",
        "languages": [
          "hin-Deva",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006492,
        "recall": 0.01302,
        "f1": 0.007601,
        "accuracy": 0.01302,
        "main_score": 0.007601,
        "hf_subset": "hin_Deva-zul_Latn",
        "languages": [
          "hin-Deva",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.016191,
        "recall": 0.021532,
        "f1": 0.017386,
        "accuracy": 0.021532,
        "main_score": 0.017386,
        "hf_subset": "hmn_Latn-eng_Latn",
        "languages": [
          "hmn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010021,
        "recall": 0.018027,
        "f1": 0.01128,
        "accuracy": 0.018027,
        "main_score": 0.01128,
        "hf_subset": "hrv_Latn-bel_Cyrl",
        "languages": [
          "hrv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.23701,
        "recall": 0.312469,
        "f1": 0.25783,
        "accuracy": 0.312469,
        "main_score": 0.25783,
        "hf_subset": "hrv_Latn-bos_Latn",
        "languages": [
          "hrv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.020715,
        "recall": 0.037056,
        "f1": 0.024346,
        "accuracy": 0.037056,
        "main_score": 0.024346,
        "hf_subset": "hrv_Latn-bul_Cyrl",
        "languages": [
          "hrv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.043625,
        "recall": 0.072609,
        "f1": 0.050353,
        "accuracy": 0.072609,
        "main_score": 0.050353,
        "hf_subset": "hrv_Latn-ces_Latn",
        "languages": [
          "hrv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.034408,
        "recall": 0.057586,
        "f1": 0.039469,
        "accuracy": 0.057586,
        "main_score": 0.039469,
        "hf_subset": "hrv_Latn-eng_Latn",
        "languages": [
          "hrv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016055,
        "recall": 0.029044,
        "f1": 0.01871,
        "accuracy": 0.029044,
        "main_score": 0.01871,
        "hf_subset": "hrv_Latn-mkd_Cyrl",
        "languages": [
          "hrv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.026219,
        "recall": 0.043565,
        "f1": 0.030293,
        "accuracy": 0.043565,
        "main_score": 0.030293,
        "hf_subset": "hrv_Latn-pol_Latn",
        "languages": [
          "hrv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.017187,
        "recall": 0.030045,
        "f1": 0.019711,
        "accuracy": 0.030045,
        "main_score": 0.019711,
        "hf_subset": "hrv_Latn-rus_Cyrl",
        "languages": [
          "hrv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.033302,
        "recall": 0.06009,
        "f1": 0.038989,
        "accuracy": 0.06009,
        "main_score": 0.038989,
        "hf_subset": "hrv_Latn-slk_Latn",
        "languages": [
          "hrv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.061926,
        "recall": 0.092138,
        "f1": 0.069513,
        "accuracy": 0.092138,
        "main_score": 0.069513,
        "hf_subset": "hrv_Latn-slv_Latn",
        "languages": [
          "hrv-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.009039,
        "recall": 0.019029,
        "f1": 0.010808,
        "accuracy": 0.019029,
        "main_score": 0.010808,
        "hf_subset": "hrv_Latn-srp_Cyrl",
        "languages": [
          "hrv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.152944,
        "recall": 0.208312,
        "f1": 0.16777,
        "accuracy": 0.208312,
        "main_score": 0.16777,
        "hf_subset": "hrv_Latn-srp_Latn",
        "languages": [
          "hrv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.013393,
        "recall": 0.024036,
        "f1": 0.015618,
        "accuracy": 0.024036,
        "main_score": 0.015618,
        "hf_subset": "hrv_Latn-ukr_Cyrl",
        "languages": [
          "hrv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.007475,
        "recall": 0.016525,
        "f1": 0.009075,
        "accuracy": 0.016525,
        "main_score": 0.009075,
        "hf_subset": "hun_Latn-arb_Arab",
        "languages": [
          "hun-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00206,
        "recall": 0.005508,
        "f1": 0.002374,
        "accuracy": 0.005508,
        "main_score": 0.002374,
        "hf_subset": "hun_Latn-ben_Beng",
        "languages": [
          "hun-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.038668,
        "recall": 0.065098,
        "f1": 0.044608,
        "accuracy": 0.065098,
        "main_score": 0.044608,
        "hf_subset": "hun_Latn-deu_Latn",
        "languages": [
          "hun-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.0076,
        "recall": 0.018027,
        "f1": 0.009305,
        "accuracy": 0.018027,
        "main_score": 0.009305,
        "hf_subset": "hun_Latn-ell_Grek",
        "languages": [
          "hun-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.033285,
        "recall": 0.05308,
        "f1": 0.037702,
        "accuracy": 0.05308,
        "main_score": 0.037702,
        "hf_subset": "hun_Latn-eng_Latn",
        "languages": [
          "hun-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015224,
        "recall": 0.031547,
        "f1": 0.018199,
        "accuracy": 0.031547,
        "main_score": 0.018199,
        "hf_subset": "hun_Latn-fas_Arab",
        "languages": [
          "hun-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.028031,
        "recall": 0.050075,
        "f1": 0.032501,
        "accuracy": 0.050075,
        "main_score": 0.032501,
        "hf_subset": "hun_Latn-fin_Latn",
        "languages": [
          "hun-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.011813,
        "recall": 0.021032,
        "f1": 0.013439,
        "accuracy": 0.021032,
        "main_score": 0.013439,
        "hf_subset": "hun_Latn-fra_Latn",
        "languages": [
          "hun-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.003419,
        "recall": 0.012018,
        "f1": 0.004633,
        "accuracy": 0.012018,
        "main_score": 0.004633,
        "hf_subset": "hun_Latn-heb_Hebr",
        "languages": [
          "hun-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.007256,
        "recall": 0.01302,
        "f1": 0.00808,
        "accuracy": 0.01302,
        "main_score": 0.00808,
        "hf_subset": "hun_Latn-hin_Deva",
        "languages": [
          "hun-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.043408,
        "recall": 0.069104,
        "f1": 0.048834,
        "accuracy": 0.069104,
        "main_score": 0.048834,
        "hf_subset": "hun_Latn-ind_Latn",
        "languages": [
          "hun-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.005104,
        "recall": 0.010015,
        "f1": 0.005739,
        "accuracy": 0.010015,
        "main_score": 0.005739,
        "hf_subset": "hun_Latn-jpn_Jpan",
        "languages": [
          "hun-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.007544,
        "recall": 0.016525,
        "f1": 0.008944,
        "accuracy": 0.016525,
        "main_score": 0.008944,
        "hf_subset": "hun_Latn-kor_Hang",
        "languages": [
          "hun-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.03269,
        "recall": 0.050576,
        "f1": 0.037246,
        "accuracy": 0.050576,
        "main_score": 0.037246,
        "hf_subset": "hun_Latn-lav_Latn",
        "languages": [
          "hun-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.029351,
        "recall": 0.047071,
        "f1": 0.03338,
        "accuracy": 0.047071,
        "main_score": 0.03338,
        "hf_subset": "hun_Latn-lit_Latn",
        "languages": [
          "hun-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.029768,
        "recall": 0.045068,
        "f1": 0.03319,
        "accuracy": 0.045068,
        "main_score": 0.03319,
        "hf_subset": "hun_Latn-nld_Latn",
        "languages": [
          "hun-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.019517,
        "recall": 0.035053,
        "f1": 0.022555,
        "accuracy": 0.035053,
        "main_score": 0.022555,
        "hf_subset": "hun_Latn-pol_Latn",
        "languages": [
          "hun-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.030713,
        "recall": 0.050075,
        "f1": 0.03468,
        "accuracy": 0.050075,
        "main_score": 0.03468,
        "hf_subset": "hun_Latn-por_Latn",
        "languages": [
          "hun-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.016075,
        "recall": 0.031547,
        "f1": 0.019043,
        "accuracy": 0.031547,
        "main_score": 0.019043,
        "hf_subset": "hun_Latn-rus_Cyrl",
        "languages": [
          "hun-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.036832,
        "recall": 0.058588,
        "f1": 0.041916,
        "accuracy": 0.058588,
        "main_score": 0.041916,
        "hf_subset": "hun_Latn-spa_Latn",
        "languages": [
          "hun-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.027019,
        "recall": 0.047571,
        "f1": 0.031318,
        "accuracy": 0.047571,
        "main_score": 0.031318,
        "hf_subset": "hun_Latn-swa_Latn",
        "languages": [
          "hun-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.034748,
        "recall": 0.058588,
        "f1": 0.040506,
        "accuracy": 0.058588,
        "main_score": 0.040506,
        "hf_subset": "hun_Latn-swe_Latn",
        "languages": [
          "hun-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002013,
        "recall": 0.003005,
        "f1": 0.002022,
        "accuracy": 0.003005,
        "main_score": 0.002022,
        "hf_subset": "hun_Latn-tam_Taml",
        "languages": [
          "hun-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.028594,
        "recall": 0.047571,
        "f1": 0.032557,
        "accuracy": 0.047571,
        "main_score": 0.032557,
        "hf_subset": "hun_Latn-tur_Latn",
        "languages": [
          "hun-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.039102,
        "recall": 0.065098,
        "f1": 0.044722,
        "accuracy": 0.065098,
        "main_score": 0.044722,
        "hf_subset": "hun_Latn-vie_Latn",
        "languages": [
          "hun-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.010368,
        "recall": 0.022033,
        "f1": 0.01216,
        "accuracy": 0.022033,
        "main_score": 0.01216,
        "hf_subset": "hun_Latn-zho_Hant",
        "languages": [
          "hun-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.010939,
        "recall": 0.024036,
        "f1": 0.013113,
        "accuracy": 0.024036,
        "main_score": 0.013113,
        "hf_subset": "hun_Latn-zul_Latn",
        "languages": [
          "hun-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002052,
        "recall": 0.005508,
        "f1": 0.002264,
        "accuracy": 0.005508,
        "main_score": 0.002264,
        "hf_subset": "hye_Armn-ell_Grek",
        "languages": [
          "hye-Armn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001281,
        "recall": 0.003505,
        "f1": 0.001393,
        "accuracy": 0.003505,
        "main_score": 0.001393,
        "hf_subset": "hye_Armn-eng_Latn",
        "languages": [
          "hye-Armn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.039344,
        "recall": 0.061592,
        "f1": 0.04359,
        "accuracy": 0.061592,
        "main_score": 0.04359,
        "hf_subset": "hye_Armn-kat_Geor",
        "languages": [
          "hye-Armn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.001729,
        "recall": 0.003505,
        "f1": 0.001866,
        "accuracy": 0.003505,
        "main_score": 0.001866,
        "hf_subset": "hye_Armn-sqi_Latn",
        "languages": [
          "hye-Armn",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "ibo_Latn-amh_Ethi",
        "languages": [
          "ibo-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.039302,
        "recall": 0.048573,
        "f1": 0.04149,
        "accuracy": 0.048573,
        "main_score": 0.04149,
        "hf_subset": "ibo_Latn-eng_Latn",
        "languages": [
          "ibo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.029387,
        "recall": 0.04006,
        "f1": 0.031704,
        "accuracy": 0.04006,
        "main_score": 0.031704,
        "hf_subset": "ibo_Latn-hau_Latn",
        "languages": [
          "ibo-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.035985,
        "recall": 0.051577,
        "f1": 0.039576,
        "accuracy": 0.051577,
        "main_score": 0.039576,
        "hf_subset": "ibo_Latn-nso_Latn",
        "languages": [
          "ibo-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.017011,
        "recall": 0.026039,
        "f1": 0.018921,
        "accuracy": 0.026039,
        "main_score": 0.018921,
        "hf_subset": "ibo_Latn-orm_Ethi",
        "languages": [
          "ibo-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.012822,
        "recall": 0.023035,
        "f1": 0.014619,
        "accuracy": 0.023035,
        "main_score": 0.014619,
        "hf_subset": "ibo_Latn-som_Latn",
        "languages": [
          "ibo-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.018109,
        "recall": 0.029044,
        "f1": 0.020396,
        "accuracy": 0.029044,
        "main_score": 0.020396,
        "hf_subset": "ibo_Latn-ssw_Latn",
        "languages": [
          "ibo-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.033561,
        "recall": 0.046069,
        "f1": 0.036242,
        "accuracy": 0.046069,
        "main_score": 0.036242,
        "hf_subset": "ibo_Latn-swa_Latn",
        "languages": [
          "ibo-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001669,
        "recall": 0.002504,
        "f1": 0.001753,
        "accuracy": 0.002504,
        "main_score": 0.001753,
        "hf_subset": "ibo_Latn-tir_Ethi",
        "languages": [
          "ibo-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.044081,
        "recall": 0.061092,
        "f1": 0.047701,
        "accuracy": 0.061092,
        "main_score": 0.047701,
        "hf_subset": "ibo_Latn-tsn_Latn",
        "languages": [
          "ibo-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.012188,
        "recall": 0.021032,
        "f1": 0.01402,
        "accuracy": 0.021032,
        "main_score": 0.01402,
        "hf_subset": "ibo_Latn-wol_Latn",
        "languages": [
          "ibo-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.01245,
        "recall": 0.019029,
        "f1": 0.013858,
        "accuracy": 0.019029,
        "main_score": 0.013858,
        "hf_subset": "ibo_Latn-xho_Latn",
        "languages": [
          "ibo-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.009006,
        "recall": 0.017526,
        "f1": 0.010411,
        "accuracy": 0.017526,
        "main_score": 0.010411,
        "hf_subset": "ibo_Latn-yor_Latn",
        "languages": [
          "ibo-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.012352,
        "recall": 0.022033,
        "f1": 0.014374,
        "accuracy": 0.022033,
        "main_score": 0.014374,
        "hf_subset": "ibo_Latn-zul_Latn",
        "languages": [
          "ibo-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.007698,
        "recall": 0.016024,
        "f1": 0.009118,
        "accuracy": 0.016024,
        "main_score": 0.009118,
        "hf_subset": "ind_Latn-arb_Arab",
        "languages": [
          "ind-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001855,
        "recall": 0.004006,
        "f1": 0.00203,
        "accuracy": 0.004006,
        "main_score": 0.00203,
        "hf_subset": "ind_Latn-ben_Beng",
        "languages": [
          "ind-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.050811,
        "recall": 0.072609,
        "f1": 0.056096,
        "accuracy": 0.072609,
        "main_score": 0.056096,
        "hf_subset": "ind_Latn-deu_Latn",
        "languages": [
          "ind-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.008486,
        "recall": 0.019529,
        "f1": 0.010468,
        "accuracy": 0.019529,
        "main_score": 0.010468,
        "hf_subset": "ind_Latn-ell_Grek",
        "languages": [
          "ind-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.086047,
        "recall": 0.122183,
        "f1": 0.095336,
        "accuracy": 0.122183,
        "main_score": 0.095336,
        "hf_subset": "ind_Latn-eng_Latn",
        "languages": [
          "ind-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026707,
        "recall": 0.05358,
        "f1": 0.032226,
        "accuracy": 0.05358,
        "main_score": 0.032226,
        "hf_subset": "ind_Latn-fas_Arab",
        "languages": [
          "ind-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.055317,
        "recall": 0.087631,
        "f1": 0.063246,
        "accuracy": 0.087631,
        "main_score": 0.063246,
        "hf_subset": "ind_Latn-fij_Latn",
        "languages": [
          "ind-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.068793,
        "recall": 0.101652,
        "f1": 0.077097,
        "accuracy": 0.101652,
        "main_score": 0.077097,
        "hf_subset": "ind_Latn-fil_Latn",
        "languages": [
          "ind-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.030696,
        "recall": 0.055583,
        "f1": 0.036006,
        "accuracy": 0.055583,
        "main_score": 0.036006,
        "hf_subset": "ind_Latn-fin_Latn",
        "languages": [
          "ind-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.00979,
        "recall": 0.019529,
        "f1": 0.011356,
        "accuracy": 0.019529,
        "main_score": 0.011356,
        "hf_subset": "ind_Latn-fra_Latn",
        "languages": [
          "ind-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005567,
        "recall": 0.01302,
        "f1": 0.006765,
        "accuracy": 0.01302,
        "main_score": 0.006765,
        "hf_subset": "ind_Latn-heb_Hebr",
        "languages": [
          "ind-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00748,
        "recall": 0.018528,
        "f1": 0.009248,
        "accuracy": 0.018528,
        "main_score": 0.009248,
        "hf_subset": "ind_Latn-hin_Deva",
        "languages": [
          "ind-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.034661,
        "recall": 0.056084,
        "f1": 0.039677,
        "accuracy": 0.056084,
        "main_score": 0.039677,
        "hf_subset": "ind_Latn-hun_Latn",
        "languages": [
          "ind-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.00343,
        "recall": 0.008513,
        "f1": 0.004164,
        "accuracy": 0.008513,
        "main_score": 0.004164,
        "hf_subset": "ind_Latn-jpn_Jpan",
        "languages": [
          "ind-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.007363,
        "recall": 0.012519,
        "f1": 0.008144,
        "accuracy": 0.012519,
        "main_score": 0.008144,
        "hf_subset": "ind_Latn-kor_Hang",
        "languages": [
          "ind-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.028802,
        "recall": 0.044567,
        "f1": 0.03224,
        "accuracy": 0.044567,
        "main_score": 0.03224,
        "hf_subset": "ind_Latn-lit_Latn",
        "languages": [
          "ind-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.001505,
        "recall": 0.002504,
        "f1": 0.001507,
        "accuracy": 0.002504,
        "main_score": 0.001507,
        "hf_subset": "ind_Latn-mal_Mlym",
        "languages": [
          "ind-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.03047,
        "recall": 0.052078,
        "f1": 0.035005,
        "accuracy": 0.052078,
        "main_score": 0.035005,
        "hf_subset": "ind_Latn-mlg_Latn",
        "languages": [
          "ind-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.05855,
        "recall": 0.085628,
        "f1": 0.065075,
        "accuracy": 0.085628,
        "main_score": 0.065075,
        "hf_subset": "ind_Latn-mri_Latn",
        "languages": [
          "ind-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.143708,
        "recall": 0.192789,
        "f1": 0.157191,
        "accuracy": 0.192789,
        "main_score": 0.157191,
        "hf_subset": "ind_Latn-msa_Latn",
        "languages": [
          "ind-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.049578,
        "recall": 0.077116,
        "f1": 0.055783,
        "accuracy": 0.077116,
        "main_score": 0.055783,
        "hf_subset": "ind_Latn-nld_Latn",
        "languages": [
          "ind-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.015483,
        "recall": 0.030045,
        "f1": 0.017668,
        "accuracy": 0.030045,
        "main_score": 0.017668,
        "hf_subset": "ind_Latn-pol_Latn",
        "languages": [
          "ind-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.032928,
        "recall": 0.05358,
        "f1": 0.037068,
        "accuracy": 0.05358,
        "main_score": 0.037068,
        "hf_subset": "ind_Latn-por_Latn",
        "languages": [
          "ind-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.013122,
        "recall": 0.027041,
        "f1": 0.015091,
        "accuracy": 0.027041,
        "main_score": 0.015091,
        "hf_subset": "ind_Latn-rus_Cyrl",
        "languages": [
          "ind-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.030719,
        "recall": 0.055583,
        "f1": 0.036279,
        "accuracy": 0.055583,
        "main_score": 0.036279,
        "hf_subset": "ind_Latn-smo_Latn",
        "languages": [
          "ind-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.049677,
        "recall": 0.081622,
        "f1": 0.056604,
        "accuracy": 0.081622,
        "main_score": 0.056604,
        "hf_subset": "ind_Latn-spa_Latn",
        "languages": [
          "ind-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.063451,
        "recall": 0.095643,
        "f1": 0.07162,
        "accuracy": 0.095643,
        "main_score": 0.07162,
        "hf_subset": "ind_Latn-swa_Latn",
        "languages": [
          "ind-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.053318,
        "recall": 0.08663,
        "f1": 0.06079,
        "accuracy": 0.08663,
        "main_score": 0.06079,
        "hf_subset": "ind_Latn-swe_Latn",
        "languages": [
          "ind-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.030594,
        "recall": 0.048573,
        "f1": 0.034305,
        "accuracy": 0.048573,
        "main_score": 0.034305,
        "hf_subset": "ind_Latn-tah_Latn",
        "languages": [
          "ind-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001812,
        "recall": 0.003505,
        "f1": 0.001947,
        "accuracy": 0.003505,
        "main_score": 0.001947,
        "hf_subset": "ind_Latn-tam_Taml",
        "languages": [
          "ind-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00139,
        "recall": 0.003505,
        "f1": 0.001575,
        "accuracy": 0.003505,
        "main_score": 0.001575,
        "hf_subset": "ind_Latn-ton_Latn",
        "languages": [
          "ind-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.045232,
        "recall": 0.068603,
        "f1": 0.050541,
        "accuracy": 0.068603,
        "main_score": 0.050541,
        "hf_subset": "ind_Latn-tur_Latn",
        "languages": [
          "ind-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.069715,
        "recall": 0.106159,
        "f1": 0.078643,
        "accuracy": 0.106159,
        "main_score": 0.078643,
        "hf_subset": "ind_Latn-vie_Latn",
        "languages": [
          "ind-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.013424,
        "recall": 0.023535,
        "f1": 0.015066,
        "accuracy": 0.023535,
        "main_score": 0.015066,
        "hf_subset": "ind_Latn-zho_Hant",
        "languages": [
          "ind-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.023281,
        "recall": 0.043065,
        "f1": 0.027152,
        "accuracy": 0.043065,
        "main_score": 0.027152,
        "hf_subset": "ind_Latn-zul_Latn",
        "languages": [
          "ind-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.022077,
        "recall": 0.034552,
        "f1": 0.02472,
        "accuracy": 0.034552,
        "main_score": 0.02472,
        "hf_subset": "isl_Latn-afr_Latn",
        "languages": [
          "isl-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.030686,
        "recall": 0.043065,
        "f1": 0.033487,
        "accuracy": 0.043065,
        "main_score": 0.033487,
        "hf_subset": "isl_Latn-dan_Latn",
        "languages": [
          "isl-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.036779,
        "recall": 0.05308,
        "f1": 0.040533,
        "accuracy": 0.05308,
        "main_score": 0.040533,
        "hf_subset": "isl_Latn-deu_Latn",
        "languages": [
          "isl-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.031522,
        "recall": 0.051077,
        "f1": 0.035142,
        "accuracy": 0.051077,
        "main_score": 0.035142,
        "hf_subset": "isl_Latn-eng_Latn",
        "languages": [
          "isl-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.044259,
        "recall": 0.067101,
        "f1": 0.0498,
        "accuracy": 0.067101,
        "main_score": 0.0498,
        "hf_subset": "isl_Latn-fao_Latn",
        "languages": [
          "isl-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.025008,
        "recall": 0.038558,
        "f1": 0.028117,
        "accuracy": 0.038558,
        "main_score": 0.028117,
        "hf_subset": "isl_Latn-ltz_Latn",
        "languages": [
          "isl-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.027129,
        "recall": 0.042063,
        "f1": 0.030612,
        "accuracy": 0.042063,
        "main_score": 0.030612,
        "hf_subset": "isl_Latn-nld_Latn",
        "languages": [
          "isl-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.032094,
        "recall": 0.047571,
        "f1": 0.035928,
        "accuracy": 0.047571,
        "main_score": 0.035928,
        "hf_subset": "isl_Latn-nno_Latn",
        "languages": [
          "isl-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.0296,
        "recall": 0.043565,
        "f1": 0.032909,
        "accuracy": 0.043565,
        "main_score": 0.032909,
        "hf_subset": "isl_Latn-nob_Latn",
        "languages": [
          "isl-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.032267,
        "recall": 0.04657,
        "f1": 0.035692,
        "accuracy": 0.04657,
        "main_score": 0.035692,
        "hf_subset": "isl_Latn-swe_Latn",
        "languages": [
          "isl-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.031318,
        "recall": 0.056084,
        "f1": 0.036107,
        "accuracy": 0.056084,
        "main_score": 0.036107,
        "hf_subset": "ita_Latn-cat_Latn",
        "languages": [
          "ita-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.072678,
        "recall": 0.103655,
        "f1": 0.080338,
        "accuracy": 0.103655,
        "main_score": 0.080338,
        "hf_subset": "ita_Latn-eng_Latn",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016391,
        "recall": 0.030546,
        "f1": 0.019054,
        "accuracy": 0.030546,
        "main_score": 0.019054,
        "hf_subset": "ita_Latn-fra_Latn",
        "languages": [
          "ita-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.05896,
        "recall": 0.09314,
        "f1": 0.066526,
        "accuracy": 0.09314,
        "main_score": 0.066526,
        "hf_subset": "ita_Latn-glg_Latn",
        "languages": [
          "ita-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.007043,
        "recall": 0.015523,
        "f1": 0.008379,
        "accuracy": 0.015523,
        "main_score": 0.008379,
        "hf_subset": "ita_Latn-mlt_Latn",
        "languages": [
          "ita-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.046621,
        "recall": 0.075113,
        "f1": 0.053022,
        "accuracy": 0.075113,
        "main_score": 0.053022,
        "hf_subset": "ita_Latn-por_Latn",
        "languages": [
          "ita-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.049451,
        "recall": 0.077616,
        "f1": 0.055731,
        "accuracy": 0.077616,
        "main_score": 0.055731,
        "hf_subset": "ita_Latn-ron_Latn",
        "languages": [
          "ita-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.065036,
        "recall": 0.096645,
        "f1": 0.07285,
        "accuracy": 0.096645,
        "main_score": 0.07285,
        "hf_subset": "ita_Latn-spa_Latn",
        "languages": [
          "ita-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004983,
        "recall": 0.010015,
        "f1": 0.005939,
        "accuracy": 0.010015,
        "main_score": 0.005939,
        "hf_subset": "jpn_Jpan-arb_Arab",
        "languages": [
          "jpn-Jpan",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.004569,
        "recall": 0.008513,
        "f1": 0.005492,
        "accuracy": 0.008513,
        "main_score": 0.005492,
        "hf_subset": "jpn_Jpan-ben_Beng",
        "languages": [
          "jpn-Jpan",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.005877,
        "recall": 0.012018,
        "f1": 0.006787,
        "accuracy": 0.012018,
        "main_score": 0.006787,
        "hf_subset": "jpn_Jpan-deu_Latn",
        "languages": [
          "jpn-Jpan",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.004448,
        "recall": 0.007511,
        "f1": 0.004916,
        "accuracy": 0.007511,
        "main_score": 0.004916,
        "hf_subset": "jpn_Jpan-ell_Grek",
        "languages": [
          "jpn-Jpan",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.007378,
        "recall": 0.011517,
        "f1": 0.008219,
        "accuracy": 0.011517,
        "main_score": 0.008219,
        "hf_subset": "jpn_Jpan-eng_Latn",
        "languages": [
          "jpn-Jpan",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004252,
        "recall": 0.007011,
        "f1": 0.004778,
        "accuracy": 0.007011,
        "main_score": 0.004778,
        "hf_subset": "jpn_Jpan-fas_Arab",
        "languages": [
          "jpn-Jpan",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.003797,
        "recall": 0.00651,
        "f1": 0.004516,
        "accuracy": 0.00651,
        "main_score": 0.004516,
        "hf_subset": "jpn_Jpan-fin_Latn",
        "languages": [
          "jpn-Jpan",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.005876,
        "recall": 0.010516,
        "f1": 0.006902,
        "accuracy": 0.010516,
        "main_score": 0.006902,
        "hf_subset": "jpn_Jpan-fra_Latn",
        "languages": [
          "jpn-Jpan",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005656,
        "recall": 0.009014,
        "f1": 0.006353,
        "accuracy": 0.009014,
        "main_score": 0.006353,
        "hf_subset": "jpn_Jpan-heb_Hebr",
        "languages": [
          "jpn-Jpan",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004825,
        "recall": 0.010516,
        "f1": 0.005842,
        "accuracy": 0.010516,
        "main_score": 0.005842,
        "hf_subset": "jpn_Jpan-hin_Deva",
        "languages": [
          "jpn-Jpan",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.004435,
        "recall": 0.007511,
        "f1": 0.005082,
        "accuracy": 0.007511,
        "main_score": 0.005082,
        "hf_subset": "jpn_Jpan-hun_Latn",
        "languages": [
          "jpn-Jpan",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.00507,
        "recall": 0.011517,
        "f1": 0.006118,
        "accuracy": 0.011517,
        "main_score": 0.006118,
        "hf_subset": "jpn_Jpan-ind_Latn",
        "languages": [
          "jpn-Jpan",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.009362,
        "recall": 0.017026,
        "f1": 0.010935,
        "accuracy": 0.017026,
        "main_score": 0.010935,
        "hf_subset": "jpn_Jpan-kor_Hang",
        "languages": [
          "jpn-Jpan",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.002905,
        "recall": 0.007011,
        "f1": 0.003441,
        "accuracy": 0.007011,
        "main_score": 0.003441,
        "hf_subset": "jpn_Jpan-lit_Latn",
        "languages": [
          "jpn-Jpan",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.005677,
        "recall": 0.011017,
        "f1": 0.006682,
        "accuracy": 0.011017,
        "main_score": 0.006682,
        "hf_subset": "jpn_Jpan-nld_Latn",
        "languages": [
          "jpn-Jpan",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.003567,
        "recall": 0.008012,
        "f1": 0.004571,
        "accuracy": 0.008012,
        "main_score": 0.004571,
        "hf_subset": "jpn_Jpan-pol_Latn",
        "languages": [
          "jpn-Jpan",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.009815,
        "recall": 0.018528,
        "f1": 0.011464,
        "accuracy": 0.018528,
        "main_score": 0.011464,
        "hf_subset": "jpn_Jpan-por_Latn",
        "languages": [
          "jpn-Jpan",
          "por-Latn"
        ]
      },
      {
        "precision": 0.004615,
        "recall": 0.011017,
        "f1": 0.005466,
        "accuracy": 0.011017,
        "main_score": 0.005466,
        "hf_subset": "jpn_Jpan-rus_Cyrl",
        "languages": [
          "jpn-Jpan",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.005994,
        "recall": 0.010015,
        "f1": 0.006832,
        "accuracy": 0.010015,
        "main_score": 0.006832,
        "hf_subset": "jpn_Jpan-spa_Latn",
        "languages": [
          "jpn-Jpan",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.004845,
        "recall": 0.008513,
        "f1": 0.005684,
        "accuracy": 0.008513,
        "main_score": 0.005684,
        "hf_subset": "jpn_Jpan-swa_Latn",
        "languages": [
          "jpn-Jpan",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.006895,
        "recall": 0.012519,
        "f1": 0.008049,
        "accuracy": 0.012519,
        "main_score": 0.008049,
        "hf_subset": "jpn_Jpan-swe_Latn",
        "languages": [
          "jpn-Jpan",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.005713,
        "recall": 0.010516,
        "f1": 0.00666,
        "accuracy": 0.010516,
        "main_score": 0.00666,
        "hf_subset": "jpn_Jpan-tam_Taml",
        "languages": [
          "jpn-Jpan",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.006376,
        "recall": 0.011517,
        "f1": 0.007273,
        "accuracy": 0.011517,
        "main_score": 0.007273,
        "hf_subset": "jpn_Jpan-tur_Latn",
        "languages": [
          "jpn-Jpan",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.005888,
        "recall": 0.011017,
        "f1": 0.006932,
        "accuracy": 0.011017,
        "main_score": 0.006932,
        "hf_subset": "jpn_Jpan-vie_Latn",
        "languages": [
          "jpn-Jpan",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.017196,
        "recall": 0.027041,
        "f1": 0.019115,
        "accuracy": 0.027041,
        "main_score": 0.019115,
        "hf_subset": "jpn_Jpan-yue_Hant",
        "languages": [
          "jpn-Jpan",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.015503,
        "recall": 0.022534,
        "f1": 0.016909,
        "accuracy": 0.022534,
        "main_score": 0.016909,
        "hf_subset": "jpn_Jpan-zho_Hans",
        "languages": [
          "jpn-Jpan",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.019928,
        "recall": 0.031047,
        "f1": 0.022043,
        "accuracy": 0.031047,
        "main_score": 0.022043,
        "hf_subset": "jpn_Jpan-zho_Hant",
        "languages": [
          "jpn-Jpan",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.004532,
        "recall": 0.007011,
        "f1": 0.004972,
        "accuracy": 0.007011,
        "main_score": 0.004972,
        "hf_subset": "jpn_Jpan-zul_Latn",
        "languages": [
          "jpn-Jpan",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.005624,
        "recall": 0.012018,
        "f1": 0.006208,
        "accuracy": 0.012018,
        "main_score": 0.006208,
        "hf_subset": "kan_Knda-ben_Beng",
        "languages": [
          "kan-Knda",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.003224,
        "recall": 0.008513,
        "f1": 0.003619,
        "accuracy": 0.008513,
        "main_score": 0.003619,
        "hf_subset": "kan_Knda-div_Thaa",
        "languages": [
          "kan-Knda",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.00053,
        "recall": 0.002003,
        "f1": 0.000557,
        "accuracy": 0.002003,
        "main_score": 0.000557,
        "hf_subset": "kan_Knda-eng_Latn",
        "languages": [
          "kan-Knda",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000517,
        "recall": 0.002504,
        "f1": 0.000533,
        "accuracy": 0.002504,
        "main_score": 0.000533,
        "hf_subset": "kan_Knda-eus_Latn",
        "languages": [
          "kan-Knda",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.090248,
        "recall": 0.135704,
        "f1": 0.100431,
        "accuracy": 0.135704,
        "main_score": 0.100431,
        "hf_subset": "kan_Knda-guj_Gujr",
        "languages": [
          "kan-Knda",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.004283,
        "recall": 0.007011,
        "f1": 0.00461,
        "accuracy": 0.007011,
        "main_score": 0.00461,
        "hf_subset": "kan_Knda-hin_Deva",
        "languages": [
          "kan-Knda",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.006196,
        "recall": 0.012519,
        "f1": 0.007454,
        "accuracy": 0.012519,
        "main_score": 0.007454,
        "hf_subset": "kan_Knda-mar_Deva",
        "languages": [
          "kan-Knda",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.003379,
        "recall": 0.00651,
        "f1": 0.003814,
        "accuracy": 0.00651,
        "main_score": 0.003814,
        "hf_subset": "kan_Knda-nep_Deva",
        "languages": [
          "kan-Knda",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.003517,
        "recall": 0.006009,
        "f1": 0.003787,
        "accuracy": 0.006009,
        "main_score": 0.003787,
        "hf_subset": "kan_Knda-pan_Guru",
        "languages": [
          "kan-Knda",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.020943,
        "recall": 0.039559,
        "f1": 0.023823,
        "accuracy": 0.039559,
        "main_score": 0.023823,
        "hf_subset": "kan_Knda-sin_Sinh",
        "languages": [
          "kan-Knda",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002433,
        "recall": 0.006009,
        "f1": 0.002667,
        "accuracy": 0.006009,
        "main_score": 0.002667,
        "hf_subset": "kan_Knda-snd_Arab",
        "languages": [
          "kan-Knda",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.013265,
        "recall": 0.026039,
        "f1": 0.014919,
        "accuracy": 0.026039,
        "main_score": 0.014919,
        "hf_subset": "kan_Knda-tam_Taml",
        "languages": [
          "kan-Knda",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.006469,
        "recall": 0.015523,
        "f1": 0.007205,
        "accuracy": 0.015523,
        "main_score": 0.007205,
        "hf_subset": "kan_Knda-tel_Telu",
        "languages": [
          "kan-Knda",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.000255,
        "recall": 0.002003,
        "f1": 0.000402,
        "accuracy": 0.002003,
        "main_score": 0.000402,
        "hf_subset": "kan_Knda-urd_Arab",
        "languages": [
          "kan-Knda",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.000851,
        "recall": 0.004006,
        "f1": 0.00101,
        "accuracy": 0.004006,
        "main_score": 0.00101,
        "hf_subset": "kat_Geor-ell_Grek",
        "languages": [
          "kat-Geor",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.000302,
        "recall": 0.002003,
        "f1": 0.000429,
        "accuracy": 0.002003,
        "main_score": 0.000429,
        "hf_subset": "kat_Geor-eng_Latn",
        "languages": [
          "kat-Geor",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015322,
        "recall": 0.034051,
        "f1": 0.018029,
        "accuracy": 0.034051,
        "main_score": 0.018029,
        "hf_subset": "kat_Geor-hye_Armn",
        "languages": [
          "kat-Geor",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.001538,
        "recall": 0.003505,
        "f1": 0.001789,
        "accuracy": 0.003505,
        "main_score": 0.001789,
        "hf_subset": "kat_Geor-sqi_Latn",
        "languages": [
          "kat-Geor",
          "sqi-Latn"
        ]
      },
      {
        "precision": 0.014601,
        "recall": 0.026039,
        "f1": 0.017078,
        "accuracy": 0.026039,
        "main_score": 0.017078,
        "hf_subset": "kaz_Cyrl-aze_Latn",
        "languages": [
          "kaz-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.008332,
        "recall": 0.015023,
        "f1": 0.009528,
        "accuracy": 0.015023,
        "main_score": 0.009528,
        "hf_subset": "kaz_Cyrl-bak_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.019818,
        "recall": 0.030045,
        "f1": 0.021766,
        "accuracy": 0.030045,
        "main_score": 0.021766,
        "hf_subset": "kaz_Cyrl-eng_Latn",
        "languages": [
          "kaz-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054713,
        "recall": 0.083125,
        "f1": 0.060875,
        "accuracy": 0.083125,
        "main_score": 0.060875,
        "hf_subset": "kaz_Cyrl-kir_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.014654,
        "recall": 0.029544,
        "f1": 0.017479,
        "accuracy": 0.029544,
        "main_score": 0.017479,
        "hf_subset": "kaz_Cyrl-tat_Cyrl",
        "languages": [
          "kaz-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.007019,
        "recall": 0.014021,
        "f1": 0.008363,
        "accuracy": 0.014021,
        "main_score": 0.008363,
        "hf_subset": "kaz_Cyrl-tuk_Latn",
        "languages": [
          "kaz-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.016752,
        "recall": 0.026039,
        "f1": 0.019037,
        "accuracy": 0.026039,
        "main_score": 0.019037,
        "hf_subset": "kaz_Cyrl-tur_Latn",
        "languages": [
          "kaz-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.003171,
        "recall": 0.006009,
        "f1": 0.003662,
        "accuracy": 0.006009,
        "main_score": 0.003662,
        "hf_subset": "kaz_Cyrl-uig_Arab",
        "languages": [
          "kaz-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.00726,
        "recall": 0.01352,
        "f1": 0.008352,
        "accuracy": 0.01352,
        "main_score": 0.008352,
        "hf_subset": "kaz_Cyrl-uzb_Latn",
        "languages": [
          "kaz-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "khm_Khmr-bod_Tibt",
        "languages": [
          "khm-Khmr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "khm_Khmr-dzo_Tibt",
        "languages": [
          "khm-Khmr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.001003,
        "recall": 0.002003,
        "f1": 0.001004,
        "accuracy": 0.002003,
        "main_score": 0.001004,
        "hf_subset": "khm_Khmr-eng_Latn",
        "languages": [
          "khm-Khmr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.010847,
        "recall": 0.02003,
        "f1": 0.012199,
        "accuracy": 0.02003,
        "main_score": 0.012199,
        "hf_subset": "khm_Khmr-lao_Laoo",
        "languages": [
          "khm-Khmr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "khm_Khmr-mon_Mong",
        "languages": [
          "khm-Khmr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.00133,
        "recall": 0.003505,
        "f1": 0.001534,
        "accuracy": 0.003505,
        "main_score": 0.001534,
        "hf_subset": "khm_Khmr-mya_Mymr",
        "languages": [
          "khm-Khmr",
          "mya-Mymr"
        ]
      },
      {
        "precision": 7.5e-05,
        "recall": 0.002504,
        "f1": 0.000138,
        "accuracy": 0.002504,
        "main_score": 0.000138,
        "hf_subset": "khm_Khmr-tha_Thai",
        "languages": [
          "khm-Khmr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.025914,
        "recall": 0.042564,
        "f1": 0.02949,
        "accuracy": 0.042564,
        "main_score": 0.02949,
        "hf_subset": "kin_Latn-bem_Latn",
        "languages": [
          "kin-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.035019,
        "recall": 0.052078,
        "f1": 0.039047,
        "accuracy": 0.052078,
        "main_score": 0.039047,
        "hf_subset": "kin_Latn-eng_Latn",
        "languages": [
          "kin-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002276,
        "recall": 0.004006,
        "f1": 0.002447,
        "accuracy": 0.004006,
        "main_score": 0.002447,
        "hf_subset": "kin_Latn-ewe_Latn",
        "languages": [
          "kin-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.036176,
        "recall": 0.048573,
        "f1": 0.039475,
        "accuracy": 0.048573,
        "main_score": 0.039475,
        "hf_subset": "kin_Latn-fuc_Latn",
        "languages": [
          "kin-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.013307,
        "recall": 0.02003,
        "f1": 0.014745,
        "accuracy": 0.02003,
        "main_score": 0.014745,
        "hf_subset": "kin_Latn-nde_Latn",
        "languages": [
          "kin-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.032054,
        "recall": 0.047071,
        "f1": 0.035343,
        "accuracy": 0.047071,
        "main_score": 0.035343,
        "hf_subset": "kin_Latn-nya_Latn",
        "languages": [
          "kin-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.02863,
        "recall": 0.042063,
        "f1": 0.03191,
        "accuracy": 0.042063,
        "main_score": 0.03191,
        "hf_subset": "kin_Latn-sna_Latn",
        "languages": [
          "kin-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.034524,
        "recall": 0.047071,
        "f1": 0.037166,
        "accuracy": 0.047071,
        "main_score": 0.037166,
        "hf_subset": "kin_Latn-ven_Latn",
        "languages": [
          "kin-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.012014,
        "recall": 0.021032,
        "f1": 0.013497,
        "accuracy": 0.021032,
        "main_score": 0.013497,
        "hf_subset": "kir_Cyrl-aze_Latn",
        "languages": [
          "kir-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.013576,
        "recall": 0.027041,
        "f1": 0.015801,
        "accuracy": 0.027041,
        "main_score": 0.015801,
        "hf_subset": "kir_Cyrl-bak_Cyrl",
        "languages": [
          "kir-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.014787,
        "recall": 0.023535,
        "f1": 0.01657,
        "accuracy": 0.023535,
        "main_score": 0.01657,
        "hf_subset": "kir_Cyrl-eng_Latn",
        "languages": [
          "kir-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.050001,
        "recall": 0.079119,
        "f1": 0.056838,
        "accuracy": 0.079119,
        "main_score": 0.056838,
        "hf_subset": "kir_Cyrl-kaz_Cyrl",
        "languages": [
          "kir-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.017856,
        "recall": 0.036054,
        "f1": 0.02117,
        "accuracy": 0.036054,
        "main_score": 0.02117,
        "hf_subset": "kir_Cyrl-tat_Cyrl",
        "languages": [
          "kir-Cyrl",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.006545,
        "recall": 0.012018,
        "f1": 0.00753,
        "accuracy": 0.012018,
        "main_score": 0.00753,
        "hf_subset": "kir_Cyrl-tuk_Latn",
        "languages": [
          "kir-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.013969,
        "recall": 0.021032,
        "f1": 0.015451,
        "accuracy": 0.021032,
        "main_score": 0.015451,
        "hf_subset": "kir_Cyrl-tur_Latn",
        "languages": [
          "kir-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.004793,
        "recall": 0.011517,
        "f1": 0.005733,
        "accuracy": 0.011517,
        "main_score": 0.005733,
        "hf_subset": "kir_Cyrl-uig_Arab",
        "languages": [
          "kir-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.009592,
        "recall": 0.01352,
        "f1": 0.010268,
        "accuracy": 0.01352,
        "main_score": 0.010268,
        "hf_subset": "kir_Cyrl-uzb_Latn",
        "languages": [
          "kir-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.006433,
        "recall": 0.010516,
        "f1": 0.007311,
        "accuracy": 0.010516,
        "main_score": 0.007311,
        "hf_subset": "kmr_Latn-arb_Arab",
        "languages": [
          "kmr-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001086,
        "recall": 0.004507,
        "f1": 0.001478,
        "accuracy": 0.004507,
        "main_score": 0.001478,
        "hf_subset": "kmr_Latn-ckb_Arab",
        "languages": [
          "kmr-Latn",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.025061,
        "recall": 0.035553,
        "f1": 0.027087,
        "accuracy": 0.035553,
        "main_score": 0.027087,
        "hf_subset": "kmr_Latn-eng_Latn",
        "languages": [
          "kmr-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009105,
        "recall": 0.014522,
        "f1": 0.010061,
        "accuracy": 0.014522,
        "main_score": 0.010061,
        "hf_subset": "kmr_Latn-fas_Arab",
        "languages": [
          "kmr-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.007009,
        "recall": 0.01352,
        "f1": 0.008067,
        "accuracy": 0.01352,
        "main_score": 0.008067,
        "hf_subset": "kmr_Latn-heb_Hebr",
        "languages": [
          "kmr-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004158,
        "recall": 0.011517,
        "f1": 0.005551,
        "accuracy": 0.011517,
        "main_score": 0.005551,
        "hf_subset": "kmr_Latn-mey_Arab",
        "languages": [
          "kmr-Latn",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.011024,
        "recall": 0.018528,
        "f1": 0.012583,
        "accuracy": 0.018528,
        "main_score": 0.012583,
        "hf_subset": "kmr_Latn-prs_Arab",
        "languages": [
          "kmr-Latn",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.003161,
        "recall": 0.00651,
        "f1": 0.003564,
        "accuracy": 0.00651,
        "main_score": 0.003564,
        "hf_subset": "kmr_Latn-pus_Arab",
        "languages": [
          "kmr-Latn",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.004215,
        "recall": 0.007511,
        "f1": 0.005124,
        "accuracy": 0.007511,
        "main_score": 0.005124,
        "hf_subset": "kmr_Latn-shi_Arab",
        "languages": [
          "kmr-Latn",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.003362,
        "recall": 0.007511,
        "f1": 0.004192,
        "accuracy": 0.007511,
        "main_score": 0.004192,
        "hf_subset": "kmr_Latn-tgk_Cyrl",
        "languages": [
          "kmr-Latn",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.005646,
        "recall": 0.010516,
        "f1": 0.006541,
        "accuracy": 0.010516,
        "main_score": 0.006541,
        "hf_subset": "kor_Hang-arb_Arab",
        "languages": [
          "kor-Hang",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.004827,
        "recall": 0.007511,
        "f1": 0.005361,
        "accuracy": 0.007511,
        "main_score": 0.005361,
        "hf_subset": "kor_Hang-ben_Beng",
        "languages": [
          "kor-Hang",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.012037,
        "recall": 0.022534,
        "f1": 0.014087,
        "accuracy": 0.022534,
        "main_score": 0.014087,
        "hf_subset": "kor_Hang-deu_Latn",
        "languages": [
          "kor-Hang",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.010756,
        "recall": 0.017026,
        "f1": 0.011985,
        "accuracy": 0.017026,
        "main_score": 0.011985,
        "hf_subset": "kor_Hang-ell_Grek",
        "languages": [
          "kor-Hang",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.020119,
        "recall": 0.032048,
        "f1": 0.022384,
        "accuracy": 0.032048,
        "main_score": 0.022384,
        "hf_subset": "kor_Hang-eng_Latn",
        "languages": [
          "kor-Hang",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012793,
        "recall": 0.021032,
        "f1": 0.014341,
        "accuracy": 0.021032,
        "main_score": 0.014341,
        "hf_subset": "kor_Hang-fas_Arab",
        "languages": [
          "kor-Hang",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.010615,
        "recall": 0.017526,
        "f1": 0.011983,
        "accuracy": 0.017526,
        "main_score": 0.011983,
        "hf_subset": "kor_Hang-fin_Latn",
        "languages": [
          "kor-Hang",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.007898,
        "recall": 0.01352,
        "f1": 0.00938,
        "accuracy": 0.01352,
        "main_score": 0.00938,
        "hf_subset": "kor_Hang-fra_Latn",
        "languages": [
          "kor-Hang",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005377,
        "recall": 0.010516,
        "f1": 0.006427,
        "accuracy": 0.010516,
        "main_score": 0.006427,
        "hf_subset": "kor_Hang-heb_Hebr",
        "languages": [
          "kor-Hang",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.010741,
        "recall": 0.016525,
        "f1": 0.012137,
        "accuracy": 0.016525,
        "main_score": 0.012137,
        "hf_subset": "kor_Hang-hin_Deva",
        "languages": [
          "kor-Hang",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.010642,
        "recall": 0.019029,
        "f1": 0.012342,
        "accuracy": 0.019029,
        "main_score": 0.012342,
        "hf_subset": "kor_Hang-hun_Latn",
        "languages": [
          "kor-Hang",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.016797,
        "recall": 0.024036,
        "f1": 0.018649,
        "accuracy": 0.024036,
        "main_score": 0.018649,
        "hf_subset": "kor_Hang-ind_Latn",
        "languages": [
          "kor-Hang",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.011107,
        "recall": 0.019029,
        "f1": 0.013111,
        "accuracy": 0.019029,
        "main_score": 0.013111,
        "hf_subset": "kor_Hang-jpn_Jpan",
        "languages": [
          "kor-Hang",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.011022,
        "recall": 0.016024,
        "f1": 0.012208,
        "accuracy": 0.016024,
        "main_score": 0.012208,
        "hf_subset": "kor_Hang-lit_Latn",
        "languages": [
          "kor-Hang",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.017189,
        "recall": 0.026039,
        "f1": 0.019061,
        "accuracy": 0.026039,
        "main_score": 0.019061,
        "hf_subset": "kor_Hang-nld_Latn",
        "languages": [
          "kor-Hang",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.005967,
        "recall": 0.010516,
        "f1": 0.007014,
        "accuracy": 0.010516,
        "main_score": 0.007014,
        "hf_subset": "kor_Hang-pol_Latn",
        "languages": [
          "kor-Hang",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.013958,
        "recall": 0.022534,
        "f1": 0.015768,
        "accuracy": 0.022534,
        "main_score": 0.015768,
        "hf_subset": "kor_Hang-por_Latn",
        "languages": [
          "kor-Hang",
          "por-Latn"
        ]
      },
      {
        "precision": 0.008913,
        "recall": 0.017026,
        "f1": 0.010447,
        "accuracy": 0.017026,
        "main_score": 0.010447,
        "hf_subset": "kor_Hang-rus_Cyrl",
        "languages": [
          "kor-Hang",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.014528,
        "recall": 0.023035,
        "f1": 0.016428,
        "accuracy": 0.023035,
        "main_score": 0.016428,
        "hf_subset": "kor_Hang-spa_Latn",
        "languages": [
          "kor-Hang",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.013937,
        "recall": 0.019529,
        "f1": 0.015143,
        "accuracy": 0.019529,
        "main_score": 0.015143,
        "hf_subset": "kor_Hang-swa_Latn",
        "languages": [
          "kor-Hang",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.013822,
        "recall": 0.021532,
        "f1": 0.015902,
        "accuracy": 0.021532,
        "main_score": 0.015902,
        "hf_subset": "kor_Hang-swe_Latn",
        "languages": [
          "kor-Hang",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.003547,
        "recall": 0.005508,
        "f1": 0.004123,
        "accuracy": 0.005508,
        "main_score": 0.004123,
        "hf_subset": "kor_Hang-tam_Taml",
        "languages": [
          "kor-Hang",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.014144,
        "recall": 0.020531,
        "f1": 0.015523,
        "accuracy": 0.020531,
        "main_score": 0.015523,
        "hf_subset": "kor_Hang-tur_Latn",
        "languages": [
          "kor-Hang",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.018311,
        "recall": 0.027041,
        "f1": 0.020515,
        "accuracy": 0.027041,
        "main_score": 0.020515,
        "hf_subset": "kor_Hang-vie_Latn",
        "languages": [
          "kor-Hang",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.006816,
        "recall": 0.011017,
        "f1": 0.007732,
        "accuracy": 0.011017,
        "main_score": 0.007732,
        "hf_subset": "kor_Hang-yue_Hant",
        "languages": [
          "kor-Hang",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.01254,
        "recall": 0.016024,
        "f1": 0.013378,
        "accuracy": 0.016024,
        "main_score": 0.013378,
        "hf_subset": "kor_Hang-zho_Hans",
        "languages": [
          "kor-Hang",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.012463,
        "recall": 0.020531,
        "f1": 0.014262,
        "accuracy": 0.020531,
        "main_score": 0.014262,
        "hf_subset": "kor_Hang-zho_Hant",
        "languages": [
          "kor-Hang",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.008444,
        "recall": 0.014522,
        "f1": 0.00974,
        "accuracy": 0.014522,
        "main_score": 0.00974,
        "hf_subset": "kor_Hang-zul_Latn",
        "languages": [
          "kor-Hang",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000169,
        "recall": 0.001002,
        "f1": 0.000255,
        "accuracy": 0.001002,
        "main_score": 0.000255,
        "hf_subset": "lao_Laoo-bod_Tibt",
        "languages": [
          "lao-Laoo",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000823,
        "recall": 0.002003,
        "f1": 0.00096,
        "accuracy": 0.002003,
        "main_score": 0.00096,
        "hf_subset": "lao_Laoo-dzo_Tibt",
        "languages": [
          "lao-Laoo",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.000548,
        "recall": 0.002003,
        "f1": 0.000587,
        "accuracy": 0.002003,
        "main_score": 0.000587,
        "hf_subset": "lao_Laoo-eng_Latn",
        "languages": [
          "lao-Laoo",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036047,
        "recall": 0.059089,
        "f1": 0.039882,
        "accuracy": 0.059089,
        "main_score": 0.039882,
        "hf_subset": "lao_Laoo-khm_Khmr",
        "languages": [
          "lao-Laoo",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.002005,
        "recall": 0.003005,
        "f1": 0.002007,
        "accuracy": 0.003005,
        "main_score": 0.002007,
        "hf_subset": "lao_Laoo-mon_Mong",
        "languages": [
          "lao-Laoo",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.001253,
        "recall": 0.005008,
        "f1": 0.001605,
        "accuracy": 0.005008,
        "main_score": 0.001605,
        "hf_subset": "lao_Laoo-mya_Mymr",
        "languages": [
          "lao-Laoo",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.000514,
        "recall": 0.002003,
        "f1": 0.000527,
        "accuracy": 0.002003,
        "main_score": 0.000527,
        "hf_subset": "lao_Laoo-tha_Thai",
        "languages": [
          "lao-Laoo",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.026987,
        "recall": 0.041562,
        "f1": 0.029944,
        "accuracy": 0.041562,
        "main_score": 0.029944,
        "hf_subset": "lav_Latn-eng_Latn",
        "languages": [
          "lav-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018882,
        "recall": 0.032048,
        "f1": 0.021741,
        "accuracy": 0.032048,
        "main_score": 0.021741,
        "hf_subset": "lav_Latn-fin_Latn",
        "languages": [
          "lav-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.025752,
        "recall": 0.040561,
        "f1": 0.028845,
        "accuracy": 0.040561,
        "main_score": 0.028845,
        "hf_subset": "lav_Latn-hun_Latn",
        "languages": [
          "lav-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.035247,
        "recall": 0.057086,
        "f1": 0.040285,
        "accuracy": 0.057086,
        "main_score": 0.040285,
        "hf_subset": "lav_Latn-lit_Latn",
        "languages": [
          "lav-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.00623,
        "recall": 0.015023,
        "f1": 0.007627,
        "accuracy": 0.015023,
        "main_score": 0.007627,
        "hf_subset": "lit_Latn-arb_Arab",
        "languages": [
          "lit-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001079,
        "recall": 0.002504,
        "f1": 0.001147,
        "accuracy": 0.002504,
        "main_score": 0.001147,
        "hf_subset": "lit_Latn-ben_Beng",
        "languages": [
          "lit-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.039641,
        "recall": 0.059589,
        "f1": 0.043971,
        "accuracy": 0.059589,
        "main_score": 0.043971,
        "hf_subset": "lit_Latn-deu_Latn",
        "languages": [
          "lit-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.006157,
        "recall": 0.011517,
        "f1": 0.00689,
        "accuracy": 0.011517,
        "main_score": 0.00689,
        "hf_subset": "lit_Latn-ell_Grek",
        "languages": [
          "lit-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.028302,
        "recall": 0.045568,
        "f1": 0.032002,
        "accuracy": 0.045568,
        "main_score": 0.032002,
        "hf_subset": "lit_Latn-eng_Latn",
        "languages": [
          "lit-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014366,
        "recall": 0.028042,
        "f1": 0.017005,
        "accuracy": 0.028042,
        "main_score": 0.017005,
        "hf_subset": "lit_Latn-fas_Arab",
        "languages": [
          "lit-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.022275,
        "recall": 0.039559,
        "f1": 0.025869,
        "accuracy": 0.039559,
        "main_score": 0.025869,
        "hf_subset": "lit_Latn-fin_Latn",
        "languages": [
          "lit-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.007593,
        "recall": 0.015023,
        "f1": 0.008802,
        "accuracy": 0.015023,
        "main_score": 0.008802,
        "hf_subset": "lit_Latn-fra_Latn",
        "languages": [
          "lit-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.003787,
        "recall": 0.009014,
        "f1": 0.004298,
        "accuracy": 0.009014,
        "main_score": 0.004298,
        "hf_subset": "lit_Latn-heb_Hebr",
        "languages": [
          "lit-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.005959,
        "recall": 0.009514,
        "f1": 0.006638,
        "accuracy": 0.009514,
        "main_score": 0.006638,
        "hf_subset": "lit_Latn-hin_Deva",
        "languages": [
          "lit-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.024477,
        "recall": 0.041062,
        "f1": 0.028331,
        "accuracy": 0.041062,
        "main_score": 0.028331,
        "hf_subset": "lit_Latn-hun_Latn",
        "languages": [
          "lit-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.033747,
        "recall": 0.05308,
        "f1": 0.038055,
        "accuracy": 0.05308,
        "main_score": 0.038055,
        "hf_subset": "lit_Latn-ind_Latn",
        "languages": [
          "lit-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00303,
        "recall": 0.005008,
        "f1": 0.003288,
        "accuracy": 0.005008,
        "main_score": 0.003288,
        "hf_subset": "lit_Latn-jpn_Jpan",
        "languages": [
          "lit-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.005202,
        "recall": 0.009514,
        "f1": 0.005697,
        "accuracy": 0.009514,
        "main_score": 0.005697,
        "hf_subset": "lit_Latn-kor_Hang",
        "languages": [
          "lit-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.03998,
        "recall": 0.058588,
        "f1": 0.044495,
        "accuracy": 0.058588,
        "main_score": 0.044495,
        "hf_subset": "lit_Latn-lav_Latn",
        "languages": [
          "lit-Latn",
          "lav-Latn"
        ]
      },
      {
        "precision": 0.029721,
        "recall": 0.049574,
        "f1": 0.033831,
        "accuracy": 0.049574,
        "main_score": 0.033831,
        "hf_subset": "lit_Latn-nld_Latn",
        "languages": [
          "lit-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.018743,
        "recall": 0.031047,
        "f1": 0.021332,
        "accuracy": 0.031047,
        "main_score": 0.021332,
        "hf_subset": "lit_Latn-pol_Latn",
        "languages": [
          "lit-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.019591,
        "recall": 0.03305,
        "f1": 0.022407,
        "accuracy": 0.03305,
        "main_score": 0.022407,
        "hf_subset": "lit_Latn-por_Latn",
        "languages": [
          "lit-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.010007,
        "recall": 0.017526,
        "f1": 0.011313,
        "accuracy": 0.017526,
        "main_score": 0.011313,
        "hf_subset": "lit_Latn-rus_Cyrl",
        "languages": [
          "lit-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.029259,
        "recall": 0.046069,
        "f1": 0.033109,
        "accuracy": 0.046069,
        "main_score": 0.033109,
        "hf_subset": "lit_Latn-spa_Latn",
        "languages": [
          "lit-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.021961,
        "recall": 0.036054,
        "f1": 0.0251,
        "accuracy": 0.036054,
        "main_score": 0.0251,
        "hf_subset": "lit_Latn-swa_Latn",
        "languages": [
          "lit-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.034428,
        "recall": 0.054081,
        "f1": 0.038625,
        "accuracy": 0.054081,
        "main_score": 0.038625,
        "hf_subset": "lit_Latn-swe_Latn",
        "languages": [
          "lit-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001012,
        "recall": 0.002003,
        "f1": 0.001021,
        "accuracy": 0.002003,
        "main_score": 0.001021,
        "hf_subset": "lit_Latn-tam_Taml",
        "languages": [
          "lit-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.020124,
        "recall": 0.036555,
        "f1": 0.023456,
        "accuracy": 0.036555,
        "main_score": 0.023456,
        "hf_subset": "lit_Latn-tur_Latn",
        "languages": [
          "lit-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.028255,
        "recall": 0.04657,
        "f1": 0.032194,
        "accuracy": 0.04657,
        "main_score": 0.032194,
        "hf_subset": "lit_Latn-vie_Latn",
        "languages": [
          "lit-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.01053,
        "recall": 0.018027,
        "f1": 0.011766,
        "accuracy": 0.018027,
        "main_score": 0.011766,
        "hf_subset": "lit_Latn-zho_Hant",
        "languages": [
          "lit-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.013149,
        "recall": 0.025538,
        "f1": 0.015381,
        "accuracy": 0.025538,
        "main_score": 0.015381,
        "hf_subset": "lit_Latn-zul_Latn",
        "languages": [
          "lit-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.029911,
        "recall": 0.046069,
        "f1": 0.033745,
        "accuracy": 0.046069,
        "main_score": 0.033745,
        "hf_subset": "ltz_Latn-afr_Latn",
        "languages": [
          "ltz-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.036521,
        "recall": 0.061592,
        "f1": 0.041728,
        "accuracy": 0.061592,
        "main_score": 0.041728,
        "hf_subset": "ltz_Latn-dan_Latn",
        "languages": [
          "ltz-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.073064,
        "recall": 0.104156,
        "f1": 0.079961,
        "accuracy": 0.104156,
        "main_score": 0.079961,
        "hf_subset": "ltz_Latn-deu_Latn",
        "languages": [
          "ltz-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.045115,
        "recall": 0.0666,
        "f1": 0.050366,
        "accuracy": 0.0666,
        "main_score": 0.050366,
        "hf_subset": "ltz_Latn-eng_Latn",
        "languages": [
          "ltz-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027033,
        "recall": 0.052579,
        "f1": 0.032238,
        "accuracy": 0.052579,
        "main_score": 0.032238,
        "hf_subset": "ltz_Latn-fao_Latn",
        "languages": [
          "ltz-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.010708,
        "recall": 0.023035,
        "f1": 0.01306,
        "accuracy": 0.023035,
        "main_score": 0.01306,
        "hf_subset": "ltz_Latn-isl_Latn",
        "languages": [
          "ltz-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.041299,
        "recall": 0.058087,
        "f1": 0.045199,
        "accuracy": 0.058087,
        "main_score": 0.045199,
        "hf_subset": "ltz_Latn-nld_Latn",
        "languages": [
          "ltz-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.034984,
        "recall": 0.055583,
        "f1": 0.039365,
        "accuracy": 0.055583,
        "main_score": 0.039365,
        "hf_subset": "ltz_Latn-nno_Latn",
        "languages": [
          "ltz-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.035581,
        "recall": 0.058087,
        "f1": 0.040684,
        "accuracy": 0.058087,
        "main_score": 0.040684,
        "hf_subset": "ltz_Latn-nob_Latn",
        "languages": [
          "ltz-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.0367,
        "recall": 0.057586,
        "f1": 0.041489,
        "accuracy": 0.057586,
        "main_score": 0.041489,
        "hf_subset": "ltz_Latn-swe_Latn",
        "languages": [
          "ltz-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001004,
        "recall": 0.002003,
        "f1": 0.001007,
        "accuracy": 0.002003,
        "main_score": 0.001007,
        "hf_subset": "mal_Mlym-eng_Latn",
        "languages": [
          "mal-Mlym",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "mal_Mlym-fij_Latn",
        "languages": [
          "mal-Mlym",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.000601,
        "recall": 0.001502,
        "f1": 0.000668,
        "accuracy": 0.001502,
        "main_score": 0.000668,
        "hf_subset": "mal_Mlym-fil_Latn",
        "languages": [
          "mal-Mlym",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.001168,
        "recall": 0.001502,
        "f1": 0.001252,
        "accuracy": 0.001502,
        "main_score": 0.001252,
        "hf_subset": "mal_Mlym-ind_Latn",
        "languages": [
          "mal-Mlym",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000526,
        "recall": 0.001502,
        "f1": 0.000549,
        "accuracy": 0.001502,
        "main_score": 0.000549,
        "hf_subset": "mal_Mlym-mlg_Latn",
        "languages": [
          "mal-Mlym",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "mal_Mlym-mri_Latn",
        "languages": [
          "mal-Mlym",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "mal_Mlym-msa_Latn",
        "languages": [
          "mal-Mlym",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "mal_Mlym-smo_Latn",
        "languages": [
          "mal-Mlym",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "mal_Mlym-tah_Latn",
        "languages": [
          "mal-Mlym",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "mal_Mlym-ton_Latn",
        "languages": [
          "mal-Mlym",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.009174,
        "recall": 0.016525,
        "f1": 0.010817,
        "accuracy": 0.016525,
        "main_score": 0.010817,
        "hf_subset": "mar_Deva-ben_Beng",
        "languages": [
          "mar-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.005246,
        "recall": 0.014021,
        "f1": 0.006273,
        "accuracy": 0.014021,
        "main_score": 0.006273,
        "hf_subset": "mar_Deva-div_Thaa",
        "languages": [
          "mar-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.010221,
        "recall": 0.015523,
        "f1": 0.010993,
        "accuracy": 0.015523,
        "main_score": 0.010993,
        "hf_subset": "mar_Deva-eng_Latn",
        "languages": [
          "mar-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005754,
        "recall": 0.009514,
        "f1": 0.006371,
        "accuracy": 0.009514,
        "main_score": 0.006371,
        "hf_subset": "mar_Deva-eus_Latn",
        "languages": [
          "mar-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.021038,
        "recall": 0.029044,
        "f1": 0.022933,
        "accuracy": 0.029044,
        "main_score": 0.022933,
        "hf_subset": "mar_Deva-guj_Gujr",
        "languages": [
          "mar-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.049512,
        "recall": 0.08012,
        "f1": 0.056756,
        "accuracy": 0.08012,
        "main_score": 0.056756,
        "hf_subset": "mar_Deva-hin_Deva",
        "languages": [
          "mar-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020172,
        "recall": 0.031547,
        "f1": 0.023104,
        "accuracy": 0.031547,
        "main_score": 0.023104,
        "hf_subset": "mar_Deva-kan_Knda",
        "languages": [
          "mar-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.043876,
        "recall": 0.061592,
        "f1": 0.048332,
        "accuracy": 0.061592,
        "main_score": 0.048332,
        "hf_subset": "mar_Deva-nep_Deva",
        "languages": [
          "mar-Deva",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.009413,
        "recall": 0.017526,
        "f1": 0.010975,
        "accuracy": 0.017526,
        "main_score": 0.010975,
        "hf_subset": "mar_Deva-pan_Guru",
        "languages": [
          "mar-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010979,
        "recall": 0.017026,
        "f1": 0.012048,
        "accuracy": 0.017026,
        "main_score": 0.012048,
        "hf_subset": "mar_Deva-sin_Sinh",
        "languages": [
          "mar-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.003385,
        "recall": 0.008513,
        "f1": 0.004241,
        "accuracy": 0.008513,
        "main_score": 0.004241,
        "hf_subset": "mar_Deva-snd_Arab",
        "languages": [
          "mar-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.010987,
        "recall": 0.018528,
        "f1": 0.012499,
        "accuracy": 0.018528,
        "main_score": 0.012499,
        "hf_subset": "mar_Deva-tam_Taml",
        "languages": [
          "mar-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.008676,
        "recall": 0.01352,
        "f1": 0.009919,
        "accuracy": 0.01352,
        "main_score": 0.009919,
        "hf_subset": "mar_Deva-tel_Telu",
        "languages": [
          "mar-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006219,
        "recall": 0.009514,
        "f1": 0.006675,
        "accuracy": 0.009514,
        "main_score": 0.006675,
        "hf_subset": "mar_Deva-urd_Arab",
        "languages": [
          "mar-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.086067,
        "recall": 0.11317,
        "f1": 0.09306,
        "accuracy": 0.11317,
        "main_score": 0.09306,
        "hf_subset": "mey_Arab-arb_Arab",
        "languages": [
          "mey-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000875,
        "recall": 0.002504,
        "f1": 0.001062,
        "accuracy": 0.002504,
        "main_score": 0.001062,
        "hf_subset": "mey_Arab-ckb_Arab",
        "languages": [
          "mey-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.014561,
        "recall": 0.023035,
        "f1": 0.016459,
        "accuracy": 0.023035,
        "main_score": 0.016459,
        "hf_subset": "mey_Arab-eng_Latn",
        "languages": [
          "mey-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008658,
        "recall": 0.01302,
        "f1": 0.009432,
        "accuracy": 0.01302,
        "main_score": 0.009432,
        "hf_subset": "mey_Arab-fas_Arab",
        "languages": [
          "mey-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.005076,
        "recall": 0.008513,
        "f1": 0.005909,
        "accuracy": 0.008513,
        "main_score": 0.005909,
        "hf_subset": "mey_Arab-heb_Hebr",
        "languages": [
          "mey-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004966,
        "recall": 0.012018,
        "f1": 0.006048,
        "accuracy": 0.012018,
        "main_score": 0.006048,
        "hf_subset": "mey_Arab-kmr_Latn",
        "languages": [
          "mey-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.013551,
        "recall": 0.019529,
        "f1": 0.014668,
        "accuracy": 0.019529,
        "main_score": 0.014668,
        "hf_subset": "mey_Arab-prs_Arab",
        "languages": [
          "mey-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.007248,
        "recall": 0.010516,
        "f1": 0.007915,
        "accuracy": 0.010516,
        "main_score": 0.007915,
        "hf_subset": "mey_Arab-pus_Arab",
        "languages": [
          "mey-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.018159,
        "recall": 0.028042,
        "f1": 0.020393,
        "accuracy": 0.028042,
        "main_score": 0.020393,
        "hf_subset": "mey_Arab-shi_Arab",
        "languages": [
          "mey-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.002793,
        "recall": 0.005008,
        "f1": 0.00308,
        "accuracy": 0.005008,
        "main_score": 0.00308,
        "hf_subset": "mey_Arab-tgk_Cyrl",
        "languages": [
          "mey-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.01419,
        "recall": 0.022534,
        "f1": 0.015958,
        "accuracy": 0.022534,
        "main_score": 0.015958,
        "hf_subset": "mkd_Cyrl-bel_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.018234,
        "recall": 0.034051,
        "f1": 0.021485,
        "accuracy": 0.034051,
        "main_score": 0.021485,
        "hf_subset": "mkd_Cyrl-bos_Latn",
        "languages": [
          "mkd-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.087336,
        "recall": 0.124186,
        "f1": 0.096354,
        "accuracy": 0.124186,
        "main_score": 0.096354,
        "hf_subset": "mkd_Cyrl-bul_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.017391,
        "recall": 0.030546,
        "f1": 0.020513,
        "accuracy": 0.030546,
        "main_score": 0.020513,
        "hf_subset": "mkd_Cyrl-ces_Latn",
        "languages": [
          "mkd-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.017364,
        "recall": 0.034552,
        "f1": 0.020872,
        "accuracy": 0.034552,
        "main_score": 0.020872,
        "hf_subset": "mkd_Cyrl-eng_Latn",
        "languages": [
          "mkd-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.019232,
        "recall": 0.035553,
        "f1": 0.022609,
        "accuracy": 0.035553,
        "main_score": 0.022609,
        "hf_subset": "mkd_Cyrl-hrv_Latn",
        "languages": [
          "mkd-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.010653,
        "recall": 0.019529,
        "f1": 0.012421,
        "accuracy": 0.019529,
        "main_score": 0.012421,
        "hf_subset": "mkd_Cyrl-pol_Latn",
        "languages": [
          "mkd-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.044864,
        "recall": 0.070606,
        "f1": 0.050776,
        "accuracy": 0.070606,
        "main_score": 0.050776,
        "hf_subset": "mkd_Cyrl-rus_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.013159,
        "recall": 0.024036,
        "f1": 0.015405,
        "accuracy": 0.024036,
        "main_score": 0.015405,
        "hf_subset": "mkd_Cyrl-slk_Latn",
        "languages": [
          "mkd-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.021195,
        "recall": 0.031047,
        "f1": 0.023563,
        "accuracy": 0.031047,
        "main_score": 0.023563,
        "hf_subset": "mkd_Cyrl-slv_Latn",
        "languages": [
          "mkd-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.055393,
        "recall": 0.082123,
        "f1": 0.06103,
        "accuracy": 0.082123,
        "main_score": 0.06103,
        "hf_subset": "mkd_Cyrl-srp_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.017045,
        "recall": 0.034051,
        "f1": 0.020563,
        "accuracy": 0.034051,
        "main_score": 0.020563,
        "hf_subset": "mkd_Cyrl-srp_Latn",
        "languages": [
          "mkd-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.026119,
        "recall": 0.040561,
        "f1": 0.029287,
        "accuracy": 0.040561,
        "main_score": 0.029287,
        "hf_subset": "mkd_Cyrl-ukr_Cyrl",
        "languages": [
          "mkd-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.031242,
        "recall": 0.049574,
        "f1": 0.035264,
        "accuracy": 0.049574,
        "main_score": 0.035264,
        "hf_subset": "mlg_Latn-eng_Latn",
        "languages": [
          "mlg-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027499,
        "recall": 0.039559,
        "f1": 0.030101,
        "accuracy": 0.039559,
        "main_score": 0.030101,
        "hf_subset": "mlg_Latn-fij_Latn",
        "languages": [
          "mlg-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.029507,
        "recall": 0.04006,
        "f1": 0.031988,
        "accuracy": 0.04006,
        "main_score": 0.031988,
        "hf_subset": "mlg_Latn-fil_Latn",
        "languages": [
          "mlg-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.040685,
        "recall": 0.054582,
        "f1": 0.044136,
        "accuracy": 0.054582,
        "main_score": 0.044136,
        "hf_subset": "mlg_Latn-ind_Latn",
        "languages": [
          "mlg-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000174,
        "recall": 0.001502,
        "f1": 0.000263,
        "accuracy": 0.001502,
        "main_score": 0.000263,
        "hf_subset": "mlg_Latn-mal_Mlym",
        "languages": [
          "mlg-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.028705,
        "recall": 0.039059,
        "f1": 0.031069,
        "accuracy": 0.039059,
        "main_score": 0.031069,
        "hf_subset": "mlg_Latn-mri_Latn",
        "languages": [
          "mlg-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.039131,
        "recall": 0.052579,
        "f1": 0.042337,
        "accuracy": 0.052579,
        "main_score": 0.042337,
        "hf_subset": "mlg_Latn-msa_Latn",
        "languages": [
          "mlg-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.017519,
        "recall": 0.028042,
        "f1": 0.019918,
        "accuracy": 0.028042,
        "main_score": 0.019918,
        "hf_subset": "mlg_Latn-smo_Latn",
        "languages": [
          "mlg-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.020302,
        "recall": 0.030546,
        "f1": 0.022814,
        "accuracy": 0.030546,
        "main_score": 0.022814,
        "hf_subset": "mlg_Latn-tah_Latn",
        "languages": [
          "mlg-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001676,
        "recall": 0.003005,
        "f1": 0.001933,
        "accuracy": 0.003005,
        "main_score": 0.001933,
        "hf_subset": "mlg_Latn-ton_Latn",
        "languages": [
          "mlg-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.010046,
        "recall": 0.014021,
        "f1": 0.010707,
        "accuracy": 0.014021,
        "main_score": 0.010707,
        "hf_subset": "mlt_Latn-cat_Latn",
        "languages": [
          "mlt-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.016738,
        "recall": 0.021032,
        "f1": 0.017828,
        "accuracy": 0.021032,
        "main_score": 0.017828,
        "hf_subset": "mlt_Latn-eng_Latn",
        "languages": [
          "mlt-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004173,
        "recall": 0.005008,
        "f1": 0.004423,
        "accuracy": 0.005008,
        "main_score": 0.004423,
        "hf_subset": "mlt_Latn-fra_Latn",
        "languages": [
          "mlt-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.010378,
        "recall": 0.014021,
        "f1": 0.010957,
        "accuracy": 0.014021,
        "main_score": 0.010957,
        "hf_subset": "mlt_Latn-glg_Latn",
        "languages": [
          "mlt-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.013385,
        "recall": 0.016024,
        "f1": 0.01408,
        "accuracy": 0.016024,
        "main_score": 0.01408,
        "hf_subset": "mlt_Latn-ita_Latn",
        "languages": [
          "mlt-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.012948,
        "recall": 0.016024,
        "f1": 0.01346,
        "accuracy": 0.016024,
        "main_score": 0.01346,
        "hf_subset": "mlt_Latn-por_Latn",
        "languages": [
          "mlt-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.006926,
        "recall": 0.009014,
        "f1": 0.007141,
        "accuracy": 0.009014,
        "main_score": 0.007141,
        "hf_subset": "mlt_Latn-ron_Latn",
        "languages": [
          "mlt-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.00997,
        "recall": 0.011517,
        "f1": 0.010337,
        "accuracy": 0.011517,
        "main_score": 0.010337,
        "hf_subset": "mlt_Latn-spa_Latn",
        "languages": [
          "mlt-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.001869,
        "recall": 0.008012,
        "f1": 0.002584,
        "accuracy": 0.008012,
        "main_score": 0.002584,
        "hf_subset": "mon_Mong-bod_Tibt",
        "languages": [
          "mon-Mong",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.002522,
        "recall": 0.00651,
        "f1": 0.003358,
        "accuracy": 0.00651,
        "main_score": 0.003358,
        "hf_subset": "mon_Mong-dzo_Tibt",
        "languages": [
          "mon-Mong",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.011207,
        "recall": 0.018528,
        "f1": 0.012788,
        "accuracy": 0.018528,
        "main_score": 0.012788,
        "hf_subset": "mon_Mong-eng_Latn",
        "languages": [
          "mon-Mong",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005557,
        "recall": 0.010015,
        "f1": 0.006152,
        "accuracy": 0.010015,
        "main_score": 0.006152,
        "hf_subset": "mon_Mong-khm_Khmr",
        "languages": [
          "mon-Mong",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.004172,
        "recall": 0.008012,
        "f1": 0.004903,
        "accuracy": 0.008012,
        "main_score": 0.004903,
        "hf_subset": "mon_Mong-lao_Laoo",
        "languages": [
          "mon-Mong",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.002026,
        "recall": 0.004507,
        "f1": 0.002279,
        "accuracy": 0.004507,
        "main_score": 0.002279,
        "hf_subset": "mon_Mong-mya_Mymr",
        "languages": [
          "mon-Mong",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.005528,
        "recall": 0.01352,
        "f1": 0.00689,
        "accuracy": 0.01352,
        "main_score": 0.00689,
        "hf_subset": "mon_Mong-tha_Thai",
        "languages": [
          "mon-Mong",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.034531,
        "recall": 0.051577,
        "f1": 0.03864,
        "accuracy": 0.051577,
        "main_score": 0.03864,
        "hf_subset": "mri_Latn-eng_Latn",
        "languages": [
          "mri-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.060846,
        "recall": 0.083625,
        "f1": 0.066616,
        "accuracy": 0.083625,
        "main_score": 0.066616,
        "hf_subset": "mri_Latn-fij_Latn",
        "languages": [
          "mri-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.042466,
        "recall": 0.061092,
        "f1": 0.046908,
        "accuracy": 0.061092,
        "main_score": 0.046908,
        "hf_subset": "mri_Latn-fil_Latn",
        "languages": [
          "mri-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.051384,
        "recall": 0.069604,
        "f1": 0.055963,
        "accuracy": 0.069604,
        "main_score": 0.055963,
        "hf_subset": "mri_Latn-ind_Latn",
        "languages": [
          "mri-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000504,
        "recall": 0.001502,
        "f1": 0.000508,
        "accuracy": 0.001502,
        "main_score": 0.000508,
        "hf_subset": "mri_Latn-mal_Mlym",
        "languages": [
          "mri-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.018047,
        "recall": 0.028543,
        "f1": 0.020214,
        "accuracy": 0.028543,
        "main_score": 0.020214,
        "hf_subset": "mri_Latn-mlg_Latn",
        "languages": [
          "mri-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.04638,
        "recall": 0.063095,
        "f1": 0.05038,
        "accuracy": 0.063095,
        "main_score": 0.05038,
        "hf_subset": "mri_Latn-msa_Latn",
        "languages": [
          "mri-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.026785,
        "recall": 0.044066,
        "f1": 0.030483,
        "accuracy": 0.044066,
        "main_score": 0.030483,
        "hf_subset": "mri_Latn-smo_Latn",
        "languages": [
          "mri-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.025267,
        "recall": 0.039059,
        "f1": 0.027829,
        "accuracy": 0.039059,
        "main_score": 0.027829,
        "hf_subset": "mri_Latn-tah_Latn",
        "languages": [
          "mri-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.001135,
        "recall": 0.002504,
        "f1": 0.001219,
        "accuracy": 0.002504,
        "main_score": 0.001219,
        "hf_subset": "mri_Latn-ton_Latn",
        "languages": [
          "mri-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.098578,
        "recall": 0.134201,
        "f1": 0.107542,
        "accuracy": 0.134201,
        "main_score": 0.107542,
        "hf_subset": "msa_Latn-eng_Latn",
        "languages": [
          "msa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.054248,
        "recall": 0.084627,
        "f1": 0.061462,
        "accuracy": 0.084627,
        "main_score": 0.061462,
        "hf_subset": "msa_Latn-fij_Latn",
        "languages": [
          "msa-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.069428,
        "recall": 0.105158,
        "f1": 0.078279,
        "accuracy": 0.105158,
        "main_score": 0.078279,
        "hf_subset": "msa_Latn-fil_Latn",
        "languages": [
          "msa-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.157649,
        "recall": 0.1998,
        "f1": 0.169587,
        "accuracy": 0.1998,
        "main_score": 0.169587,
        "hf_subset": "msa_Latn-ind_Latn",
        "languages": [
          "msa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000753,
        "recall": 0.002003,
        "f1": 0.000839,
        "accuracy": 0.002003,
        "main_score": 0.000839,
        "hf_subset": "msa_Latn-mal_Mlym",
        "languages": [
          "msa-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.024356,
        "recall": 0.041562,
        "f1": 0.02756,
        "accuracy": 0.041562,
        "main_score": 0.02756,
        "hf_subset": "msa_Latn-mlg_Latn",
        "languages": [
          "msa-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.062059,
        "recall": 0.08663,
        "f1": 0.06796,
        "accuracy": 0.08663,
        "main_score": 0.06796,
        "hf_subset": "msa_Latn-mri_Latn",
        "languages": [
          "msa-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.033063,
        "recall": 0.061592,
        "f1": 0.039137,
        "accuracy": 0.061592,
        "main_score": 0.039137,
        "hf_subset": "msa_Latn-smo_Latn",
        "languages": [
          "msa-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.029102,
        "recall": 0.048573,
        "f1": 0.033024,
        "accuracy": 0.048573,
        "main_score": 0.033024,
        "hf_subset": "msa_Latn-tah_Latn",
        "languages": [
          "msa-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.00445,
        "recall": 0.008012,
        "f1": 0.004839,
        "accuracy": 0.008012,
        "main_score": 0.004839,
        "hf_subset": "msa_Latn-ton_Latn",
        "languages": [
          "msa-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.001175,
        "recall": 0.003005,
        "f1": 0.001265,
        "accuracy": 0.003005,
        "main_score": 0.001265,
        "hf_subset": "mya_Mymr-bod_Tibt",
        "languages": [
          "mya-Mymr",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.000517,
        "recall": 0.001502,
        "f1": 0.000532,
        "accuracy": 0.001502,
        "main_score": 0.000532,
        "hf_subset": "mya_Mymr-dzo_Tibt",
        "languages": [
          "mya-Mymr",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.001169,
        "recall": 0.003505,
        "f1": 0.001298,
        "accuracy": 0.003505,
        "main_score": 0.001298,
        "hf_subset": "mya_Mymr-eng_Latn",
        "languages": [
          "mya-Mymr",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008852,
        "recall": 0.018027,
        "f1": 0.010404,
        "accuracy": 0.018027,
        "main_score": 0.010404,
        "hf_subset": "mya_Mymr-khm_Khmr",
        "languages": [
          "mya-Mymr",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.002733,
        "recall": 0.005008,
        "f1": 0.002921,
        "accuracy": 0.005008,
        "main_score": 0.002921,
        "hf_subset": "mya_Mymr-lao_Laoo",
        "languages": [
          "mya-Mymr",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000506,
        "accuracy": 0.001502,
        "main_score": 0.000506,
        "hf_subset": "mya_Mymr-mon_Mong",
        "languages": [
          "mya-Mymr",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.001798,
        "recall": 0.004006,
        "f1": 0.001922,
        "accuracy": 0.004006,
        "main_score": 0.001922,
        "hf_subset": "mya_Mymr-tha_Thai",
        "languages": [
          "mya-Mymr",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.018819,
        "recall": 0.029544,
        "f1": 0.021598,
        "accuracy": 0.029544,
        "main_score": 0.021598,
        "hf_subset": "nde_Latn-bem_Latn",
        "languages": [
          "nde-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.022688,
        "recall": 0.034051,
        "f1": 0.024538,
        "accuracy": 0.034051,
        "main_score": 0.024538,
        "hf_subset": "nde_Latn-eng_Latn",
        "languages": [
          "nde-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001411,
        "recall": 0.004006,
        "f1": 0.001626,
        "accuracy": 0.004006,
        "main_score": 0.001626,
        "hf_subset": "nde_Latn-ewe_Latn",
        "languages": [
          "nde-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.018648,
        "recall": 0.031547,
        "f1": 0.021249,
        "accuracy": 0.031547,
        "main_score": 0.021249,
        "hf_subset": "nde_Latn-fuc_Latn",
        "languages": [
          "nde-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.018504,
        "recall": 0.026039,
        "f1": 0.020253,
        "accuracy": 0.026039,
        "main_score": 0.020253,
        "hf_subset": "nde_Latn-kin_Latn",
        "languages": [
          "nde-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.021884,
        "recall": 0.029044,
        "f1": 0.023686,
        "accuracy": 0.029044,
        "main_score": 0.023686,
        "hf_subset": "nde_Latn-nya_Latn",
        "languages": [
          "nde-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.027679,
        "recall": 0.04006,
        "f1": 0.030553,
        "accuracy": 0.04006,
        "main_score": 0.030553,
        "hf_subset": "nde_Latn-sna_Latn",
        "languages": [
          "nde-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.017754,
        "recall": 0.02654,
        "f1": 0.019802,
        "accuracy": 0.02654,
        "main_score": 0.019802,
        "hf_subset": "nde_Latn-ven_Latn",
        "languages": [
          "nde-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.008968,
        "recall": 0.014522,
        "f1": 0.010107,
        "accuracy": 0.014522,
        "main_score": 0.010107,
        "hf_subset": "nep_Deva-ben_Beng",
        "languages": [
          "nep-Deva",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.007605,
        "recall": 0.014522,
        "f1": 0.00888,
        "accuracy": 0.014522,
        "main_score": 0.00888,
        "hf_subset": "nep_Deva-div_Thaa",
        "languages": [
          "nep-Deva",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.020436,
        "recall": 0.029544,
        "f1": 0.022192,
        "accuracy": 0.029544,
        "main_score": 0.022192,
        "hf_subset": "nep_Deva-eng_Latn",
        "languages": [
          "nep-Deva",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009556,
        "recall": 0.018027,
        "f1": 0.01135,
        "accuracy": 0.018027,
        "main_score": 0.01135,
        "hf_subset": "nep_Deva-eus_Latn",
        "languages": [
          "nep-Deva",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.012353,
        "recall": 0.017026,
        "f1": 0.013396,
        "accuracy": 0.017026,
        "main_score": 0.013396,
        "hf_subset": "nep_Deva-guj_Gujr",
        "languages": [
          "nep-Deva",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.065936,
        "recall": 0.10015,
        "f1": 0.074478,
        "accuracy": 0.10015,
        "main_score": 0.074478,
        "hf_subset": "nep_Deva-hin_Deva",
        "languages": [
          "nep-Deva",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.016393,
        "recall": 0.021032,
        "f1": 0.017372,
        "accuracy": 0.021032,
        "main_score": 0.017372,
        "hf_subset": "nep_Deva-kan_Knda",
        "languages": [
          "nep-Deva",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.042979,
        "recall": 0.064597,
        "f1": 0.048231,
        "accuracy": 0.064597,
        "main_score": 0.048231,
        "hf_subset": "nep_Deva-mar_Deva",
        "languages": [
          "nep-Deva",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.006995,
        "recall": 0.014021,
        "f1": 0.008308,
        "accuracy": 0.014021,
        "main_score": 0.008308,
        "hf_subset": "nep_Deva-pan_Guru",
        "languages": [
          "nep-Deva",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.011492,
        "recall": 0.016024,
        "f1": 0.012579,
        "accuracy": 0.016024,
        "main_score": 0.012579,
        "hf_subset": "nep_Deva-sin_Sinh",
        "languages": [
          "nep-Deva",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.004273,
        "recall": 0.008012,
        "f1": 0.004914,
        "accuracy": 0.008012,
        "main_score": 0.004914,
        "hf_subset": "nep_Deva-snd_Arab",
        "languages": [
          "nep-Deva",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.011055,
        "recall": 0.016525,
        "f1": 0.01242,
        "accuracy": 0.016525,
        "main_score": 0.01242,
        "hf_subset": "nep_Deva-tam_Taml",
        "languages": [
          "nep-Deva",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.010744,
        "recall": 0.020531,
        "f1": 0.012551,
        "accuracy": 0.020531,
        "main_score": 0.012551,
        "hf_subset": "nep_Deva-tel_Telu",
        "languages": [
          "nep-Deva",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.009558,
        "recall": 0.016525,
        "f1": 0.010852,
        "accuracy": 0.016525,
        "main_score": 0.010852,
        "hf_subset": "nep_Deva-urd_Arab",
        "languages": [
          "nep-Deva",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.069262,
        "recall": 0.109164,
        "f1": 0.078113,
        "accuracy": 0.109164,
        "main_score": 0.078113,
        "hf_subset": "nld_Latn-afr_Latn",
        "languages": [
          "nld-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.005279,
        "recall": 0.012519,
        "f1": 0.006409,
        "accuracy": 0.012519,
        "main_score": 0.006409,
        "hf_subset": "nld_Latn-arb_Arab",
        "languages": [
          "nld-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002575,
        "recall": 0.004507,
        "f1": 0.002641,
        "accuracy": 0.004507,
        "main_score": 0.002641,
        "hf_subset": "nld_Latn-ben_Beng",
        "languages": [
          "nld-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.05656,
        "recall": 0.092639,
        "f1": 0.065334,
        "accuracy": 0.092639,
        "main_score": 0.065334,
        "hf_subset": "nld_Latn-dan_Latn",
        "languages": [
          "nld-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.057097,
        "recall": 0.089134,
        "f1": 0.06491,
        "accuracy": 0.089134,
        "main_score": 0.06491,
        "hf_subset": "nld_Latn-deu_Latn",
        "languages": [
          "nld-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.010847,
        "recall": 0.021532,
        "f1": 0.012675,
        "accuracy": 0.021532,
        "main_score": 0.012675,
        "hf_subset": "nld_Latn-ell_Grek",
        "languages": [
          "nld-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.06874,
        "recall": 0.10015,
        "f1": 0.07638,
        "accuracy": 0.10015,
        "main_score": 0.07638,
        "hf_subset": "nld_Latn-eng_Latn",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024926,
        "recall": 0.049574,
        "f1": 0.029931,
        "accuracy": 0.049574,
        "main_score": 0.029931,
        "hf_subset": "nld_Latn-fao_Latn",
        "languages": [
          "nld-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.019175,
        "recall": 0.041062,
        "f1": 0.022981,
        "accuracy": 0.041062,
        "main_score": 0.022981,
        "hf_subset": "nld_Latn-fas_Arab",
        "languages": [
          "nld-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.02755,
        "recall": 0.054081,
        "f1": 0.032864,
        "accuracy": 0.054081,
        "main_score": 0.032864,
        "hf_subset": "nld_Latn-fin_Latn",
        "languages": [
          "nld-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.017072,
        "recall": 0.031547,
        "f1": 0.019694,
        "accuracy": 0.031547,
        "main_score": 0.019694,
        "hf_subset": "nld_Latn-fra_Latn",
        "languages": [
          "nld-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005013,
        "recall": 0.012519,
        "f1": 0.006178,
        "accuracy": 0.012519,
        "main_score": 0.006178,
        "hf_subset": "nld_Latn-heb_Hebr",
        "languages": [
          "nld-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.008879,
        "recall": 0.016024,
        "f1": 0.009969,
        "accuracy": 0.016024,
        "main_score": 0.009969,
        "hf_subset": "nld_Latn-hin_Deva",
        "languages": [
          "nld-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.032963,
        "recall": 0.058588,
        "f1": 0.038571,
        "accuracy": 0.058588,
        "main_score": 0.038571,
        "hf_subset": "nld_Latn-hun_Latn",
        "languages": [
          "nld-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.064726,
        "recall": 0.10015,
        "f1": 0.073265,
        "accuracy": 0.10015,
        "main_score": 0.073265,
        "hf_subset": "nld_Latn-ind_Latn",
        "languages": [
          "nld-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.022082,
        "recall": 0.04006,
        "f1": 0.025735,
        "accuracy": 0.04006,
        "main_score": 0.025735,
        "hf_subset": "nld_Latn-isl_Latn",
        "languages": [
          "nld-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.005142,
        "recall": 0.008513,
        "f1": 0.005661,
        "accuracy": 0.008513,
        "main_score": 0.005661,
        "hf_subset": "nld_Latn-jpn_Jpan",
        "languages": [
          "nld-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.010655,
        "recall": 0.02003,
        "f1": 0.012019,
        "accuracy": 0.02003,
        "main_score": 0.012019,
        "hf_subset": "nld_Latn-kor_Hang",
        "languages": [
          "nld-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.02591,
        "recall": 0.047071,
        "f1": 0.030811,
        "accuracy": 0.047071,
        "main_score": 0.030811,
        "hf_subset": "nld_Latn-lit_Latn",
        "languages": [
          "nld-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.044611,
        "recall": 0.07311,
        "f1": 0.051418,
        "accuracy": 0.07311,
        "main_score": 0.051418,
        "hf_subset": "nld_Latn-ltz_Latn",
        "languages": [
          "nld-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.050411,
        "recall": 0.081622,
        "f1": 0.057692,
        "accuracy": 0.081622,
        "main_score": 0.057692,
        "hf_subset": "nld_Latn-nno_Latn",
        "languages": [
          "nld-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.054799,
        "recall": 0.079619,
        "f1": 0.060954,
        "accuracy": 0.079619,
        "main_score": 0.060954,
        "hf_subset": "nld_Latn-nob_Latn",
        "languages": [
          "nld-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.023505,
        "recall": 0.045068,
        "f1": 0.027378,
        "accuracy": 0.045068,
        "main_score": 0.027378,
        "hf_subset": "nld_Latn-pol_Latn",
        "languages": [
          "nld-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.037202,
        "recall": 0.064096,
        "f1": 0.042806,
        "accuracy": 0.064096,
        "main_score": 0.042806,
        "hf_subset": "nld_Latn-por_Latn",
        "languages": [
          "nld-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.011089,
        "recall": 0.026039,
        "f1": 0.013432,
        "accuracy": 0.026039,
        "main_score": 0.013432,
        "hf_subset": "nld_Latn-rus_Cyrl",
        "languages": [
          "nld-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.053328,
        "recall": 0.084126,
        "f1": 0.061025,
        "accuracy": 0.084126,
        "main_score": 0.061025,
        "hf_subset": "nld_Latn-spa_Latn",
        "languages": [
          "nld-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.035318,
        "recall": 0.064597,
        "f1": 0.041485,
        "accuracy": 0.064597,
        "main_score": 0.041485,
        "hf_subset": "nld_Latn-swa_Latn",
        "languages": [
          "nld-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.057901,
        "recall": 0.091137,
        "f1": 0.066157,
        "accuracy": 0.091137,
        "main_score": 0.066157,
        "hf_subset": "nld_Latn-swe_Latn",
        "languages": [
          "nld-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002785,
        "recall": 0.004507,
        "f1": 0.003065,
        "accuracy": 0.004507,
        "main_score": 0.003065,
        "hf_subset": "nld_Latn-tam_Taml",
        "languages": [
          "nld-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.038177,
        "recall": 0.0666,
        "f1": 0.044555,
        "accuracy": 0.0666,
        "main_score": 0.044555,
        "hf_subset": "nld_Latn-tur_Latn",
        "languages": [
          "nld-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.042845,
        "recall": 0.076114,
        "f1": 0.049985,
        "accuracy": 0.076114,
        "main_score": 0.049985,
        "hf_subset": "nld_Latn-vie_Latn",
        "languages": [
          "nld-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.014446,
        "recall": 0.027541,
        "f1": 0.016947,
        "accuracy": 0.027541,
        "main_score": 0.016947,
        "hf_subset": "nld_Latn-zho_Hant",
        "languages": [
          "nld-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.019414,
        "recall": 0.036054,
        "f1": 0.022317,
        "accuracy": 0.036054,
        "main_score": 0.022317,
        "hf_subset": "nld_Latn-zul_Latn",
        "languages": [
          "nld-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.037884,
        "recall": 0.063095,
        "f1": 0.04328,
        "accuracy": 0.063095,
        "main_score": 0.04328,
        "hf_subset": "nno_Latn-afr_Latn",
        "languages": [
          "nno-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.088327,
        "recall": 0.131197,
        "f1": 0.098704,
        "accuracy": 0.131197,
        "main_score": 0.098704,
        "hf_subset": "nno_Latn-dan_Latn",
        "languages": [
          "nno-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.045815,
        "recall": 0.07311,
        "f1": 0.052008,
        "accuracy": 0.07311,
        "main_score": 0.052008,
        "hf_subset": "nno_Latn-deu_Latn",
        "languages": [
          "nno-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.054983,
        "recall": 0.084126,
        "f1": 0.062162,
        "accuracy": 0.084126,
        "main_score": 0.062162,
        "hf_subset": "nno_Latn-eng_Latn",
        "languages": [
          "nno-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.038568,
        "recall": 0.062093,
        "f1": 0.043868,
        "accuracy": 0.062093,
        "main_score": 0.043868,
        "hf_subset": "nno_Latn-fao_Latn",
        "languages": [
          "nno-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.021989,
        "recall": 0.039559,
        "f1": 0.025584,
        "accuracy": 0.039559,
        "main_score": 0.025584,
        "hf_subset": "nno_Latn-isl_Latn",
        "languages": [
          "nno-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.039959,
        "recall": 0.061592,
        "f1": 0.044955,
        "accuracy": 0.061592,
        "main_score": 0.044955,
        "hf_subset": "nno_Latn-ltz_Latn",
        "languages": [
          "nno-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.048941,
        "recall": 0.074612,
        "f1": 0.05505,
        "accuracy": 0.074612,
        "main_score": 0.05505,
        "hf_subset": "nno_Latn-nld_Latn",
        "languages": [
          "nno-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.151641,
        "recall": 0.1998,
        "f1": 0.16413,
        "accuracy": 0.1998,
        "main_score": 0.16413,
        "hf_subset": "nno_Latn-nob_Latn",
        "languages": [
          "nno-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.095199,
        "recall": 0.130696,
        "f1": 0.103968,
        "accuracy": 0.130696,
        "main_score": 0.103968,
        "hf_subset": "nno_Latn-swe_Latn",
        "languages": [
          "nno-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.045401,
        "recall": 0.07311,
        "f1": 0.051653,
        "accuracy": 0.07311,
        "main_score": 0.051653,
        "hf_subset": "nob_Latn-afr_Latn",
        "languages": [
          "nob-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.132672,
        "recall": 0.191788,
        "f1": 0.147809,
        "accuracy": 0.191788,
        "main_score": 0.147809,
        "hf_subset": "nob_Latn-dan_Latn",
        "languages": [
          "nob-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.053914,
        "recall": 0.083625,
        "f1": 0.060399,
        "accuracy": 0.083625,
        "main_score": 0.060399,
        "hf_subset": "nob_Latn-deu_Latn",
        "languages": [
          "nob-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.058709,
        "recall": 0.095143,
        "f1": 0.067055,
        "accuracy": 0.095143,
        "main_score": 0.067055,
        "hf_subset": "nob_Latn-eng_Latn",
        "languages": [
          "nob-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.036688,
        "recall": 0.064597,
        "f1": 0.042891,
        "accuracy": 0.064597,
        "main_score": 0.042891,
        "hf_subset": "nob_Latn-fao_Latn",
        "languages": [
          "nob-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.02045,
        "recall": 0.037056,
        "f1": 0.023852,
        "accuracy": 0.037056,
        "main_score": 0.023852,
        "hf_subset": "nob_Latn-isl_Latn",
        "languages": [
          "nob-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.043887,
        "recall": 0.069104,
        "f1": 0.049725,
        "accuracy": 0.069104,
        "main_score": 0.049725,
        "hf_subset": "nob_Latn-ltz_Latn",
        "languages": [
          "nob-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.053516,
        "recall": 0.083125,
        "f1": 0.060262,
        "accuracy": 0.083125,
        "main_score": 0.060262,
        "hf_subset": "nob_Latn-nld_Latn",
        "languages": [
          "nob-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.137794,
        "recall": 0.189284,
        "f1": 0.151756,
        "accuracy": 0.189284,
        "main_score": 0.151756,
        "hf_subset": "nob_Latn-nno_Latn",
        "languages": [
          "nob-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.110067,
        "recall": 0.15323,
        "f1": 0.121208,
        "accuracy": 0.15323,
        "main_score": 0.121208,
        "hf_subset": "nob_Latn-swe_Latn",
        "languages": [
          "nob-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "nso_Latn-amh_Ethi",
        "languages": [
          "nso-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.044923,
        "recall": 0.067601,
        "f1": 0.049987,
        "accuracy": 0.067601,
        "main_score": 0.049987,
        "hf_subset": "nso_Latn-eng_Latn",
        "languages": [
          "nso-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031577,
        "recall": 0.048573,
        "f1": 0.035506,
        "accuracy": 0.048573,
        "main_score": 0.035506,
        "hf_subset": "nso_Latn-hau_Latn",
        "languages": [
          "nso-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.040255,
        "recall": 0.055583,
        "f1": 0.043537,
        "accuracy": 0.055583,
        "main_score": 0.043537,
        "hf_subset": "nso_Latn-ibo_Latn",
        "languages": [
          "nso-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.016995,
        "recall": 0.029544,
        "f1": 0.019414,
        "accuracy": 0.029544,
        "main_score": 0.019414,
        "hf_subset": "nso_Latn-orm_Ethi",
        "languages": [
          "nso-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.021699,
        "recall": 0.039059,
        "f1": 0.024886,
        "accuracy": 0.039059,
        "main_score": 0.024886,
        "hf_subset": "nso_Latn-som_Latn",
        "languages": [
          "nso-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.019584,
        "recall": 0.03355,
        "f1": 0.02273,
        "accuracy": 0.03355,
        "main_score": 0.02273,
        "hf_subset": "nso_Latn-ssw_Latn",
        "languages": [
          "nso-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.046272,
        "recall": 0.063595,
        "f1": 0.050529,
        "accuracy": 0.063595,
        "main_score": 0.050529,
        "hf_subset": "nso_Latn-swa_Latn",
        "languages": [
          "nso-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "nso_Latn-tir_Ethi",
        "languages": [
          "nso-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.079256,
        "recall": 0.108162,
        "f1": 0.086678,
        "accuracy": 0.108162,
        "main_score": 0.086678,
        "hf_subset": "nso_Latn-tsn_Latn",
        "languages": [
          "nso-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.016882,
        "recall": 0.029044,
        "f1": 0.019473,
        "accuracy": 0.029044,
        "main_score": 0.019473,
        "hf_subset": "nso_Latn-wol_Latn",
        "languages": [
          "nso-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.012854,
        "recall": 0.021532,
        "f1": 0.014763,
        "accuracy": 0.021532,
        "main_score": 0.014763,
        "hf_subset": "nso_Latn-xho_Latn",
        "languages": [
          "nso-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.009494,
        "recall": 0.022033,
        "f1": 0.011669,
        "accuracy": 0.022033,
        "main_score": 0.011669,
        "hf_subset": "nso_Latn-yor_Latn",
        "languages": [
          "nso-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.016097,
        "recall": 0.028042,
        "f1": 0.018175,
        "accuracy": 0.028042,
        "main_score": 0.018175,
        "hf_subset": "nso_Latn-zul_Latn",
        "languages": [
          "nso-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.031943,
        "recall": 0.055583,
        "f1": 0.03675,
        "accuracy": 0.055583,
        "main_score": 0.03675,
        "hf_subset": "nya_Latn-bem_Latn",
        "languages": [
          "nya-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.04617,
        "recall": 0.066099,
        "f1": 0.050523,
        "accuracy": 0.066099,
        "main_score": 0.050523,
        "hf_subset": "nya_Latn-eng_Latn",
        "languages": [
          "nya-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001325,
        "recall": 0.004507,
        "f1": 0.001541,
        "accuracy": 0.004507,
        "main_score": 0.001541,
        "hf_subset": "nya_Latn-ewe_Latn",
        "languages": [
          "nya-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.051228,
        "recall": 0.071107,
        "f1": 0.056123,
        "accuracy": 0.071107,
        "main_score": 0.056123,
        "hf_subset": "nya_Latn-fuc_Latn",
        "languages": [
          "nya-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.030492,
        "recall": 0.050576,
        "f1": 0.034903,
        "accuracy": 0.050576,
        "main_score": 0.034903,
        "hf_subset": "nya_Latn-kin_Latn",
        "languages": [
          "nya-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.015873,
        "recall": 0.026039,
        "f1": 0.017798,
        "accuracy": 0.026039,
        "main_score": 0.017798,
        "hf_subset": "nya_Latn-nde_Latn",
        "languages": [
          "nya-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.036582,
        "recall": 0.055083,
        "f1": 0.04093,
        "accuracy": 0.055083,
        "main_score": 0.04093,
        "hf_subset": "nya_Latn-sna_Latn",
        "languages": [
          "nya-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.033233,
        "recall": 0.048573,
        "f1": 0.036695,
        "accuracy": 0.048573,
        "main_score": 0.036695,
        "hf_subset": "nya_Latn-ven_Latn",
        "languages": [
          "nya-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.000501,
        "f1": 1e-06,
        "accuracy": 0.000501,
        "main_score": 1e-06,
        "hf_subset": "orm_Ethi-amh_Ethi",
        "languages": [
          "orm-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.029753,
        "recall": 0.043565,
        "f1": 0.033137,
        "accuracy": 0.043565,
        "main_score": 0.033137,
        "hf_subset": "orm_Ethi-eng_Latn",
        "languages": [
          "orm-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020057,
        "recall": 0.032048,
        "f1": 0.022767,
        "accuracy": 0.032048,
        "main_score": 0.022767,
        "hf_subset": "orm_Ethi-hau_Latn",
        "languages": [
          "orm-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.025243,
        "recall": 0.035553,
        "f1": 0.027321,
        "accuracy": 0.035553,
        "main_score": 0.027321,
        "hf_subset": "orm_Ethi-ibo_Latn",
        "languages": [
          "orm-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.024063,
        "recall": 0.032048,
        "f1": 0.025964,
        "accuracy": 0.032048,
        "main_score": 0.025964,
        "hf_subset": "orm_Ethi-nso_Latn",
        "languages": [
          "orm-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.012323,
        "recall": 0.019529,
        "f1": 0.013819,
        "accuracy": 0.019529,
        "main_score": 0.013819,
        "hf_subset": "orm_Ethi-som_Latn",
        "languages": [
          "orm-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.019573,
        "recall": 0.025538,
        "f1": 0.020907,
        "accuracy": 0.025538,
        "main_score": 0.020907,
        "hf_subset": "orm_Ethi-ssw_Latn",
        "languages": [
          "orm-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.026198,
        "recall": 0.035553,
        "f1": 0.02881,
        "accuracy": 0.035553,
        "main_score": 0.02881,
        "hf_subset": "orm_Ethi-swa_Latn",
        "languages": [
          "orm-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000167,
        "recall": 0.001002,
        "f1": 0.000251,
        "accuracy": 0.001002,
        "main_score": 0.000251,
        "hf_subset": "orm_Ethi-tir_Ethi",
        "languages": [
          "orm-Ethi",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.02531,
        "recall": 0.035053,
        "f1": 0.027717,
        "accuracy": 0.035053,
        "main_score": 0.027717,
        "hf_subset": "orm_Ethi-tsn_Latn",
        "languages": [
          "orm-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.013581,
        "recall": 0.018528,
        "f1": 0.014817,
        "accuracy": 0.018528,
        "main_score": 0.014817,
        "hf_subset": "orm_Ethi-wol_Latn",
        "languages": [
          "orm-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.01443,
        "recall": 0.021532,
        "f1": 0.01616,
        "accuracy": 0.021532,
        "main_score": 0.01616,
        "hf_subset": "orm_Ethi-xho_Latn",
        "languages": [
          "orm-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.005513,
        "recall": 0.011017,
        "f1": 0.00652,
        "accuracy": 0.011017,
        "main_score": 0.00652,
        "hf_subset": "orm_Ethi-yor_Latn",
        "languages": [
          "orm-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.015001,
        "recall": 0.022033,
        "f1": 0.016368,
        "accuracy": 0.022033,
        "main_score": 0.016368,
        "hf_subset": "orm_Ethi-zul_Latn",
        "languages": [
          "orm-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.005988,
        "recall": 0.010516,
        "f1": 0.006767,
        "accuracy": 0.010516,
        "main_score": 0.006767,
        "hf_subset": "pan_Guru-ben_Beng",
        "languages": [
          "pan-Guru",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.00408,
        "recall": 0.009514,
        "f1": 0.004845,
        "accuracy": 0.009514,
        "main_score": 0.004845,
        "hf_subset": "pan_Guru-div_Thaa",
        "languages": [
          "pan-Guru",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.00823,
        "recall": 0.016024,
        "f1": 0.009436,
        "accuracy": 0.016024,
        "main_score": 0.009436,
        "hf_subset": "pan_Guru-eng_Latn",
        "languages": [
          "pan-Guru",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006423,
        "recall": 0.011017,
        "f1": 0.007408,
        "accuracy": 0.011017,
        "main_score": 0.007408,
        "hf_subset": "pan_Guru-eus_Latn",
        "languages": [
          "pan-Guru",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.017435,
        "recall": 0.022033,
        "f1": 0.018458,
        "accuracy": 0.022033,
        "main_score": 0.018458,
        "hf_subset": "pan_Guru-guj_Gujr",
        "languages": [
          "pan-Guru",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.01116,
        "recall": 0.019529,
        "f1": 0.012813,
        "accuracy": 0.019529,
        "main_score": 0.012813,
        "hf_subset": "pan_Guru-hin_Deva",
        "languages": [
          "pan-Guru",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.013329,
        "recall": 0.019529,
        "f1": 0.014218,
        "accuracy": 0.019529,
        "main_score": 0.014218,
        "hf_subset": "pan_Guru-kan_Knda",
        "languages": [
          "pan-Guru",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006914,
        "recall": 0.01352,
        "f1": 0.007931,
        "accuracy": 0.01352,
        "main_score": 0.007931,
        "hf_subset": "pan_Guru-mar_Deva",
        "languages": [
          "pan-Guru",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.012607,
        "recall": 0.019529,
        "f1": 0.014232,
        "accuracy": 0.019529,
        "main_score": 0.014232,
        "hf_subset": "pan_Guru-nep_Deva",
        "languages": [
          "pan-Guru",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.009053,
        "recall": 0.015023,
        "f1": 0.010162,
        "accuracy": 0.015023,
        "main_score": 0.010162,
        "hf_subset": "pan_Guru-sin_Sinh",
        "languages": [
          "pan-Guru",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.004944,
        "recall": 0.009514,
        "f1": 0.005813,
        "accuracy": 0.009514,
        "main_score": 0.005813,
        "hf_subset": "pan_Guru-snd_Arab",
        "languages": [
          "pan-Guru",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.00863,
        "recall": 0.012018,
        "f1": 0.00927,
        "accuracy": 0.012018,
        "main_score": 0.00927,
        "hf_subset": "pan_Guru-tam_Taml",
        "languages": [
          "pan-Guru",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00838,
        "recall": 0.014021,
        "f1": 0.009403,
        "accuracy": 0.014021,
        "main_score": 0.009403,
        "hf_subset": "pan_Guru-tel_Telu",
        "languages": [
          "pan-Guru",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.007317,
        "recall": 0.011017,
        "f1": 0.007754,
        "accuracy": 0.011017,
        "main_score": 0.007754,
        "hf_subset": "pan_Guru-urd_Arab",
        "languages": [
          "pan-Guru",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.006615,
        "recall": 0.01352,
        "f1": 0.007646,
        "accuracy": 0.01352,
        "main_score": 0.007646,
        "hf_subset": "pol_Latn-arb_Arab",
        "languages": [
          "pol-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.008132,
        "recall": 0.01302,
        "f1": 0.009121,
        "accuracy": 0.01302,
        "main_score": 0.009121,
        "hf_subset": "pol_Latn-bel_Cyrl",
        "languages": [
          "pol-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.004353,
        "recall": 0.007511,
        "f1": 0.004747,
        "accuracy": 0.007511,
        "main_score": 0.004747,
        "hf_subset": "pol_Latn-ben_Beng",
        "languages": [
          "pol-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.03469,
        "recall": 0.049074,
        "f1": 0.038258,
        "accuracy": 0.049074,
        "main_score": 0.038258,
        "hf_subset": "pol_Latn-bos_Latn",
        "languages": [
          "pol-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.019062,
        "recall": 0.03355,
        "f1": 0.022174,
        "accuracy": 0.03355,
        "main_score": 0.022174,
        "hf_subset": "pol_Latn-bul_Cyrl",
        "languages": [
          "pol-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.038412,
        "recall": 0.056084,
        "f1": 0.042801,
        "accuracy": 0.056084,
        "main_score": 0.042801,
        "hf_subset": "pol_Latn-ces_Latn",
        "languages": [
          "pol-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.037544,
        "recall": 0.058588,
        "f1": 0.042164,
        "accuracy": 0.058588,
        "main_score": 0.042164,
        "hf_subset": "pol_Latn-deu_Latn",
        "languages": [
          "pol-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.009184,
        "recall": 0.018027,
        "f1": 0.010874,
        "accuracy": 0.018027,
        "main_score": 0.010874,
        "hf_subset": "pol_Latn-ell_Grek",
        "languages": [
          "pol-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.030671,
        "recall": 0.048573,
        "f1": 0.034875,
        "accuracy": 0.048573,
        "main_score": 0.034875,
        "hf_subset": "pol_Latn-eng_Latn",
        "languages": [
          "pol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012958,
        "recall": 0.027541,
        "f1": 0.015549,
        "accuracy": 0.027541,
        "main_score": 0.015549,
        "hf_subset": "pol_Latn-fas_Arab",
        "languages": [
          "pol-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.024748,
        "recall": 0.041562,
        "f1": 0.028611,
        "accuracy": 0.041562,
        "main_score": 0.028611,
        "hf_subset": "pol_Latn-fin_Latn",
        "languages": [
          "pol-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.014667,
        "recall": 0.025538,
        "f1": 0.016642,
        "accuracy": 0.025538,
        "main_score": 0.016642,
        "hf_subset": "pol_Latn-fra_Latn",
        "languages": [
          "pol-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.005454,
        "recall": 0.01302,
        "f1": 0.006642,
        "accuracy": 0.01302,
        "main_score": 0.006642,
        "hf_subset": "pol_Latn-heb_Hebr",
        "languages": [
          "pol-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.006594,
        "recall": 0.011517,
        "f1": 0.007731,
        "accuracy": 0.011517,
        "main_score": 0.007731,
        "hf_subset": "pol_Latn-hin_Deva",
        "languages": [
          "pol-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.029115,
        "recall": 0.043565,
        "f1": 0.032565,
        "accuracy": 0.043565,
        "main_score": 0.032565,
        "hf_subset": "pol_Latn-hrv_Latn",
        "languages": [
          "pol-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.025674,
        "recall": 0.041062,
        "f1": 0.029142,
        "accuracy": 0.041062,
        "main_score": 0.029142,
        "hf_subset": "pol_Latn-hun_Latn",
        "languages": [
          "pol-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.03351,
        "recall": 0.05358,
        "f1": 0.038144,
        "accuracy": 0.05358,
        "main_score": 0.038144,
        "hf_subset": "pol_Latn-ind_Latn",
        "languages": [
          "pol-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.005001,
        "recall": 0.008513,
        "f1": 0.005713,
        "accuracy": 0.008513,
        "main_score": 0.005713,
        "hf_subset": "pol_Latn-jpn_Jpan",
        "languages": [
          "pol-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00648,
        "recall": 0.011517,
        "f1": 0.007619,
        "accuracy": 0.011517,
        "main_score": 0.007619,
        "hf_subset": "pol_Latn-kor_Hang",
        "languages": [
          "pol-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.030442,
        "recall": 0.049574,
        "f1": 0.034853,
        "accuracy": 0.049574,
        "main_score": 0.034853,
        "hf_subset": "pol_Latn-lit_Latn",
        "languages": [
          "pol-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.015645,
        "recall": 0.028543,
        "f1": 0.018032,
        "accuracy": 0.028543,
        "main_score": 0.018032,
        "hf_subset": "pol_Latn-mkd_Cyrl",
        "languages": [
          "pol-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.03357,
        "recall": 0.048573,
        "f1": 0.037186,
        "accuracy": 0.048573,
        "main_score": 0.037186,
        "hf_subset": "pol_Latn-nld_Latn",
        "languages": [
          "pol-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.029214,
        "recall": 0.040561,
        "f1": 0.031546,
        "accuracy": 0.040561,
        "main_score": 0.031546,
        "hf_subset": "pol_Latn-por_Latn",
        "languages": [
          "pol-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.011886,
        "recall": 0.021532,
        "f1": 0.01373,
        "accuracy": 0.021532,
        "main_score": 0.01373,
        "hf_subset": "pol_Latn-rus_Cyrl",
        "languages": [
          "pol-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.032691,
        "recall": 0.050075,
        "f1": 0.036927,
        "accuracy": 0.050075,
        "main_score": 0.036927,
        "hf_subset": "pol_Latn-slk_Latn",
        "languages": [
          "pol-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.028929,
        "recall": 0.048072,
        "f1": 0.033194,
        "accuracy": 0.048072,
        "main_score": 0.033194,
        "hf_subset": "pol_Latn-slv_Latn",
        "languages": [
          "pol-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.031898,
        "recall": 0.051577,
        "f1": 0.036385,
        "accuracy": 0.051577,
        "main_score": 0.036385,
        "hf_subset": "pol_Latn-spa_Latn",
        "languages": [
          "pol-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006387,
        "recall": 0.012519,
        "f1": 0.007467,
        "accuracy": 0.012519,
        "main_score": 0.007467,
        "hf_subset": "pol_Latn-srp_Cyrl",
        "languages": [
          "pol-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.027063,
        "recall": 0.038558,
        "f1": 0.029808,
        "accuracy": 0.038558,
        "main_score": 0.029808,
        "hf_subset": "pol_Latn-srp_Latn",
        "languages": [
          "pol-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.022399,
        "recall": 0.037056,
        "f1": 0.025372,
        "accuracy": 0.037056,
        "main_score": 0.025372,
        "hf_subset": "pol_Latn-swa_Latn",
        "languages": [
          "pol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.036163,
        "recall": 0.057086,
        "f1": 0.040791,
        "accuracy": 0.057086,
        "main_score": 0.040791,
        "hf_subset": "pol_Latn-swe_Latn",
        "languages": [
          "pol-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.005515,
        "recall": 0.007011,
        "f1": 0.005771,
        "accuracy": 0.007011,
        "main_score": 0.005771,
        "hf_subset": "pol_Latn-tam_Taml",
        "languages": [
          "pol-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.025255,
        "recall": 0.040561,
        "f1": 0.028737,
        "accuracy": 0.040561,
        "main_score": 0.028737,
        "hf_subset": "pol_Latn-tur_Latn",
        "languages": [
          "pol-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.01353,
        "recall": 0.022534,
        "f1": 0.015076,
        "accuracy": 0.022534,
        "main_score": 0.015076,
        "hf_subset": "pol_Latn-ukr_Cyrl",
        "languages": [
          "pol-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.024738,
        "recall": 0.047571,
        "f1": 0.029413,
        "accuracy": 0.047571,
        "main_score": 0.029413,
        "hf_subset": "pol_Latn-vie_Latn",
        "languages": [
          "pol-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012132,
        "recall": 0.023035,
        "f1": 0.014357,
        "accuracy": 0.023035,
        "main_score": 0.014357,
        "hf_subset": "pol_Latn-zho_Hant",
        "languages": [
          "pol-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.010083,
        "recall": 0.018027,
        "f1": 0.011735,
        "accuracy": 0.018027,
        "main_score": 0.011735,
        "hf_subset": "pol_Latn-zul_Latn",
        "languages": [
          "pol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.014742,
        "recall": 0.02654,
        "f1": 0.016975,
        "accuracy": 0.02654,
        "main_score": 0.016975,
        "hf_subset": "por_Latn-arb_Arab",
        "languages": [
          "por-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.003962,
        "recall": 0.008513,
        "f1": 0.004456,
        "accuracy": 0.008513,
        "main_score": 0.004456,
        "hf_subset": "por_Latn-ben_Beng",
        "languages": [
          "por-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.062608,
        "recall": 0.094642,
        "f1": 0.069945,
        "accuracy": 0.094642,
        "main_score": 0.069945,
        "hf_subset": "por_Latn-cat_Latn",
        "languages": [
          "por-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.044832,
        "recall": 0.068603,
        "f1": 0.050128,
        "accuracy": 0.068603,
        "main_score": 0.050128,
        "hf_subset": "por_Latn-deu_Latn",
        "languages": [
          "por-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.013406,
        "recall": 0.02654,
        "f1": 0.01555,
        "accuracy": 0.02654,
        "main_score": 0.01555,
        "hf_subset": "por_Latn-ell_Grek",
        "languages": [
          "por-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.060825,
        "recall": 0.095143,
        "f1": 0.068724,
        "accuracy": 0.095143,
        "main_score": 0.068724,
        "hf_subset": "por_Latn-eng_Latn",
        "languages": [
          "por-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014229,
        "recall": 0.028042,
        "f1": 0.01698,
        "accuracy": 0.028042,
        "main_score": 0.01698,
        "hf_subset": "por_Latn-fas_Arab",
        "languages": [
          "por-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.026732,
        "recall": 0.047571,
        "f1": 0.031315,
        "accuracy": 0.047571,
        "main_score": 0.031315,
        "hf_subset": "por_Latn-fin_Latn",
        "languages": [
          "por-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.030089,
        "recall": 0.049574,
        "f1": 0.033671,
        "accuracy": 0.049574,
        "main_score": 0.033671,
        "hf_subset": "por_Latn-fra_Latn",
        "languages": [
          "por-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.124359,
        "recall": 0.177266,
        "f1": 0.137848,
        "accuracy": 0.177266,
        "main_score": 0.137848,
        "hf_subset": "por_Latn-glg_Latn",
        "languages": [
          "por-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.0055,
        "recall": 0.016525,
        "f1": 0.007192,
        "accuracy": 0.016525,
        "main_score": 0.007192,
        "hf_subset": "por_Latn-heb_Hebr",
        "languages": [
          "por-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.010923,
        "recall": 0.021032,
        "f1": 0.012805,
        "accuracy": 0.021032,
        "main_score": 0.012805,
        "hf_subset": "por_Latn-hin_Deva",
        "languages": [
          "por-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.042204,
        "recall": 0.062093,
        "f1": 0.046761,
        "accuracy": 0.062093,
        "main_score": 0.046761,
        "hf_subset": "por_Latn-hun_Latn",
        "languages": [
          "por-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.055125,
        "recall": 0.085128,
        "f1": 0.061774,
        "accuracy": 0.085128,
        "main_score": 0.061774,
        "hf_subset": "por_Latn-ind_Latn",
        "languages": [
          "por-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.065476,
        "recall": 0.096144,
        "f1": 0.07265,
        "accuracy": 0.096144,
        "main_score": 0.07265,
        "hf_subset": "por_Latn-ita_Latn",
        "languages": [
          "por-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.008972,
        "recall": 0.016525,
        "f1": 0.010179,
        "accuracy": 0.016525,
        "main_score": 0.010179,
        "hf_subset": "por_Latn-jpn_Jpan",
        "languages": [
          "por-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.007416,
        "recall": 0.017026,
        "f1": 0.00904,
        "accuracy": 0.017026,
        "main_score": 0.00904,
        "hf_subset": "por_Latn-kor_Hang",
        "languages": [
          "por-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.025014,
        "recall": 0.041562,
        "f1": 0.028717,
        "accuracy": 0.041562,
        "main_score": 0.028717,
        "hf_subset": "por_Latn-lit_Latn",
        "languages": [
          "por-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.006937,
        "recall": 0.018027,
        "f1": 0.008529,
        "accuracy": 0.018027,
        "main_score": 0.008529,
        "hf_subset": "por_Latn-mlt_Latn",
        "languages": [
          "por-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.048473,
        "recall": 0.076114,
        "f1": 0.054496,
        "accuracy": 0.076114,
        "main_score": 0.054496,
        "hf_subset": "por_Latn-nld_Latn",
        "languages": [
          "por-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.025999,
        "recall": 0.044567,
        "f1": 0.029813,
        "accuracy": 0.044567,
        "main_score": 0.029813,
        "hf_subset": "por_Latn-pol_Latn",
        "languages": [
          "por-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.042947,
        "recall": 0.067101,
        "f1": 0.048506,
        "accuracy": 0.067101,
        "main_score": 0.048506,
        "hf_subset": "por_Latn-ron_Latn",
        "languages": [
          "por-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.014521,
        "recall": 0.028543,
        "f1": 0.017395,
        "accuracy": 0.028543,
        "main_score": 0.017395,
        "hf_subset": "por_Latn-rus_Cyrl",
        "languages": [
          "por-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.104648,
        "recall": 0.154732,
        "f1": 0.117088,
        "accuracy": 0.154732,
        "main_score": 0.117088,
        "hf_subset": "por_Latn-spa_Latn",
        "languages": [
          "por-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.0325,
        "recall": 0.056585,
        "f1": 0.038035,
        "accuracy": 0.056585,
        "main_score": 0.038035,
        "hf_subset": "por_Latn-swa_Latn",
        "languages": [
          "por-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.045011,
        "recall": 0.072108,
        "f1": 0.051196,
        "accuracy": 0.072108,
        "main_score": 0.051196,
        "hf_subset": "por_Latn-swe_Latn",
        "languages": [
          "por-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.003028,
        "recall": 0.007011,
        "f1": 0.003743,
        "accuracy": 0.007011,
        "main_score": 0.003743,
        "hf_subset": "por_Latn-tam_Taml",
        "languages": [
          "por-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.035609,
        "recall": 0.060591,
        "f1": 0.041344,
        "accuracy": 0.060591,
        "main_score": 0.041344,
        "hf_subset": "por_Latn-tur_Latn",
        "languages": [
          "por-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.035282,
        "recall": 0.062093,
        "f1": 0.040843,
        "accuracy": 0.062093,
        "main_score": 0.040843,
        "hf_subset": "por_Latn-vie_Latn",
        "languages": [
          "por-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.02305,
        "recall": 0.04006,
        "f1": 0.026434,
        "accuracy": 0.04006,
        "main_score": 0.026434,
        "hf_subset": "por_Latn-zho_Hant",
        "languages": [
          "por-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.01437,
        "recall": 0.029544,
        "f1": 0.016867,
        "accuracy": 0.029544,
        "main_score": 0.016867,
        "hf_subset": "por_Latn-zul_Latn",
        "languages": [
          "por-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.008774,
        "recall": 0.016525,
        "f1": 0.010066,
        "accuracy": 0.016525,
        "main_score": 0.010066,
        "hf_subset": "prs_Arab-arb_Arab",
        "languages": [
          "prs-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000774,
        "recall": 0.002504,
        "f1": 0.000929,
        "accuracy": 0.002504,
        "main_score": 0.000929,
        "hf_subset": "prs_Arab-ckb_Arab",
        "languages": [
          "prs-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.029816,
        "recall": 0.04657,
        "f1": 0.033872,
        "accuracy": 0.04657,
        "main_score": 0.033872,
        "hf_subset": "prs_Arab-eng_Latn",
        "languages": [
          "prs-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.074643,
        "recall": 0.111167,
        "f1": 0.083728,
        "accuracy": 0.111167,
        "main_score": 0.083728,
        "hf_subset": "prs_Arab-fas_Arab",
        "languages": [
          "prs-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001777,
        "recall": 0.005508,
        "f1": 0.00241,
        "accuracy": 0.005508,
        "main_score": 0.00241,
        "hf_subset": "prs_Arab-heb_Hebr",
        "languages": [
          "prs-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.00283,
        "recall": 0.008513,
        "f1": 0.003552,
        "accuracy": 0.008513,
        "main_score": 0.003552,
        "hf_subset": "prs_Arab-kmr_Latn",
        "languages": [
          "prs-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.007324,
        "recall": 0.017526,
        "f1": 0.008721,
        "accuracy": 0.017526,
        "main_score": 0.008721,
        "hf_subset": "prs_Arab-mey_Arab",
        "languages": [
          "prs-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.016918,
        "recall": 0.03355,
        "f1": 0.020286,
        "accuracy": 0.03355,
        "main_score": 0.020286,
        "hf_subset": "prs_Arab-pus_Arab",
        "languages": [
          "prs-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.008346,
        "recall": 0.018027,
        "f1": 0.009723,
        "accuracy": 0.018027,
        "main_score": 0.009723,
        "hf_subset": "prs_Arab-shi_Arab",
        "languages": [
          "prs-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.006614,
        "recall": 0.009514,
        "f1": 0.006925,
        "accuracy": 0.009514,
        "main_score": 0.006925,
        "hf_subset": "prs_Arab-tgk_Cyrl",
        "languages": [
          "prs-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.006611,
        "recall": 0.01352,
        "f1": 0.007795,
        "accuracy": 0.01352,
        "main_score": 0.007795,
        "hf_subset": "pus_Arab-arb_Arab",
        "languages": [
          "pus-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000929,
        "recall": 0.002003,
        "f1": 0.001106,
        "accuracy": 0.002003,
        "main_score": 0.001106,
        "hf_subset": "pus_Arab-ckb_Arab",
        "languages": [
          "pus-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.013442,
        "recall": 0.019029,
        "f1": 0.014817,
        "accuracy": 0.019029,
        "main_score": 0.014817,
        "hf_subset": "pus_Arab-eng_Latn",
        "languages": [
          "pus-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.017082,
        "recall": 0.025538,
        "f1": 0.01914,
        "accuracy": 0.025538,
        "main_score": 0.01914,
        "hf_subset": "pus_Arab-fas_Arab",
        "languages": [
          "pus-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.004278,
        "recall": 0.007011,
        "f1": 0.004661,
        "accuracy": 0.007011,
        "main_score": 0.004661,
        "hf_subset": "pus_Arab-heb_Hebr",
        "languages": [
          "pus-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.003976,
        "recall": 0.008513,
        "f1": 0.004686,
        "accuracy": 0.008513,
        "main_score": 0.004686,
        "hf_subset": "pus_Arab-kmr_Latn",
        "languages": [
          "pus-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.005915,
        "recall": 0.011517,
        "f1": 0.006968,
        "accuracy": 0.011517,
        "main_score": 0.006968,
        "hf_subset": "pus_Arab-mey_Arab",
        "languages": [
          "pus-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.033211,
        "recall": 0.043065,
        "f1": 0.035678,
        "accuracy": 0.043065,
        "main_score": 0.035678,
        "hf_subset": "pus_Arab-prs_Arab",
        "languages": [
          "pus-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.005853,
        "recall": 0.009514,
        "f1": 0.00667,
        "accuracy": 0.009514,
        "main_score": 0.00667,
        "hf_subset": "pus_Arab-shi_Arab",
        "languages": [
          "pus-Arab",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.004942,
        "recall": 0.007511,
        "f1": 0.005154,
        "accuracy": 0.007511,
        "main_score": 0.005154,
        "hf_subset": "pus_Arab-tgk_Cyrl",
        "languages": [
          "pus-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.027551,
        "recall": 0.050075,
        "f1": 0.03224,
        "accuracy": 0.050075,
        "main_score": 0.03224,
        "hf_subset": "ron_Latn-cat_Latn",
        "languages": [
          "ron-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.046959,
        "recall": 0.074111,
        "f1": 0.053559,
        "accuracy": 0.074111,
        "main_score": 0.053559,
        "hf_subset": "ron_Latn-eng_Latn",
        "languages": [
          "ron-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.018286,
        "recall": 0.034552,
        "f1": 0.02114,
        "accuracy": 0.034552,
        "main_score": 0.02114,
        "hf_subset": "ron_Latn-fra_Latn",
        "languages": [
          "ron-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.046195,
        "recall": 0.071107,
        "f1": 0.051713,
        "accuracy": 0.071107,
        "main_score": 0.051713,
        "hf_subset": "ron_Latn-glg_Latn",
        "languages": [
          "ron-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.060754,
        "recall": 0.090636,
        "f1": 0.067969,
        "accuracy": 0.090636,
        "main_score": 0.067969,
        "hf_subset": "ron_Latn-ita_Latn",
        "languages": [
          "ron-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.004094,
        "recall": 0.014021,
        "f1": 0.005659,
        "accuracy": 0.014021,
        "main_score": 0.005659,
        "hf_subset": "ron_Latn-mlt_Latn",
        "languages": [
          "ron-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.03758,
        "recall": 0.061592,
        "f1": 0.043115,
        "accuracy": 0.061592,
        "main_score": 0.043115,
        "hf_subset": "ron_Latn-por_Latn",
        "languages": [
          "ron-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.051765,
        "recall": 0.081622,
        "f1": 0.058634,
        "accuracy": 0.081622,
        "main_score": 0.058634,
        "hf_subset": "ron_Latn-spa_Latn",
        "languages": [
          "ron-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.006012,
        "recall": 0.014021,
        "f1": 0.007597,
        "accuracy": 0.014021,
        "main_score": 0.007597,
        "hf_subset": "rus_Cyrl-arb_Arab",
        "languages": [
          "rus-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.023008,
        "recall": 0.038057,
        "f1": 0.025663,
        "accuracy": 0.038057,
        "main_score": 0.025663,
        "hf_subset": "rus_Cyrl-bel_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.003561,
        "recall": 0.00651,
        "f1": 0.004055,
        "accuracy": 0.00651,
        "main_score": 0.004055,
        "hf_subset": "rus_Cyrl-ben_Beng",
        "languages": [
          "rus-Cyrl",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.018772,
        "recall": 0.031047,
        "f1": 0.021478,
        "accuracy": 0.031047,
        "main_score": 0.021478,
        "hf_subset": "rus_Cyrl-bos_Latn",
        "languages": [
          "rus-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.067146,
        "recall": 0.100651,
        "f1": 0.075317,
        "accuracy": 0.100651,
        "main_score": 0.075317,
        "hf_subset": "rus_Cyrl-bul_Cyrl",
        "languages": [
          "rus-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.015507,
        "recall": 0.024036,
        "f1": 0.017459,
        "accuracy": 0.024036,
        "main_score": 0.017459,
        "hf_subset": "rus_Cyrl-ces_Latn",
        "languages": [
          "rus-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.020327,
        "recall": 0.036054,
        "f1": 0.023632,
        "accuracy": 0.036054,
        "main_score": 0.023632,
        "hf_subset": "rus_Cyrl-deu_Latn",
        "languages": [
          "rus-Cyrl",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.011359,
        "recall": 0.017026,
        "f1": 0.012587,
        "accuracy": 0.017026,
        "main_score": 0.012587,
        "hf_subset": "rus_Cyrl-ell_Grek",
        "languages": [
          "rus-Cyrl",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.026857,
        "recall": 0.041562,
        "f1": 0.030148,
        "accuracy": 0.041562,
        "main_score": 0.030148,
        "hf_subset": "rus_Cyrl-eng_Latn",
        "languages": [
          "rus-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013344,
        "recall": 0.023535,
        "f1": 0.015455,
        "accuracy": 0.023535,
        "main_score": 0.015455,
        "hf_subset": "rus_Cyrl-fas_Arab",
        "languages": [
          "rus-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.018661,
        "recall": 0.031547,
        "f1": 0.021531,
        "accuracy": 0.031547,
        "main_score": 0.021531,
        "hf_subset": "rus_Cyrl-fin_Latn",
        "languages": [
          "rus-Cyrl",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.012051,
        "recall": 0.018528,
        "f1": 0.013342,
        "accuracy": 0.018528,
        "main_score": 0.013342,
        "hf_subset": "rus_Cyrl-fra_Latn",
        "languages": [
          "rus-Cyrl",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.006,
        "recall": 0.014522,
        "f1": 0.00741,
        "accuracy": 0.014522,
        "main_score": 0.00741,
        "hf_subset": "rus_Cyrl-heb_Hebr",
        "languages": [
          "rus-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.009886,
        "recall": 0.018528,
        "f1": 0.011701,
        "accuracy": 0.018528,
        "main_score": 0.011701,
        "hf_subset": "rus_Cyrl-hin_Deva",
        "languages": [
          "rus-Cyrl",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020895,
        "recall": 0.031047,
        "f1": 0.02339,
        "accuracy": 0.031047,
        "main_score": 0.02339,
        "hf_subset": "rus_Cyrl-hrv_Latn",
        "languages": [
          "rus-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.016715,
        "recall": 0.028042,
        "f1": 0.019344,
        "accuracy": 0.028042,
        "main_score": 0.019344,
        "hf_subset": "rus_Cyrl-hun_Latn",
        "languages": [
          "rus-Cyrl",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.027355,
        "recall": 0.044567,
        "f1": 0.031356,
        "accuracy": 0.044567,
        "main_score": 0.031356,
        "hf_subset": "rus_Cyrl-ind_Latn",
        "languages": [
          "rus-Cyrl",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.005284,
        "recall": 0.010516,
        "f1": 0.006265,
        "accuracy": 0.010516,
        "main_score": 0.006265,
        "hf_subset": "rus_Cyrl-jpn_Jpan",
        "languages": [
          "rus-Cyrl",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.006144,
        "recall": 0.014522,
        "f1": 0.00743,
        "accuracy": 0.014522,
        "main_score": 0.00743,
        "hf_subset": "rus_Cyrl-kor_Hang",
        "languages": [
          "rus-Cyrl",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.019777,
        "recall": 0.03305,
        "f1": 0.022606,
        "accuracy": 0.03305,
        "main_score": 0.022606,
        "hf_subset": "rus_Cyrl-lit_Latn",
        "languages": [
          "rus-Cyrl",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.039701,
        "recall": 0.064096,
        "f1": 0.045385,
        "accuracy": 0.064096,
        "main_score": 0.045385,
        "hf_subset": "rus_Cyrl-mkd_Cyrl",
        "languages": [
          "rus-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.021557,
        "recall": 0.032549,
        "f1": 0.024262,
        "accuracy": 0.032549,
        "main_score": 0.024262,
        "hf_subset": "rus_Cyrl-nld_Latn",
        "languages": [
          "rus-Cyrl",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.014526,
        "recall": 0.024537,
        "f1": 0.016693,
        "accuracy": 0.024537,
        "main_score": 0.016693,
        "hf_subset": "rus_Cyrl-pol_Latn",
        "languages": [
          "rus-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.022514,
        "recall": 0.036054,
        "f1": 0.025432,
        "accuracy": 0.036054,
        "main_score": 0.025432,
        "hf_subset": "rus_Cyrl-por_Latn",
        "languages": [
          "rus-Cyrl",
          "por-Latn"
        ]
      },
      {
        "precision": 0.013179,
        "recall": 0.024537,
        "f1": 0.015397,
        "accuracy": 0.024537,
        "main_score": 0.015397,
        "hf_subset": "rus_Cyrl-slk_Latn",
        "languages": [
          "rus-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.020723,
        "recall": 0.029544,
        "f1": 0.022806,
        "accuracy": 0.029544,
        "main_score": 0.022806,
        "hf_subset": "rus_Cyrl-slv_Latn",
        "languages": [
          "rus-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.026357,
        "recall": 0.04006,
        "f1": 0.029416,
        "accuracy": 0.04006,
        "main_score": 0.029416,
        "hf_subset": "rus_Cyrl-spa_Latn",
        "languages": [
          "rus-Cyrl",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.015575,
        "recall": 0.02654,
        "f1": 0.01791,
        "accuracy": 0.02654,
        "main_score": 0.01791,
        "hf_subset": "rus_Cyrl-srp_Cyrl",
        "languages": [
          "rus-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.015103,
        "recall": 0.02654,
        "f1": 0.017539,
        "accuracy": 0.02654,
        "main_score": 0.017539,
        "hf_subset": "rus_Cyrl-srp_Latn",
        "languages": [
          "rus-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.011071,
        "recall": 0.019529,
        "f1": 0.012983,
        "accuracy": 0.019529,
        "main_score": 0.012983,
        "hf_subset": "rus_Cyrl-swa_Latn",
        "languages": [
          "rus-Cyrl",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.025797,
        "recall": 0.039059,
        "f1": 0.02898,
        "accuracy": 0.039059,
        "main_score": 0.02898,
        "hf_subset": "rus_Cyrl-swe_Latn",
        "languages": [
          "rus-Cyrl",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.003859,
        "recall": 0.006009,
        "f1": 0.004213,
        "accuracy": 0.006009,
        "main_score": 0.004213,
        "hf_subset": "rus_Cyrl-tam_Taml",
        "languages": [
          "rus-Cyrl",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.021758,
        "recall": 0.03305,
        "f1": 0.024368,
        "accuracy": 0.03305,
        "main_score": 0.024368,
        "hf_subset": "rus_Cyrl-tur_Latn",
        "languages": [
          "rus-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.052572,
        "recall": 0.08012,
        "f1": 0.058234,
        "accuracy": 0.08012,
        "main_score": 0.058234,
        "hf_subset": "rus_Cyrl-ukr_Cyrl",
        "languages": [
          "rus-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.018268,
        "recall": 0.031047,
        "f1": 0.021074,
        "accuracy": 0.031047,
        "main_score": 0.021074,
        "hf_subset": "rus_Cyrl-vie_Latn",
        "languages": [
          "rus-Cyrl",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012324,
        "recall": 0.021032,
        "f1": 0.014176,
        "accuracy": 0.021032,
        "main_score": 0.014176,
        "hf_subset": "rus_Cyrl-zho_Hant",
        "languages": [
          "rus-Cyrl",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.006061,
        "recall": 0.012018,
        "f1": 0.006954,
        "accuracy": 0.012018,
        "main_score": 0.006954,
        "hf_subset": "rus_Cyrl-zul_Latn",
        "languages": [
          "rus-Cyrl",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.024486,
        "recall": 0.03355,
        "f1": 0.026324,
        "accuracy": 0.03355,
        "main_score": 0.026324,
        "hf_subset": "shi_Arab-arb_Arab",
        "languages": [
          "shi-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "shi_Arab-ckb_Arab",
        "languages": [
          "shi-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.012199,
        "recall": 0.017026,
        "f1": 0.013439,
        "accuracy": 0.017026,
        "main_score": 0.013439,
        "hf_subset": "shi_Arab-eng_Latn",
        "languages": [
          "shi-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008071,
        "recall": 0.01302,
        "f1": 0.008966,
        "accuracy": 0.01302,
        "main_score": 0.008966,
        "hf_subset": "shi_Arab-fas_Arab",
        "languages": [
          "shi-Arab",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.00703,
        "recall": 0.010015,
        "f1": 0.007656,
        "accuracy": 0.010015,
        "main_score": 0.007656,
        "hf_subset": "shi_Arab-heb_Hebr",
        "languages": [
          "shi-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.002608,
        "recall": 0.005008,
        "f1": 0.003125,
        "accuracy": 0.005008,
        "main_score": 0.003125,
        "hf_subset": "shi_Arab-kmr_Latn",
        "languages": [
          "shi-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.015222,
        "recall": 0.024537,
        "f1": 0.017192,
        "accuracy": 0.024537,
        "main_score": 0.017192,
        "hf_subset": "shi_Arab-mey_Arab",
        "languages": [
          "shi-Arab",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.012596,
        "recall": 0.019029,
        "f1": 0.013842,
        "accuracy": 0.019029,
        "main_score": 0.013842,
        "hf_subset": "shi_Arab-prs_Arab",
        "languages": [
          "shi-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.007224,
        "recall": 0.009514,
        "f1": 0.007753,
        "accuracy": 0.009514,
        "main_score": 0.007753,
        "hf_subset": "shi_Arab-pus_Arab",
        "languages": [
          "shi-Arab",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.003255,
        "recall": 0.005508,
        "f1": 0.003639,
        "accuracy": 0.005508,
        "main_score": 0.003639,
        "hf_subset": "shi_Arab-tgk_Cyrl",
        "languages": [
          "shi-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.002976,
        "recall": 0.006009,
        "f1": 0.003253,
        "accuracy": 0.006009,
        "main_score": 0.003253,
        "hf_subset": "sin_Sinh-ben_Beng",
        "languages": [
          "sin-Sinh",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.004267,
        "recall": 0.011017,
        "f1": 0.005081,
        "accuracy": 0.011017,
        "main_score": 0.005081,
        "hf_subset": "sin_Sinh-div_Thaa",
        "languages": [
          "sin-Sinh",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.002254,
        "recall": 0.003005,
        "f1": 0.002338,
        "accuracy": 0.003005,
        "main_score": 0.002338,
        "hf_subset": "sin_Sinh-eng_Latn",
        "languages": [
          "sin-Sinh",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004765,
        "recall": 0.008012,
        "f1": 0.005104,
        "accuracy": 0.008012,
        "main_score": 0.005104,
        "hf_subset": "sin_Sinh-eus_Latn",
        "languages": [
          "sin-Sinh",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.034016,
        "recall": 0.051077,
        "f1": 0.037615,
        "accuracy": 0.051077,
        "main_score": 0.037615,
        "hf_subset": "sin_Sinh-guj_Gujr",
        "languages": [
          "sin-Sinh",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.002896,
        "recall": 0.005508,
        "f1": 0.003085,
        "accuracy": 0.005508,
        "main_score": 0.003085,
        "hf_subset": "sin_Sinh-hin_Deva",
        "languages": [
          "sin-Sinh",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.038348,
        "recall": 0.066099,
        "f1": 0.043963,
        "accuracy": 0.066099,
        "main_score": 0.043963,
        "hf_subset": "sin_Sinh-kan_Knda",
        "languages": [
          "sin-Sinh",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.006893,
        "recall": 0.012519,
        "f1": 0.007772,
        "accuracy": 0.012519,
        "main_score": 0.007772,
        "hf_subset": "sin_Sinh-mar_Deva",
        "languages": [
          "sin-Sinh",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.006404,
        "recall": 0.009014,
        "f1": 0.006791,
        "accuracy": 0.009014,
        "main_score": 0.006791,
        "hf_subset": "sin_Sinh-nep_Deva",
        "languages": [
          "sin-Sinh",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.002348,
        "recall": 0.004507,
        "f1": 0.002575,
        "accuracy": 0.004507,
        "main_score": 0.002575,
        "hf_subset": "sin_Sinh-pan_Guru",
        "languages": [
          "sin-Sinh",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002775,
        "recall": 0.00651,
        "f1": 0.003111,
        "accuracy": 0.00651,
        "main_score": 0.003111,
        "hf_subset": "sin_Sinh-snd_Arab",
        "languages": [
          "sin-Sinh",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.010629,
        "recall": 0.021532,
        "f1": 0.01204,
        "accuracy": 0.021532,
        "main_score": 0.01204,
        "hf_subset": "sin_Sinh-tam_Taml",
        "languages": [
          "sin-Sinh",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.003212,
        "recall": 0.008012,
        "f1": 0.003675,
        "accuracy": 0.008012,
        "main_score": 0.003675,
        "hf_subset": "sin_Sinh-tel_Telu",
        "languages": [
          "sin-Sinh",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.001253,
        "recall": 0.002504,
        "f1": 0.001338,
        "accuracy": 0.002504,
        "main_score": 0.001338,
        "hf_subset": "sin_Sinh-urd_Arab",
        "languages": [
          "sin-Sinh",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.008815,
        "recall": 0.01352,
        "f1": 0.009615,
        "accuracy": 0.01352,
        "main_score": 0.009615,
        "hf_subset": "slk_Latn-bel_Cyrl",
        "languages": [
          "slk-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.03145,
        "recall": 0.047071,
        "f1": 0.035046,
        "accuracy": 0.047071,
        "main_score": 0.035046,
        "hf_subset": "slk_Latn-bos_Latn",
        "languages": [
          "slk-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.022008,
        "recall": 0.035553,
        "f1": 0.024923,
        "accuracy": 0.035553,
        "main_score": 0.024923,
        "hf_subset": "slk_Latn-bul_Cyrl",
        "languages": [
          "slk-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.096846,
        "recall": 0.132699,
        "f1": 0.106255,
        "accuracy": 0.132699,
        "main_score": 0.106255,
        "hf_subset": "slk_Latn-ces_Latn",
        "languages": [
          "slk-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.033956,
        "recall": 0.055583,
        "f1": 0.038575,
        "accuracy": 0.055583,
        "main_score": 0.038575,
        "hf_subset": "slk_Latn-eng_Latn",
        "languages": [
          "slk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030901,
        "recall": 0.049574,
        "f1": 0.035185,
        "accuracy": 0.049574,
        "main_score": 0.035185,
        "hf_subset": "slk_Latn-hrv_Latn",
        "languages": [
          "slk-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.016616,
        "recall": 0.027541,
        "f1": 0.018661,
        "accuracy": 0.027541,
        "main_score": 0.018661,
        "hf_subset": "slk_Latn-mkd_Cyrl",
        "languages": [
          "slk-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.030698,
        "recall": 0.049574,
        "f1": 0.034759,
        "accuracy": 0.049574,
        "main_score": 0.034759,
        "hf_subset": "slk_Latn-pol_Latn",
        "languages": [
          "slk-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.014379,
        "recall": 0.023535,
        "f1": 0.016146,
        "accuracy": 0.023535,
        "main_score": 0.016146,
        "hf_subset": "slk_Latn-rus_Cyrl",
        "languages": [
          "slk-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.037426,
        "recall": 0.059089,
        "f1": 0.042183,
        "accuracy": 0.059089,
        "main_score": 0.042183,
        "hf_subset": "slk_Latn-slv_Latn",
        "languages": [
          "slk-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.009288,
        "recall": 0.016024,
        "f1": 0.010328,
        "accuracy": 0.016024,
        "main_score": 0.010328,
        "hf_subset": "slk_Latn-srp_Cyrl",
        "languages": [
          "slk-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.028941,
        "recall": 0.046069,
        "f1": 0.032618,
        "accuracy": 0.046069,
        "main_score": 0.032618,
        "hf_subset": "slk_Latn-srp_Latn",
        "languages": [
          "slk-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.014011,
        "recall": 0.022033,
        "f1": 0.015698,
        "accuracy": 0.022033,
        "main_score": 0.015698,
        "hf_subset": "slk_Latn-ukr_Cyrl",
        "languages": [
          "slk-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.005975,
        "recall": 0.012018,
        "f1": 0.006722,
        "accuracy": 0.012018,
        "main_score": 0.006722,
        "hf_subset": "slv_Latn-bel_Cyrl",
        "languages": [
          "slv-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.059192,
        "recall": 0.087631,
        "f1": 0.065717,
        "accuracy": 0.087631,
        "main_score": 0.065717,
        "hf_subset": "slv_Latn-bos_Latn",
        "languages": [
          "slv-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.018348,
        "recall": 0.032549,
        "f1": 0.021566,
        "accuracy": 0.032549,
        "main_score": 0.021566,
        "hf_subset": "slv_Latn-bul_Cyrl",
        "languages": [
          "slv-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.038073,
        "recall": 0.068102,
        "f1": 0.045023,
        "accuracy": 0.068102,
        "main_score": 0.045023,
        "hf_subset": "slv_Latn-ces_Latn",
        "languages": [
          "slv-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.040516,
        "recall": 0.068603,
        "f1": 0.04701,
        "accuracy": 0.068603,
        "main_score": 0.04701,
        "hf_subset": "slv_Latn-eng_Latn",
        "languages": [
          "slv-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.058117,
        "recall": 0.088633,
        "f1": 0.064988,
        "accuracy": 0.088633,
        "main_score": 0.064988,
        "hf_subset": "slv_Latn-hrv_Latn",
        "languages": [
          "slv-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.014696,
        "recall": 0.027041,
        "f1": 0.017045,
        "accuracy": 0.027041,
        "main_score": 0.017045,
        "hf_subset": "slv_Latn-mkd_Cyrl",
        "languages": [
          "slv-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.019137,
        "recall": 0.038558,
        "f1": 0.023106,
        "accuracy": 0.038558,
        "main_score": 0.023106,
        "hf_subset": "slv_Latn-pol_Latn",
        "languages": [
          "slv-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.014975,
        "recall": 0.029044,
        "f1": 0.017739,
        "accuracy": 0.029044,
        "main_score": 0.017739,
        "hf_subset": "slv_Latn-rus_Cyrl",
        "languages": [
          "slv-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.029889,
        "recall": 0.056585,
        "f1": 0.035162,
        "accuracy": 0.056585,
        "main_score": 0.035162,
        "hf_subset": "slv_Latn-slk_Latn",
        "languages": [
          "slv-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.007821,
        "recall": 0.014522,
        "f1": 0.008768,
        "accuracy": 0.014522,
        "main_score": 0.008768,
        "hf_subset": "slv_Latn-srp_Cyrl",
        "languages": [
          "slv-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.054481,
        "recall": 0.082123,
        "f1": 0.060931,
        "accuracy": 0.082123,
        "main_score": 0.060931,
        "hf_subset": "slv_Latn-srp_Latn",
        "languages": [
          "slv-Latn",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.011247,
        "recall": 0.021032,
        "f1": 0.012959,
        "accuracy": 0.021032,
        "main_score": 0.012959,
        "hf_subset": "slv_Latn-ukr_Cyrl",
        "languages": [
          "slv-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.059578,
        "recall": 0.078618,
        "f1": 0.064074,
        "accuracy": 0.078618,
        "main_score": 0.064074,
        "hf_subset": "smo_Latn-eng_Latn",
        "languages": [
          "smo-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.041944,
        "recall": 0.056084,
        "f1": 0.045182,
        "accuracy": 0.056084,
        "main_score": 0.045182,
        "hf_subset": "smo_Latn-fij_Latn",
        "languages": [
          "smo-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.044123,
        "recall": 0.059089,
        "f1": 0.047583,
        "accuracy": 0.059089,
        "main_score": 0.047583,
        "hf_subset": "smo_Latn-fil_Latn",
        "languages": [
          "smo-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.048243,
        "recall": 0.062594,
        "f1": 0.051298,
        "accuracy": 0.062594,
        "main_score": 0.051298,
        "hf_subset": "smo_Latn-ind_Latn",
        "languages": [
          "smo-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001755,
        "recall": 0.002504,
        "f1": 0.001842,
        "accuracy": 0.002504,
        "main_score": 0.001842,
        "hf_subset": "smo_Latn-mal_Mlym",
        "languages": [
          "smo-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.022333,
        "recall": 0.034552,
        "f1": 0.025169,
        "accuracy": 0.034552,
        "main_score": 0.025169,
        "hf_subset": "smo_Latn-mlg_Latn",
        "languages": [
          "smo-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.047095,
        "recall": 0.065098,
        "f1": 0.051202,
        "accuracy": 0.065098,
        "main_score": 0.051202,
        "hf_subset": "smo_Latn-mri_Latn",
        "languages": [
          "smo-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.04434,
        "recall": 0.063095,
        "f1": 0.048367,
        "accuracy": 0.063095,
        "main_score": 0.048367,
        "hf_subset": "smo_Latn-msa_Latn",
        "languages": [
          "smo-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.037039,
        "recall": 0.050075,
        "f1": 0.040149,
        "accuracy": 0.050075,
        "main_score": 0.040149,
        "hf_subset": "smo_Latn-tah_Latn",
        "languages": [
          "smo-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.00469,
        "recall": 0.009014,
        "f1": 0.005379,
        "accuracy": 0.009014,
        "main_score": 0.005379,
        "hf_subset": "smo_Latn-ton_Latn",
        "languages": [
          "smo-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.02883,
        "recall": 0.047071,
        "f1": 0.03257,
        "accuracy": 0.047071,
        "main_score": 0.03257,
        "hf_subset": "sna_Latn-bem_Latn",
        "languages": [
          "sna-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.025786,
        "recall": 0.038558,
        "f1": 0.028343,
        "accuracy": 0.038558,
        "main_score": 0.028343,
        "hf_subset": "sna_Latn-eng_Latn",
        "languages": [
          "sna-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.000591,
        "recall": 0.002504,
        "f1": 0.000667,
        "accuracy": 0.002504,
        "main_score": 0.000667,
        "hf_subset": "sna_Latn-ewe_Latn",
        "languages": [
          "sna-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.034835,
        "recall": 0.048072,
        "f1": 0.037877,
        "accuracy": 0.048072,
        "main_score": 0.037877,
        "hf_subset": "sna_Latn-fuc_Latn",
        "languages": [
          "sna-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.025831,
        "recall": 0.042564,
        "f1": 0.029583,
        "accuracy": 0.042564,
        "main_score": 0.029583,
        "hf_subset": "sna_Latn-kin_Latn",
        "languages": [
          "sna-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.018797,
        "recall": 0.031547,
        "f1": 0.021413,
        "accuracy": 0.031547,
        "main_score": 0.021413,
        "hf_subset": "sna_Latn-nde_Latn",
        "languages": [
          "sna-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.037556,
        "recall": 0.056585,
        "f1": 0.042334,
        "accuracy": 0.056585,
        "main_score": 0.042334,
        "hf_subset": "sna_Latn-nya_Latn",
        "languages": [
          "sna-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.026437,
        "recall": 0.04006,
        "f1": 0.029423,
        "accuracy": 0.04006,
        "main_score": 0.029423,
        "hf_subset": "sna_Latn-ven_Latn",
        "languages": [
          "sna-Latn",
          "ven-Latn"
        ]
      },
      {
        "precision": 0.004164,
        "recall": 0.008513,
        "f1": 0.0048,
        "accuracy": 0.008513,
        "main_score": 0.0048,
        "hf_subset": "snd_Arab-ben_Beng",
        "languages": [
          "snd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.005178,
        "recall": 0.011517,
        "f1": 0.005749,
        "accuracy": 0.011517,
        "main_score": 0.005749,
        "hf_subset": "snd_Arab-div_Thaa",
        "languages": [
          "snd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.010212,
        "recall": 0.015023,
        "f1": 0.010982,
        "accuracy": 0.015023,
        "main_score": 0.010982,
        "hf_subset": "snd_Arab-eng_Latn",
        "languages": [
          "snd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002291,
        "recall": 0.005508,
        "f1": 0.002724,
        "accuracy": 0.005508,
        "main_score": 0.002724,
        "hf_subset": "snd_Arab-eus_Latn",
        "languages": [
          "snd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.005649,
        "recall": 0.008513,
        "f1": 0.006304,
        "accuracy": 0.008513,
        "main_score": 0.006304,
        "hf_subset": "snd_Arab-guj_Gujr",
        "languages": [
          "snd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.004139,
        "recall": 0.00651,
        "f1": 0.004723,
        "accuracy": 0.00651,
        "main_score": 0.004723,
        "hf_subset": "snd_Arab-hin_Deva",
        "languages": [
          "snd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003998,
        "recall": 0.00651,
        "f1": 0.00425,
        "accuracy": 0.00651,
        "main_score": 0.00425,
        "hf_subset": "snd_Arab-kan_Knda",
        "languages": [
          "snd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.004596,
        "recall": 0.007511,
        "f1": 0.004957,
        "accuracy": 0.007511,
        "main_score": 0.004957,
        "hf_subset": "snd_Arab-mar_Deva",
        "languages": [
          "snd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005275,
        "recall": 0.008513,
        "f1": 0.006052,
        "accuracy": 0.008513,
        "main_score": 0.006052,
        "hf_subset": "snd_Arab-nep_Deva",
        "languages": [
          "snd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.003842,
        "recall": 0.011017,
        "f1": 0.004982,
        "accuracy": 0.011017,
        "main_score": 0.004982,
        "hf_subset": "snd_Arab-pan_Guru",
        "languages": [
          "snd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00363,
        "recall": 0.004507,
        "f1": 0.003872,
        "accuracy": 0.004507,
        "main_score": 0.003872,
        "hf_subset": "snd_Arab-sin_Sinh",
        "languages": [
          "snd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.005825,
        "recall": 0.009014,
        "f1": 0.006407,
        "accuracy": 0.009014,
        "main_score": 0.006407,
        "hf_subset": "snd_Arab-tam_Taml",
        "languages": [
          "snd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00593,
        "recall": 0.009514,
        "f1": 0.006638,
        "accuracy": 0.009514,
        "main_score": 0.006638,
        "hf_subset": "snd_Arab-tel_Telu",
        "languages": [
          "snd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.010342,
        "recall": 0.017526,
        "f1": 0.011473,
        "accuracy": 0.017526,
        "main_score": 0.011473,
        "hf_subset": "snd_Arab-urd_Arab",
        "languages": [
          "snd-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.002671,
        "recall": 0.003005,
        "f1": 0.002754,
        "accuracy": 0.003005,
        "main_score": 0.002754,
        "hf_subset": "som_Latn-amh_Ethi",
        "languages": [
          "som-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.043764,
        "recall": 0.064597,
        "f1": 0.048467,
        "accuracy": 0.064597,
        "main_score": 0.048467,
        "hf_subset": "som_Latn-eng_Latn",
        "languages": [
          "som-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.027951,
        "recall": 0.040561,
        "f1": 0.03123,
        "accuracy": 0.040561,
        "main_score": 0.03123,
        "hf_subset": "som_Latn-hau_Latn",
        "languages": [
          "som-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.031153,
        "recall": 0.048573,
        "f1": 0.034762,
        "accuracy": 0.048573,
        "main_score": 0.034762,
        "hf_subset": "som_Latn-ibo_Latn",
        "languages": [
          "som-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.038693,
        "recall": 0.056585,
        "f1": 0.042962,
        "accuracy": 0.056585,
        "main_score": 0.042962,
        "hf_subset": "som_Latn-nso_Latn",
        "languages": [
          "som-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.01615,
        "recall": 0.025538,
        "f1": 0.018199,
        "accuracy": 0.025538,
        "main_score": 0.018199,
        "hf_subset": "som_Latn-orm_Ethi",
        "languages": [
          "som-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.022593,
        "recall": 0.03305,
        "f1": 0.024984,
        "accuracy": 0.03305,
        "main_score": 0.024984,
        "hf_subset": "som_Latn-ssw_Latn",
        "languages": [
          "som-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.038474,
        "recall": 0.059089,
        "f1": 0.043303,
        "accuracy": 0.059089,
        "main_score": 0.043303,
        "hf_subset": "som_Latn-swa_Latn",
        "languages": [
          "som-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.002504,
        "f1": 0.001253,
        "accuracy": 0.002504,
        "main_score": 0.001253,
        "hf_subset": "som_Latn-tir_Ethi",
        "languages": [
          "som-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.039726,
        "recall": 0.063595,
        "f1": 0.045456,
        "accuracy": 0.063595,
        "main_score": 0.045456,
        "hf_subset": "som_Latn-tsn_Latn",
        "languages": [
          "som-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.019591,
        "recall": 0.030546,
        "f1": 0.022002,
        "accuracy": 0.030546,
        "main_score": 0.022002,
        "hf_subset": "som_Latn-wol_Latn",
        "languages": [
          "som-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.012359,
        "recall": 0.022033,
        "f1": 0.014477,
        "accuracy": 0.022033,
        "main_score": 0.014477,
        "hf_subset": "som_Latn-xho_Latn",
        "languages": [
          "som-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.00818,
        "recall": 0.021532,
        "f1": 0.010356,
        "accuracy": 0.021532,
        "main_score": 0.010356,
        "hf_subset": "som_Latn-yor_Latn",
        "languages": [
          "som-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.012903,
        "recall": 0.022033,
        "f1": 0.014968,
        "accuracy": 0.022033,
        "main_score": 0.014968,
        "hf_subset": "som_Latn-zul_Latn",
        "languages": [
          "som-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.008267,
        "recall": 0.016525,
        "f1": 0.009432,
        "accuracy": 0.016525,
        "main_score": 0.009432,
        "hf_subset": "spa_Latn-arb_Arab",
        "languages": [
          "spa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002957,
        "recall": 0.005508,
        "f1": 0.00321,
        "accuracy": 0.005508,
        "main_score": 0.00321,
        "hf_subset": "spa_Latn-ben_Beng",
        "languages": [
          "spa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.047516,
        "recall": 0.074111,
        "f1": 0.05328,
        "accuracy": 0.074111,
        "main_score": 0.05328,
        "hf_subset": "spa_Latn-cat_Latn",
        "languages": [
          "spa-Latn",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.047694,
        "recall": 0.074612,
        "f1": 0.053773,
        "accuracy": 0.074612,
        "main_score": 0.053773,
        "hf_subset": "spa_Latn-deu_Latn",
        "languages": [
          "spa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.010838,
        "recall": 0.021532,
        "f1": 0.012818,
        "accuracy": 0.021532,
        "main_score": 0.012818,
        "hf_subset": "spa_Latn-ell_Grek",
        "languages": [
          "spa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.061545,
        "recall": 0.094141,
        "f1": 0.069319,
        "accuracy": 0.094141,
        "main_score": 0.069319,
        "hf_subset": "spa_Latn-eng_Latn",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021726,
        "recall": 0.04006,
        "f1": 0.025149,
        "accuracy": 0.04006,
        "main_score": 0.025149,
        "hf_subset": "spa_Latn-fas_Arab",
        "languages": [
          "spa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.029698,
        "recall": 0.056084,
        "f1": 0.034975,
        "accuracy": 0.056084,
        "main_score": 0.034975,
        "hf_subset": "spa_Latn-fin_Latn",
        "languages": [
          "spa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.017132,
        "recall": 0.035553,
        "f1": 0.020279,
        "accuracy": 0.035553,
        "main_score": 0.020279,
        "hf_subset": "spa_Latn-fra_Latn",
        "languages": [
          "spa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.139959,
        "recall": 0.201302,
        "f1": 0.155345,
        "accuracy": 0.201302,
        "main_score": 0.155345,
        "hf_subset": "spa_Latn-glg_Latn",
        "languages": [
          "spa-Latn",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.004249,
        "recall": 0.012018,
        "f1": 0.005364,
        "accuracy": 0.012018,
        "main_score": 0.005364,
        "hf_subset": "spa_Latn-heb_Hebr",
        "languages": [
          "spa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.007485,
        "recall": 0.015523,
        "f1": 0.009073,
        "accuracy": 0.015523,
        "main_score": 0.009073,
        "hf_subset": "spa_Latn-hin_Deva",
        "languages": [
          "spa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.035639,
        "recall": 0.058087,
        "f1": 0.040792,
        "accuracy": 0.058087,
        "main_score": 0.040792,
        "hf_subset": "spa_Latn-hun_Latn",
        "languages": [
          "spa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.064209,
        "recall": 0.096144,
        "f1": 0.071536,
        "accuracy": 0.096144,
        "main_score": 0.071536,
        "hf_subset": "spa_Latn-ind_Latn",
        "languages": [
          "spa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.067035,
        "recall": 0.100651,
        "f1": 0.075663,
        "accuracy": 0.100651,
        "main_score": 0.075663,
        "hf_subset": "spa_Latn-ita_Latn",
        "languages": [
          "spa-Latn",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.003577,
        "recall": 0.009014,
        "f1": 0.004373,
        "accuracy": 0.009014,
        "main_score": 0.004373,
        "hf_subset": "spa_Latn-jpn_Jpan",
        "languages": [
          "spa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00741,
        "recall": 0.01352,
        "f1": 0.008342,
        "accuracy": 0.01352,
        "main_score": 0.008342,
        "hf_subset": "spa_Latn-kor_Hang",
        "languages": [
          "spa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.02844,
        "recall": 0.049574,
        "f1": 0.032811,
        "accuracy": 0.049574,
        "main_score": 0.032811,
        "hf_subset": "spa_Latn-lit_Latn",
        "languages": [
          "spa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.005945,
        "recall": 0.012519,
        "f1": 0.00698,
        "accuracy": 0.012519,
        "main_score": 0.00698,
        "hf_subset": "spa_Latn-mlt_Latn",
        "languages": [
          "spa-Latn",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.047895,
        "recall": 0.076615,
        "f1": 0.054563,
        "accuracy": 0.076615,
        "main_score": 0.054563,
        "hf_subset": "spa_Latn-nld_Latn",
        "languages": [
          "spa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.021339,
        "recall": 0.041062,
        "f1": 0.02477,
        "accuracy": 0.041062,
        "main_score": 0.02477,
        "hf_subset": "spa_Latn-pol_Latn",
        "languages": [
          "spa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.080736,
        "recall": 0.125188,
        "f1": 0.091031,
        "accuracy": 0.125188,
        "main_score": 0.091031,
        "hf_subset": "spa_Latn-por_Latn",
        "languages": [
          "spa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.048707,
        "recall": 0.078618,
        "f1": 0.055907,
        "accuracy": 0.078618,
        "main_score": 0.055907,
        "hf_subset": "spa_Latn-ron_Latn",
        "languages": [
          "spa-Latn",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.01211,
        "recall": 0.025538,
        "f1": 0.014546,
        "accuracy": 0.025538,
        "main_score": 0.014546,
        "hf_subset": "spa_Latn-rus_Cyrl",
        "languages": [
          "spa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.039301,
        "recall": 0.0666,
        "f1": 0.045494,
        "accuracy": 0.0666,
        "main_score": 0.045494,
        "hf_subset": "spa_Latn-swa_Latn",
        "languages": [
          "spa-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.054478,
        "recall": 0.082123,
        "f1": 0.061303,
        "accuracy": 0.082123,
        "main_score": 0.061303,
        "hf_subset": "spa_Latn-swe_Latn",
        "languages": [
          "spa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001719,
        "recall": 0.004006,
        "f1": 0.002212,
        "accuracy": 0.004006,
        "main_score": 0.002212,
        "hf_subset": "spa_Latn-tam_Taml",
        "languages": [
          "spa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.03176,
        "recall": 0.05358,
        "f1": 0.036293,
        "accuracy": 0.05358,
        "main_score": 0.036293,
        "hf_subset": "spa_Latn-tur_Latn",
        "languages": [
          "spa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.045424,
        "recall": 0.082123,
        "f1": 0.05311,
        "accuracy": 0.082123,
        "main_score": 0.05311,
        "hf_subset": "spa_Latn-vie_Latn",
        "languages": [
          "spa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.016363,
        "recall": 0.028543,
        "f1": 0.018402,
        "accuracy": 0.028543,
        "main_score": 0.018402,
        "hf_subset": "spa_Latn-zho_Hant",
        "languages": [
          "spa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.01816,
        "recall": 0.034051,
        "f1": 0.020814,
        "accuracy": 0.034051,
        "main_score": 0.020814,
        "hf_subset": "spa_Latn-zul_Latn",
        "languages": [
          "spa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.013615,
        "recall": 0.026039,
        "f1": 0.015845,
        "accuracy": 0.026039,
        "main_score": 0.015845,
        "hf_subset": "sqi_Latn-ell_Grek",
        "languages": [
          "sqi-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.050493,
        "recall": 0.08012,
        "f1": 0.056896,
        "accuracy": 0.08012,
        "main_score": 0.056896,
        "hf_subset": "sqi_Latn-eng_Latn",
        "languages": [
          "sqi-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004683,
        "recall": 0.007511,
        "f1": 0.005177,
        "accuracy": 0.007511,
        "main_score": 0.005177,
        "hf_subset": "sqi_Latn-hye_Armn",
        "languages": [
          "sqi-Latn",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.003114,
        "recall": 0.005508,
        "f1": 0.003555,
        "accuracy": 0.005508,
        "main_score": 0.003555,
        "hf_subset": "sqi_Latn-kat_Geor",
        "languages": [
          "sqi-Latn",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.013555,
        "recall": 0.023035,
        "f1": 0.015406,
        "accuracy": 0.023035,
        "main_score": 0.015406,
        "hf_subset": "srp_Cyrl-bel_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.011132,
        "recall": 0.018528,
        "f1": 0.012196,
        "accuracy": 0.018528,
        "main_score": 0.012196,
        "hf_subset": "srp_Cyrl-bos_Latn",
        "languages": [
          "srp-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.028763,
        "recall": 0.040561,
        "f1": 0.031168,
        "accuracy": 0.040561,
        "main_score": 0.031168,
        "hf_subset": "srp_Cyrl-bul_Cyrl",
        "languages": [
          "srp-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.007193,
        "recall": 0.011017,
        "f1": 0.008069,
        "accuracy": 0.011017,
        "main_score": 0.008069,
        "hf_subset": "srp_Cyrl-ces_Latn",
        "languages": [
          "srp-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.009122,
        "recall": 0.015523,
        "f1": 0.010231,
        "accuracy": 0.015523,
        "main_score": 0.010231,
        "hf_subset": "srp_Cyrl-eng_Latn",
        "languages": [
          "srp-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.009653,
        "recall": 0.017526,
        "f1": 0.010838,
        "accuracy": 0.017526,
        "main_score": 0.010838,
        "hf_subset": "srp_Cyrl-hrv_Latn",
        "languages": [
          "srp-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.044341,
        "recall": 0.066099,
        "f1": 0.048779,
        "accuracy": 0.066099,
        "main_score": 0.048779,
        "hf_subset": "srp_Cyrl-mkd_Cyrl",
        "languages": [
          "srp-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.006639,
        "recall": 0.01352,
        "f1": 0.007618,
        "accuracy": 0.01352,
        "main_score": 0.007618,
        "hf_subset": "srp_Cyrl-pol_Latn",
        "languages": [
          "srp-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.014576,
        "recall": 0.024537,
        "f1": 0.016536,
        "accuracy": 0.024537,
        "main_score": 0.016536,
        "hf_subset": "srp_Cyrl-rus_Cyrl",
        "languages": [
          "srp-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.008394,
        "recall": 0.015523,
        "f1": 0.009397,
        "accuracy": 0.015523,
        "main_score": 0.009397,
        "hf_subset": "srp_Cyrl-slk_Latn",
        "languages": [
          "srp-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.005727,
        "recall": 0.011517,
        "f1": 0.006484,
        "accuracy": 0.011517,
        "main_score": 0.006484,
        "hf_subset": "srp_Cyrl-slv_Latn",
        "languages": [
          "srp-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.014128,
        "recall": 0.021532,
        "f1": 0.015368,
        "accuracy": 0.021532,
        "main_score": 0.015368,
        "hf_subset": "srp_Cyrl-srp_Latn",
        "languages": [
          "srp-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 0.017313,
        "recall": 0.029544,
        "f1": 0.019936,
        "accuracy": 0.029544,
        "main_score": 0.019936,
        "hf_subset": "srp_Cyrl-ukr_Cyrl",
        "languages": [
          "srp-Cyrl",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.006957,
        "recall": 0.014021,
        "f1": 0.00814,
        "accuracy": 0.014021,
        "main_score": 0.00814,
        "hf_subset": "srp_Latn-bel_Cyrl",
        "languages": [
          "srp-Latn",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.257112,
        "recall": 0.334502,
        "f1": 0.277992,
        "accuracy": 0.334502,
        "main_score": 0.277992,
        "hf_subset": "srp_Latn-bos_Latn",
        "languages": [
          "srp-Latn",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.01913,
        "recall": 0.034552,
        "f1": 0.022319,
        "accuracy": 0.034552,
        "main_score": 0.022319,
        "hf_subset": "srp_Latn-bul_Cyrl",
        "languages": [
          "srp-Latn",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.037025,
        "recall": 0.059589,
        "f1": 0.042483,
        "accuracy": 0.059589,
        "main_score": 0.042483,
        "hf_subset": "srp_Latn-ces_Latn",
        "languages": [
          "srp-Latn",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.033935,
        "recall": 0.050576,
        "f1": 0.037681,
        "accuracy": 0.050576,
        "main_score": 0.037681,
        "hf_subset": "srp_Latn-eng_Latn",
        "languages": [
          "srp-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.15137,
        "recall": 0.211317,
        "f1": 0.167249,
        "accuracy": 0.211317,
        "main_score": 0.167249,
        "hf_subset": "srp_Latn-hrv_Latn",
        "languages": [
          "srp-Latn",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.017737,
        "recall": 0.030546,
        "f1": 0.020476,
        "accuracy": 0.030546,
        "main_score": 0.020476,
        "hf_subset": "srp_Latn-mkd_Cyrl",
        "languages": [
          "srp-Latn",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.019336,
        "recall": 0.035053,
        "f1": 0.022501,
        "accuracy": 0.035053,
        "main_score": 0.022501,
        "hf_subset": "srp_Latn-pol_Latn",
        "languages": [
          "srp-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.014394,
        "recall": 0.029044,
        "f1": 0.017272,
        "accuracy": 0.029044,
        "main_score": 0.017272,
        "hf_subset": "srp_Latn-rus_Cyrl",
        "languages": [
          "srp-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.02472,
        "recall": 0.047071,
        "f1": 0.029433,
        "accuracy": 0.047071,
        "main_score": 0.029433,
        "hf_subset": "srp_Latn-slk_Latn",
        "languages": [
          "srp-Latn",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.061259,
        "recall": 0.085628,
        "f1": 0.067307,
        "accuracy": 0.085628,
        "main_score": 0.067307,
        "hf_subset": "srp_Latn-slv_Latn",
        "languages": [
          "srp-Latn",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.014432,
        "recall": 0.028042,
        "f1": 0.0164,
        "accuracy": 0.028042,
        "main_score": 0.0164,
        "hf_subset": "srp_Latn-srp_Cyrl",
        "languages": [
          "srp-Latn",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.012775,
        "recall": 0.021032,
        "f1": 0.01438,
        "accuracy": 0.021032,
        "main_score": 0.01438,
        "hf_subset": "srp_Latn-ukr_Cyrl",
        "languages": [
          "srp-Latn",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.000573,
        "recall": 0.001502,
        "f1": 0.000627,
        "accuracy": 0.001502,
        "main_score": 0.000627,
        "hf_subset": "ssw_Latn-amh_Ethi",
        "languages": [
          "ssw-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.025725,
        "recall": 0.039559,
        "f1": 0.028538,
        "accuracy": 0.039559,
        "main_score": 0.028538,
        "hf_subset": "ssw_Latn-eng_Latn",
        "languages": [
          "ssw-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.021989,
        "recall": 0.035553,
        "f1": 0.024742,
        "accuracy": 0.035553,
        "main_score": 0.024742,
        "hf_subset": "ssw_Latn-hau_Latn",
        "languages": [
          "ssw-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.020191,
        "recall": 0.035053,
        "f1": 0.023158,
        "accuracy": 0.035053,
        "main_score": 0.023158,
        "hf_subset": "ssw_Latn-ibo_Latn",
        "languages": [
          "ssw-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.022643,
        "recall": 0.038057,
        "f1": 0.026013,
        "accuracy": 0.038057,
        "main_score": 0.026013,
        "hf_subset": "ssw_Latn-nso_Latn",
        "languages": [
          "ssw-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.010829,
        "recall": 0.019029,
        "f1": 0.012314,
        "accuracy": 0.019029,
        "main_score": 0.012314,
        "hf_subset": "ssw_Latn-orm_Ethi",
        "languages": [
          "ssw-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.008301,
        "recall": 0.021532,
        "f1": 0.010358,
        "accuracy": 0.021532,
        "main_score": 0.010358,
        "hf_subset": "ssw_Latn-som_Latn",
        "languages": [
          "ssw-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.025776,
        "recall": 0.036555,
        "f1": 0.028166,
        "accuracy": 0.036555,
        "main_score": 0.028166,
        "hf_subset": "ssw_Latn-swa_Latn",
        "languages": [
          "ssw-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "ssw_Latn-tir_Ethi",
        "languages": [
          "ssw-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.032394,
        "recall": 0.048573,
        "f1": 0.036182,
        "accuracy": 0.048573,
        "main_score": 0.036182,
        "hf_subset": "ssw_Latn-tsn_Latn",
        "languages": [
          "ssw-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.009377,
        "recall": 0.019529,
        "f1": 0.01127,
        "accuracy": 0.019529,
        "main_score": 0.01127,
        "hf_subset": "ssw_Latn-wol_Latn",
        "languages": [
          "ssw-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.030935,
        "recall": 0.050075,
        "f1": 0.034997,
        "accuracy": 0.050075,
        "main_score": 0.034997,
        "hf_subset": "ssw_Latn-xho_Latn",
        "languages": [
          "ssw-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.005957,
        "recall": 0.012519,
        "f1": 0.007015,
        "accuracy": 0.012519,
        "main_score": 0.007015,
        "hf_subset": "ssw_Latn-yor_Latn",
        "languages": [
          "ssw-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.046426,
        "recall": 0.07311,
        "f1": 0.052159,
        "accuracy": 0.07311,
        "main_score": 0.052159,
        "hf_subset": "ssw_Latn-zul_Latn",
        "languages": [
          "ssw-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.001056,
        "recall": 0.003505,
        "f1": 0.001322,
        "accuracy": 0.003505,
        "main_score": 0.001322,
        "hf_subset": "swa_Latn-amh_Ethi",
        "languages": [
          "swa-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.006104,
        "recall": 0.016024,
        "f1": 0.007544,
        "accuracy": 0.016024,
        "main_score": 0.007544,
        "hf_subset": "swa_Latn-arb_Arab",
        "languages": [
          "swa-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00217,
        "recall": 0.00651,
        "f1": 0.002524,
        "accuracy": 0.00651,
        "main_score": 0.002524,
        "hf_subset": "swa_Latn-ben_Beng",
        "languages": [
          "swa-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.034821,
        "recall": 0.055083,
        "f1": 0.039398,
        "accuracy": 0.055083,
        "main_score": 0.039398,
        "hf_subset": "swa_Latn-deu_Latn",
        "languages": [
          "swa-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.007882,
        "recall": 0.016525,
        "f1": 0.009465,
        "accuracy": 0.016525,
        "main_score": 0.009465,
        "hf_subset": "swa_Latn-ell_Grek",
        "languages": [
          "swa-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.060379,
        "recall": 0.084627,
        "f1": 0.06592,
        "accuracy": 0.084627,
        "main_score": 0.06592,
        "hf_subset": "swa_Latn-eng_Latn",
        "languages": [
          "swa-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.026692,
        "recall": 0.045068,
        "f1": 0.030392,
        "accuracy": 0.045068,
        "main_score": 0.030392,
        "hf_subset": "swa_Latn-fas_Arab",
        "languages": [
          "swa-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.017639,
        "recall": 0.038057,
        "f1": 0.021904,
        "accuracy": 0.038057,
        "main_score": 0.021904,
        "hf_subset": "swa_Latn-fin_Latn",
        "languages": [
          "swa-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.006384,
        "recall": 0.011517,
        "f1": 0.007279,
        "accuracy": 0.011517,
        "main_score": 0.007279,
        "hf_subset": "swa_Latn-fra_Latn",
        "languages": [
          "swa-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.037157,
        "recall": 0.067601,
        "f1": 0.043845,
        "accuracy": 0.067601,
        "main_score": 0.043845,
        "hf_subset": "swa_Latn-hau_Latn",
        "languages": [
          "swa-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.003719,
        "recall": 0.014021,
        "f1": 0.005125,
        "accuracy": 0.014021,
        "main_score": 0.005125,
        "hf_subset": "swa_Latn-heb_Hebr",
        "languages": [
          "swa-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.010683,
        "recall": 0.022033,
        "f1": 0.012635,
        "accuracy": 0.022033,
        "main_score": 0.012635,
        "hf_subset": "swa_Latn-hin_Deva",
        "languages": [
          "swa-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.023913,
        "recall": 0.04006,
        "f1": 0.02737,
        "accuracy": 0.04006,
        "main_score": 0.02737,
        "hf_subset": "swa_Latn-hun_Latn",
        "languages": [
          "swa-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.03381,
        "recall": 0.058588,
        "f1": 0.039141,
        "accuracy": 0.058588,
        "main_score": 0.039141,
        "hf_subset": "swa_Latn-ibo_Latn",
        "languages": [
          "swa-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.078649,
        "recall": 0.108663,
        "f1": 0.08631,
        "accuracy": 0.108663,
        "main_score": 0.08631,
        "hf_subset": "swa_Latn-ind_Latn",
        "languages": [
          "swa-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.003491,
        "recall": 0.008012,
        "f1": 0.00406,
        "accuracy": 0.008012,
        "main_score": 0.00406,
        "hf_subset": "swa_Latn-jpn_Jpan",
        "languages": [
          "swa-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.006787,
        "recall": 0.01352,
        "f1": 0.007735,
        "accuracy": 0.01352,
        "main_score": 0.007735,
        "hf_subset": "swa_Latn-kor_Hang",
        "languages": [
          "swa-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.0205,
        "recall": 0.03355,
        "f1": 0.023422,
        "accuracy": 0.03355,
        "main_score": 0.023422,
        "hf_subset": "swa_Latn-lit_Latn",
        "languages": [
          "swa-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.030342,
        "recall": 0.054582,
        "f1": 0.035325,
        "accuracy": 0.054582,
        "main_score": 0.035325,
        "hf_subset": "swa_Latn-nld_Latn",
        "languages": [
          "swa-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.043317,
        "recall": 0.069604,
        "f1": 0.049025,
        "accuracy": 0.069604,
        "main_score": 0.049025,
        "hf_subset": "swa_Latn-nso_Latn",
        "languages": [
          "swa-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.020036,
        "recall": 0.034552,
        "f1": 0.02342,
        "accuracy": 0.034552,
        "main_score": 0.02342,
        "hf_subset": "swa_Latn-orm_Ethi",
        "languages": [
          "swa-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.012245,
        "recall": 0.023535,
        "f1": 0.014529,
        "accuracy": 0.023535,
        "main_score": 0.014529,
        "hf_subset": "swa_Latn-pol_Latn",
        "languages": [
          "swa-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.023122,
        "recall": 0.04006,
        "f1": 0.026673,
        "accuracy": 0.04006,
        "main_score": 0.026673,
        "hf_subset": "swa_Latn-por_Latn",
        "languages": [
          "swa-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.008145,
        "recall": 0.018528,
        "f1": 0.009736,
        "accuracy": 0.018528,
        "main_score": 0.009736,
        "hf_subset": "swa_Latn-rus_Cyrl",
        "languages": [
          "swa-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.024971,
        "recall": 0.046069,
        "f1": 0.029305,
        "accuracy": 0.046069,
        "main_score": 0.029305,
        "hf_subset": "swa_Latn-som_Latn",
        "languages": [
          "swa-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.030719,
        "recall": 0.05308,
        "f1": 0.035699,
        "accuracy": 0.05308,
        "main_score": 0.035699,
        "hf_subset": "swa_Latn-spa_Latn",
        "languages": [
          "swa-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.026606,
        "recall": 0.041562,
        "f1": 0.030318,
        "accuracy": 0.041562,
        "main_score": 0.030318,
        "hf_subset": "swa_Latn-ssw_Latn",
        "languages": [
          "swa-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.032556,
        "recall": 0.057086,
        "f1": 0.037543,
        "accuracy": 0.057086,
        "main_score": 0.037543,
        "hf_subset": "swa_Latn-swe_Latn",
        "languages": [
          "swa-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002047,
        "recall": 0.004507,
        "f1": 0.002254,
        "accuracy": 0.004507,
        "main_score": 0.002254,
        "hf_subset": "swa_Latn-tam_Taml",
        "languages": [
          "swa-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.002003,
        "f1": 0.001169,
        "accuracy": 0.002003,
        "main_score": 0.001169,
        "hf_subset": "swa_Latn-tir_Ethi",
        "languages": [
          "swa-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.049428,
        "recall": 0.08012,
        "f1": 0.056751,
        "accuracy": 0.08012,
        "main_score": 0.056751,
        "hf_subset": "swa_Latn-tsn_Latn",
        "languages": [
          "swa-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.035938,
        "recall": 0.055583,
        "f1": 0.040682,
        "accuracy": 0.055583,
        "main_score": 0.040682,
        "hf_subset": "swa_Latn-tur_Latn",
        "languages": [
          "swa-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.055156,
        "recall": 0.091637,
        "f1": 0.063713,
        "accuracy": 0.091637,
        "main_score": 0.063713,
        "hf_subset": "swa_Latn-vie_Latn",
        "languages": [
          "swa-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.020719,
        "recall": 0.04006,
        "f1": 0.024183,
        "accuracy": 0.04006,
        "main_score": 0.024183,
        "hf_subset": "swa_Latn-wol_Latn",
        "languages": [
          "swa-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.017832,
        "recall": 0.031547,
        "f1": 0.020769,
        "accuracy": 0.031547,
        "main_score": 0.020769,
        "hf_subset": "swa_Latn-xho_Latn",
        "languages": [
          "swa-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.010681,
        "recall": 0.027041,
        "f1": 0.013258,
        "accuracy": 0.027041,
        "main_score": 0.013258,
        "hf_subset": "swa_Latn-yor_Latn",
        "languages": [
          "swa-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.010647,
        "recall": 0.02003,
        "f1": 0.012285,
        "accuracy": 0.02003,
        "main_score": 0.012285,
        "hf_subset": "swa_Latn-zho_Hant",
        "languages": [
          "swa-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.019838,
        "recall": 0.040561,
        "f1": 0.023898,
        "accuracy": 0.040561,
        "main_score": 0.023898,
        "hf_subset": "swa_Latn-zul_Latn",
        "languages": [
          "swa-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.045554,
        "recall": 0.071107,
        "f1": 0.051003,
        "accuracy": 0.071107,
        "main_score": 0.051003,
        "hf_subset": "swe_Latn-afr_Latn",
        "languages": [
          "swe-Latn",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.007863,
        "recall": 0.018027,
        "f1": 0.009681,
        "accuracy": 0.018027,
        "main_score": 0.009681,
        "hf_subset": "swe_Latn-arb_Arab",
        "languages": [
          "swe-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002551,
        "recall": 0.004006,
        "f1": 0.002761,
        "accuracy": 0.004006,
        "main_score": 0.002761,
        "hf_subset": "swe_Latn-ben_Beng",
        "languages": [
          "swe-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.097702,
        "recall": 0.140711,
        "f1": 0.107785,
        "accuracy": 0.140711,
        "main_score": 0.107785,
        "hf_subset": "swe_Latn-dan_Latn",
        "languages": [
          "swe-Latn",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.060169,
        "recall": 0.091137,
        "f1": 0.067795,
        "accuracy": 0.091137,
        "main_score": 0.067795,
        "hf_subset": "swe_Latn-deu_Latn",
        "languages": [
          "swe-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.010693,
        "recall": 0.02003,
        "f1": 0.012105,
        "accuracy": 0.02003,
        "main_score": 0.012105,
        "hf_subset": "swe_Latn-ell_Grek",
        "languages": [
          "swe-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.062665,
        "recall": 0.089634,
        "f1": 0.069216,
        "accuracy": 0.089634,
        "main_score": 0.069216,
        "hf_subset": "swe_Latn-eng_Latn",
        "languages": [
          "swe-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.037004,
        "recall": 0.061592,
        "f1": 0.042583,
        "accuracy": 0.061592,
        "main_score": 0.042583,
        "hf_subset": "swe_Latn-fao_Latn",
        "languages": [
          "swe-Latn",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.018585,
        "recall": 0.040561,
        "f1": 0.022855,
        "accuracy": 0.040561,
        "main_score": 0.022855,
        "hf_subset": "swe_Latn-fas_Arab",
        "languages": [
          "swe-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.032281,
        "recall": 0.059089,
        "f1": 0.038396,
        "accuracy": 0.059089,
        "main_score": 0.038396,
        "hf_subset": "swe_Latn-fin_Latn",
        "languages": [
          "swe-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.013531,
        "recall": 0.024036,
        "f1": 0.015362,
        "accuracy": 0.024036,
        "main_score": 0.015362,
        "hf_subset": "swe_Latn-fra_Latn",
        "languages": [
          "swe-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.004586,
        "recall": 0.016024,
        "f1": 0.005977,
        "accuracy": 0.016024,
        "main_score": 0.005977,
        "hf_subset": "swe_Latn-heb_Hebr",
        "languages": [
          "swe-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.008782,
        "recall": 0.017526,
        "f1": 0.010265,
        "accuracy": 0.017526,
        "main_score": 0.010265,
        "hf_subset": "swe_Latn-hin_Deva",
        "languages": [
          "swe-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.034754,
        "recall": 0.056084,
        "f1": 0.040384,
        "accuracy": 0.056084,
        "main_score": 0.040384,
        "hf_subset": "swe_Latn-hun_Latn",
        "languages": [
          "swe-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.071954,
        "recall": 0.10666,
        "f1": 0.080341,
        "accuracy": 0.10666,
        "main_score": 0.080341,
        "hf_subset": "swe_Latn-ind_Latn",
        "languages": [
          "swe-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.021037,
        "recall": 0.037556,
        "f1": 0.024275,
        "accuracy": 0.037556,
        "main_score": 0.024275,
        "hf_subset": "swe_Latn-isl_Latn",
        "languages": [
          "swe-Latn",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.005499,
        "recall": 0.008513,
        "f1": 0.005966,
        "accuracy": 0.008513,
        "main_score": 0.005966,
        "hf_subset": "swe_Latn-jpn_Jpan",
        "languages": [
          "swe-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.00851,
        "recall": 0.017026,
        "f1": 0.010091,
        "accuracy": 0.017026,
        "main_score": 0.010091,
        "hf_subset": "swe_Latn-kor_Hang",
        "languages": [
          "swe-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.030508,
        "recall": 0.049574,
        "f1": 0.034902,
        "accuracy": 0.049574,
        "main_score": 0.034902,
        "hf_subset": "swe_Latn-lit_Latn",
        "languages": [
          "swe-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.047716,
        "recall": 0.075113,
        "f1": 0.053978,
        "accuracy": 0.075113,
        "main_score": 0.053978,
        "hf_subset": "swe_Latn-ltz_Latn",
        "languages": [
          "swe-Latn",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.054481,
        "recall": 0.083125,
        "f1": 0.061572,
        "accuracy": 0.083125,
        "main_score": 0.061572,
        "hf_subset": "swe_Latn-nld_Latn",
        "languages": [
          "swe-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.085174,
        "recall": 0.123185,
        "f1": 0.094688,
        "accuracy": 0.123185,
        "main_score": 0.094688,
        "hf_subset": "swe_Latn-nno_Latn",
        "languages": [
          "swe-Latn",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.109879,
        "recall": 0.155734,
        "f1": 0.121444,
        "accuracy": 0.155734,
        "main_score": 0.121444,
        "hf_subset": "swe_Latn-nob_Latn",
        "languages": [
          "swe-Latn",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.026542,
        "recall": 0.050576,
        "f1": 0.03095,
        "accuracy": 0.050576,
        "main_score": 0.03095,
        "hf_subset": "swe_Latn-pol_Latn",
        "languages": [
          "swe-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.033362,
        "recall": 0.051577,
        "f1": 0.037532,
        "accuracy": 0.051577,
        "main_score": 0.037532,
        "hf_subset": "swe_Latn-por_Latn",
        "languages": [
          "swe-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.015714,
        "recall": 0.03355,
        "f1": 0.01852,
        "accuracy": 0.03355,
        "main_score": 0.01852,
        "hf_subset": "swe_Latn-rus_Cyrl",
        "languages": [
          "swe-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.045605,
        "recall": 0.077116,
        "f1": 0.052716,
        "accuracy": 0.077116,
        "main_score": 0.052716,
        "hf_subset": "swe_Latn-spa_Latn",
        "languages": [
          "swe-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.037017,
        "recall": 0.064597,
        "f1": 0.043445,
        "accuracy": 0.064597,
        "main_score": 0.043445,
        "hf_subset": "swe_Latn-swa_Latn",
        "languages": [
          "swe-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.003349,
        "recall": 0.005508,
        "f1": 0.003693,
        "accuracy": 0.005508,
        "main_score": 0.003693,
        "hf_subset": "swe_Latn-tam_Taml",
        "languages": [
          "swe-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.030239,
        "recall": 0.05358,
        "f1": 0.035043,
        "accuracy": 0.05358,
        "main_score": 0.035043,
        "hf_subset": "swe_Latn-tur_Latn",
        "languages": [
          "swe-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.041483,
        "recall": 0.072609,
        "f1": 0.048554,
        "accuracy": 0.072609,
        "main_score": 0.048554,
        "hf_subset": "swe_Latn-vie_Latn",
        "languages": [
          "swe-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.016549,
        "recall": 0.027041,
        "f1": 0.018411,
        "accuracy": 0.027041,
        "main_score": 0.018411,
        "hf_subset": "swe_Latn-zho_Hant",
        "languages": [
          "swe-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.015309,
        "recall": 0.029544,
        "f1": 0.017679,
        "accuracy": 0.029544,
        "main_score": 0.017679,
        "hf_subset": "swe_Latn-zul_Latn",
        "languages": [
          "swe-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.040488,
        "recall": 0.054081,
        "f1": 0.043447,
        "accuracy": 0.054081,
        "main_score": 0.043447,
        "hf_subset": "tah_Latn-eng_Latn",
        "languages": [
          "tah-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.024284,
        "recall": 0.035553,
        "f1": 0.026977,
        "accuracy": 0.035553,
        "main_score": 0.026977,
        "hf_subset": "tah_Latn-fij_Latn",
        "languages": [
          "tah-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.029966,
        "recall": 0.041562,
        "f1": 0.032734,
        "accuracy": 0.041562,
        "main_score": 0.032734,
        "hf_subset": "tah_Latn-fil_Latn",
        "languages": [
          "tah-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.037945,
        "recall": 0.051077,
        "f1": 0.040676,
        "accuracy": 0.051077,
        "main_score": 0.040676,
        "hf_subset": "tah_Latn-ind_Latn",
        "languages": [
          "tah-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.000751,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "tah_Latn-mal_Mlym",
        "languages": [
          "tah-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.017188,
        "recall": 0.028543,
        "f1": 0.019559,
        "accuracy": 0.028543,
        "main_score": 0.019559,
        "hf_subset": "tah_Latn-mlg_Latn",
        "languages": [
          "tah-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.034899,
        "recall": 0.047071,
        "f1": 0.037617,
        "accuracy": 0.047071,
        "main_score": 0.037617,
        "hf_subset": "tah_Latn-mri_Latn",
        "languages": [
          "tah-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.033843,
        "recall": 0.04657,
        "f1": 0.036414,
        "accuracy": 0.04657,
        "main_score": 0.036414,
        "hf_subset": "tah_Latn-msa_Latn",
        "languages": [
          "tah-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.02901,
        "recall": 0.043565,
        "f1": 0.032186,
        "accuracy": 0.043565,
        "main_score": 0.032186,
        "hf_subset": "tah_Latn-smo_Latn",
        "languages": [
          "tah-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.001378,
        "recall": 0.004507,
        "f1": 0.001561,
        "accuracy": 0.004507,
        "main_score": 0.001561,
        "hf_subset": "tah_Latn-ton_Latn",
        "languages": [
          "tah-Latn",
          "ton-Latn"
        ]
      },
      {
        "precision": 0.002115,
        "recall": 0.005008,
        "f1": 0.002207,
        "accuracy": 0.005008,
        "main_score": 0.002207,
        "hf_subset": "tam_Taml-arb_Arab",
        "languages": [
          "tam-Taml",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.006471,
        "recall": 0.012519,
        "f1": 0.007688,
        "accuracy": 0.012519,
        "main_score": 0.007688,
        "hf_subset": "tam_Taml-ben_Beng",
        "languages": [
          "tam-Taml",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.003874,
        "recall": 0.006009,
        "f1": 0.004208,
        "accuracy": 0.006009,
        "main_score": 0.004208,
        "hf_subset": "tam_Taml-deu_Latn",
        "languages": [
          "tam-Taml",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.007315,
        "recall": 0.016024,
        "f1": 0.008454,
        "accuracy": 0.016024,
        "main_score": 0.008454,
        "hf_subset": "tam_Taml-div_Thaa",
        "languages": [
          "tam-Taml",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.002239,
        "recall": 0.00651,
        "f1": 0.002387,
        "accuracy": 0.00651,
        "main_score": 0.002387,
        "hf_subset": "tam_Taml-ell_Grek",
        "languages": [
          "tam-Taml",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.003216,
        "recall": 0.006009,
        "f1": 0.003362,
        "accuracy": 0.006009,
        "main_score": 0.003362,
        "hf_subset": "tam_Taml-eng_Latn",
        "languages": [
          "tam-Taml",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.004771,
        "recall": 0.007511,
        "f1": 0.005475,
        "accuracy": 0.007511,
        "main_score": 0.005475,
        "hf_subset": "tam_Taml-eus_Latn",
        "languages": [
          "tam-Taml",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.001252,
        "recall": 0.001502,
        "f1": 0.001335,
        "accuracy": 0.001502,
        "main_score": 0.001335,
        "hf_subset": "tam_Taml-fas_Arab",
        "languages": [
          "tam-Taml",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.002212,
        "recall": 0.004006,
        "f1": 0.002557,
        "accuracy": 0.004006,
        "main_score": 0.002557,
        "hf_subset": "tam_Taml-fin_Latn",
        "languages": [
          "tam-Taml",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.006173,
        "recall": 0.011017,
        "f1": 0.007121,
        "accuracy": 0.011017,
        "main_score": 0.007121,
        "hf_subset": "tam_Taml-fra_Latn",
        "languages": [
          "tam-Taml",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.029074,
        "recall": 0.044066,
        "f1": 0.032453,
        "accuracy": 0.044066,
        "main_score": 0.032453,
        "hf_subset": "tam_Taml-guj_Gujr",
        "languages": [
          "tam-Taml",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.001622,
        "recall": 0.006009,
        "f1": 0.002155,
        "accuracy": 0.006009,
        "main_score": 0.002155,
        "hf_subset": "tam_Taml-heb_Hebr",
        "languages": [
          "tam-Taml",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.002046,
        "recall": 0.006009,
        "f1": 0.002504,
        "accuracy": 0.006009,
        "main_score": 0.002504,
        "hf_subset": "tam_Taml-hin_Deva",
        "languages": [
          "tam-Taml",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001127,
        "recall": 0.003505,
        "f1": 0.001389,
        "accuracy": 0.003505,
        "main_score": 0.001389,
        "hf_subset": "tam_Taml-hun_Latn",
        "languages": [
          "tam-Taml",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.00271,
        "recall": 0.006009,
        "f1": 0.003046,
        "accuracy": 0.006009,
        "main_score": 0.003046,
        "hf_subset": "tam_Taml-ind_Latn",
        "languages": [
          "tam-Taml",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.00674,
        "recall": 0.011017,
        "f1": 0.007257,
        "accuracy": 0.011017,
        "main_score": 0.007257,
        "hf_subset": "tam_Taml-jpn_Jpan",
        "languages": [
          "tam-Taml",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.042885,
        "recall": 0.067601,
        "f1": 0.048128,
        "accuracy": 0.067601,
        "main_score": 0.048128,
        "hf_subset": "tam_Taml-kan_Knda",
        "languages": [
          "tam-Taml",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.002468,
        "recall": 0.006009,
        "f1": 0.002743,
        "accuracy": 0.006009,
        "main_score": 0.002743,
        "hf_subset": "tam_Taml-kor_Hang",
        "languages": [
          "tam-Taml",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.000785,
        "recall": 0.002003,
        "f1": 0.000898,
        "accuracy": 0.002003,
        "main_score": 0.000898,
        "hf_subset": "tam_Taml-lit_Latn",
        "languages": [
          "tam-Taml",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.004071,
        "recall": 0.010516,
        "f1": 0.004859,
        "accuracy": 0.010516,
        "main_score": 0.004859,
        "hf_subset": "tam_Taml-mar_Deva",
        "languages": [
          "tam-Taml",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005759,
        "recall": 0.008012,
        "f1": 0.006137,
        "accuracy": 0.008012,
        "main_score": 0.006137,
        "hf_subset": "tam_Taml-nep_Deva",
        "languages": [
          "tam-Taml",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.003584,
        "recall": 0.005508,
        "f1": 0.00382,
        "accuracy": 0.005508,
        "main_score": 0.00382,
        "hf_subset": "tam_Taml-nld_Latn",
        "languages": [
          "tam-Taml",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.00435,
        "recall": 0.009514,
        "f1": 0.005192,
        "accuracy": 0.009514,
        "main_score": 0.005192,
        "hf_subset": "tam_Taml-pan_Guru",
        "languages": [
          "tam-Taml",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.002524,
        "recall": 0.004507,
        "f1": 0.002762,
        "accuracy": 0.004507,
        "main_score": 0.002762,
        "hf_subset": "tam_Taml-pol_Latn",
        "languages": [
          "tam-Taml",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.003957,
        "recall": 0.008012,
        "f1": 0.004201,
        "accuracy": 0.008012,
        "main_score": 0.004201,
        "hf_subset": "tam_Taml-por_Latn",
        "languages": [
          "tam-Taml",
          "por-Latn"
        ]
      },
      {
        "precision": 0.002513,
        "recall": 0.006009,
        "f1": 0.002779,
        "accuracy": 0.006009,
        "main_score": 0.002779,
        "hf_subset": "tam_Taml-rus_Cyrl",
        "languages": [
          "tam-Taml",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.015014,
        "recall": 0.031047,
        "f1": 0.017863,
        "accuracy": 0.031047,
        "main_score": 0.017863,
        "hf_subset": "tam_Taml-sin_Sinh",
        "languages": [
          "tam-Taml",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.00408,
        "recall": 0.007511,
        "f1": 0.004696,
        "accuracy": 0.007511,
        "main_score": 0.004696,
        "hf_subset": "tam_Taml-snd_Arab",
        "languages": [
          "tam-Taml",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.002768,
        "recall": 0.005008,
        "f1": 0.003139,
        "accuracy": 0.005008,
        "main_score": 0.003139,
        "hf_subset": "tam_Taml-spa_Latn",
        "languages": [
          "tam-Taml",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.003721,
        "recall": 0.00651,
        "f1": 0.003888,
        "accuracy": 0.00651,
        "main_score": 0.003888,
        "hf_subset": "tam_Taml-swa_Latn",
        "languages": [
          "tam-Taml",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.002971,
        "recall": 0.005008,
        "f1": 0.003273,
        "accuracy": 0.005008,
        "main_score": 0.003273,
        "hf_subset": "tam_Taml-swe_Latn",
        "languages": [
          "tam-Taml",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.005015,
        "recall": 0.012519,
        "f1": 0.005949,
        "accuracy": 0.012519,
        "main_score": 0.005949,
        "hf_subset": "tam_Taml-tel_Telu",
        "languages": [
          "tam-Taml",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004222,
        "recall": 0.00651,
        "f1": 0.004555,
        "accuracy": 0.00651,
        "main_score": 0.004555,
        "hf_subset": "tam_Taml-tur_Latn",
        "languages": [
          "tam-Taml",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.003077,
        "recall": 0.004006,
        "f1": 0.003131,
        "accuracy": 0.004006,
        "main_score": 0.003131,
        "hf_subset": "tam_Taml-urd_Arab",
        "languages": [
          "tam-Taml",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.001753,
        "recall": 0.002504,
        "f1": 0.001837,
        "accuracy": 0.002504,
        "main_score": 0.001837,
        "hf_subset": "tam_Taml-vie_Latn",
        "languages": [
          "tam-Taml",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.001214,
        "recall": 0.003505,
        "f1": 0.001359,
        "accuracy": 0.003505,
        "main_score": 0.001359,
        "hf_subset": "tam_Taml-zho_Hant",
        "languages": [
          "tam-Taml",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.001066,
        "recall": 0.003005,
        "f1": 0.001288,
        "accuracy": 0.003005,
        "main_score": 0.001288,
        "hf_subset": "tam_Taml-zul_Latn",
        "languages": [
          "tam-Taml",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002375,
        "recall": 0.004507,
        "f1": 0.002743,
        "accuracy": 0.004507,
        "main_score": 0.002743,
        "hf_subset": "tat_Cyrl-aze_Latn",
        "languages": [
          "tat-Cyrl",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.039055,
        "recall": 0.060591,
        "f1": 0.04338,
        "accuracy": 0.060591,
        "main_score": 0.04338,
        "hf_subset": "tat_Cyrl-bak_Cyrl",
        "languages": [
          "tat-Cyrl",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.005682,
        "recall": 0.009514,
        "f1": 0.00604,
        "accuracy": 0.009514,
        "main_score": 0.00604,
        "hf_subset": "tat_Cyrl-eng_Latn",
        "languages": [
          "tat-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.013616,
        "recall": 0.016525,
        "f1": 0.014212,
        "accuracy": 0.016525,
        "main_score": 0.014212,
        "hf_subset": "tat_Cyrl-kaz_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.014469,
        "recall": 0.019029,
        "f1": 0.01536,
        "accuracy": 0.019029,
        "main_score": 0.01536,
        "hf_subset": "tat_Cyrl-kir_Cyrl",
        "languages": [
          "tat-Cyrl",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.003381,
        "recall": 0.005508,
        "f1": 0.003875,
        "accuracy": 0.005508,
        "main_score": 0.003875,
        "hf_subset": "tat_Cyrl-tuk_Latn",
        "languages": [
          "tat-Cyrl",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.003969,
        "recall": 0.005508,
        "f1": 0.004178,
        "accuracy": 0.005508,
        "main_score": 0.004178,
        "hf_subset": "tat_Cyrl-tur_Latn",
        "languages": [
          "tat-Cyrl",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.002094,
        "recall": 0.004006,
        "f1": 0.002169,
        "accuracy": 0.004006,
        "main_score": 0.002169,
        "hf_subset": "tat_Cyrl-uig_Arab",
        "languages": [
          "tat-Cyrl",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.002293,
        "recall": 0.004006,
        "f1": 0.002631,
        "accuracy": 0.004006,
        "main_score": 0.002631,
        "hf_subset": "tat_Cyrl-uzb_Latn",
        "languages": [
          "tat-Cyrl",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.006816,
        "recall": 0.014021,
        "f1": 0.007965,
        "accuracy": 0.014021,
        "main_score": 0.007965,
        "hf_subset": "tel_Telu-ben_Beng",
        "languages": [
          "tel-Telu",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.004623,
        "recall": 0.012018,
        "f1": 0.005488,
        "accuracy": 0.012018,
        "main_score": 0.005488,
        "hf_subset": "tel_Telu-div_Thaa",
        "languages": [
          "tel-Telu",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.014375,
        "recall": 0.023535,
        "f1": 0.016379,
        "accuracy": 0.023535,
        "main_score": 0.016379,
        "hf_subset": "tel_Telu-eng_Latn",
        "languages": [
          "tel-Telu",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011807,
        "recall": 0.017526,
        "f1": 0.012933,
        "accuracy": 0.017526,
        "main_score": 0.012933,
        "hf_subset": "tel_Telu-eus_Latn",
        "languages": [
          "tel-Telu",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.012547,
        "recall": 0.018528,
        "f1": 0.013521,
        "accuracy": 0.018528,
        "main_score": 0.013521,
        "hf_subset": "tel_Telu-guj_Gujr",
        "languages": [
          "tel-Telu",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.012548,
        "recall": 0.019529,
        "f1": 0.013917,
        "accuracy": 0.019529,
        "main_score": 0.013917,
        "hf_subset": "tel_Telu-hin_Deva",
        "languages": [
          "tel-Telu",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020158,
        "recall": 0.029544,
        "f1": 0.021724,
        "accuracy": 0.029544,
        "main_score": 0.021724,
        "hf_subset": "tel_Telu-kan_Knda",
        "languages": [
          "tel-Telu",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.009508,
        "recall": 0.016024,
        "f1": 0.010726,
        "accuracy": 0.016024,
        "main_score": 0.010726,
        "hf_subset": "tel_Telu-mar_Deva",
        "languages": [
          "tel-Telu",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.008576,
        "recall": 0.017026,
        "f1": 0.010258,
        "accuracy": 0.017026,
        "main_score": 0.010258,
        "hf_subset": "tel_Telu-nep_Deva",
        "languages": [
          "tel-Telu",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.006926,
        "recall": 0.012519,
        "f1": 0.008082,
        "accuracy": 0.012519,
        "main_score": 0.008082,
        "hf_subset": "tel_Telu-pan_Guru",
        "languages": [
          "tel-Telu",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.006818,
        "recall": 0.01352,
        "f1": 0.007754,
        "accuracy": 0.01352,
        "main_score": 0.007754,
        "hf_subset": "tel_Telu-sin_Sinh",
        "languages": [
          "tel-Telu",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002851,
        "recall": 0.009014,
        "f1": 0.00397,
        "accuracy": 0.009014,
        "main_score": 0.00397,
        "hf_subset": "tel_Telu-snd_Arab",
        "languages": [
          "tel-Telu",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.009938,
        "recall": 0.018528,
        "f1": 0.011305,
        "accuracy": 0.018528,
        "main_score": 0.011305,
        "hf_subset": "tel_Telu-tam_Taml",
        "languages": [
          "tel-Telu",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.00838,
        "recall": 0.012018,
        "f1": 0.009008,
        "accuracy": 0.012018,
        "main_score": 0.009008,
        "hf_subset": "tel_Telu-urd_Arab",
        "languages": [
          "tel-Telu",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.003883,
        "recall": 0.006009,
        "f1": 0.004315,
        "accuracy": 0.006009,
        "main_score": 0.004315,
        "hf_subset": "tgk_Cyrl-arb_Arab",
        "languages": [
          "tgk-Cyrl",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001385,
        "recall": 0.004006,
        "f1": 0.001599,
        "accuracy": 0.004006,
        "main_score": 0.001599,
        "hf_subset": "tgk_Cyrl-ckb_Arab",
        "languages": [
          "tgk-Cyrl",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.007764,
        "recall": 0.010015,
        "f1": 0.008105,
        "accuracy": 0.010015,
        "main_score": 0.008105,
        "hf_subset": "tgk_Cyrl-eng_Latn",
        "languages": [
          "tgk-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.005079,
        "recall": 0.007011,
        "f1": 0.005533,
        "accuracy": 0.007011,
        "main_score": 0.005533,
        "hf_subset": "tgk_Cyrl-fas_Arab",
        "languages": [
          "tgk-Cyrl",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.001669,
        "recall": 0.002003,
        "f1": 0.001753,
        "accuracy": 0.002003,
        "main_score": 0.001753,
        "hf_subset": "tgk_Cyrl-heb_Hebr",
        "languages": [
          "tgk-Cyrl",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.002959,
        "recall": 0.005008,
        "f1": 0.003348,
        "accuracy": 0.005008,
        "main_score": 0.003348,
        "hf_subset": "tgk_Cyrl-kmr_Latn",
        "languages": [
          "tgk-Cyrl",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.001615,
        "recall": 0.003005,
        "f1": 0.001693,
        "accuracy": 0.003005,
        "main_score": 0.001693,
        "hf_subset": "tgk_Cyrl-mey_Arab",
        "languages": [
          "tgk-Cyrl",
          "mey-Arab"
        ]
      },
      {
        "precision": 0.007681,
        "recall": 0.010015,
        "f1": 0.00817,
        "accuracy": 0.010015,
        "main_score": 0.00817,
        "hf_subset": "tgk_Cyrl-prs_Arab",
        "languages": [
          "tgk-Cyrl",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.00338,
        "recall": 0.004006,
        "f1": 0.003539,
        "accuracy": 0.004006,
        "main_score": 0.003539,
        "hf_subset": "tgk_Cyrl-pus_Arab",
        "languages": [
          "tgk-Cyrl",
          "pus-Arab"
        ]
      },
      {
        "precision": 0.002859,
        "recall": 0.004507,
        "f1": 0.003073,
        "accuracy": 0.004507,
        "main_score": 0.003073,
        "hf_subset": "tgk_Cyrl-shi_Arab",
        "languages": [
          "tgk-Cyrl",
          "shi-Arab"
        ]
      },
      {
        "precision": 0.006203,
        "recall": 0.014021,
        "f1": 0.0077,
        "accuracy": 0.014021,
        "main_score": 0.0077,
        "hf_subset": "tha_Thai-bod_Tibt",
        "languages": [
          "tha-Thai",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.003078,
        "recall": 0.007511,
        "f1": 0.003962,
        "accuracy": 0.007511,
        "main_score": 0.003962,
        "hf_subset": "tha_Thai-dzo_Tibt",
        "languages": [
          "tha-Thai",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.03526,
        "recall": 0.05358,
        "f1": 0.039183,
        "accuracy": 0.05358,
        "main_score": 0.039183,
        "hf_subset": "tha_Thai-eng_Latn",
        "languages": [
          "tha-Thai",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003964,
        "recall": 0.005508,
        "f1": 0.004373,
        "accuracy": 0.005508,
        "main_score": 0.004373,
        "hf_subset": "tha_Thai-khm_Khmr",
        "languages": [
          "tha-Thai",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.007382,
        "recall": 0.010516,
        "f1": 0.008052,
        "accuracy": 0.010516,
        "main_score": 0.008052,
        "hf_subset": "tha_Thai-lao_Laoo",
        "languages": [
          "tha-Thai",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.00671,
        "recall": 0.01302,
        "f1": 0.007985,
        "accuracy": 0.01302,
        "main_score": 0.007985,
        "hf_subset": "tha_Thai-mon_Mong",
        "languages": [
          "tha-Thai",
          "mon-Mong"
        ]
      },
      {
        "precision": 0.001901,
        "recall": 0.005008,
        "f1": 0.002456,
        "accuracy": 0.005008,
        "main_score": 0.002456,
        "hf_subset": "tha_Thai-mya_Mymr",
        "languages": [
          "tha-Thai",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.021403,
        "recall": 0.03355,
        "f1": 0.023187,
        "accuracy": 0.03355,
        "main_score": 0.023187,
        "hf_subset": "tir_Ethi-amh_Ethi",
        "languages": [
          "tir-Ethi",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.002003,
        "f1": 0.00117,
        "accuracy": 0.002003,
        "main_score": 0.00117,
        "hf_subset": "tir_Ethi-eng_Latn",
        "languages": [
          "tir-Ethi",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "tir_Ethi-hau_Latn",
        "languages": [
          "tir-Ethi",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "tir_Ethi-ibo_Latn",
        "languages": [
          "tir-Ethi",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.001006,
        "recall": 0.002504,
        "f1": 0.00101,
        "accuracy": 0.002504,
        "main_score": 0.00101,
        "hf_subset": "tir_Ethi-nso_Latn",
        "languages": [
          "tir-Ethi",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.001252,
        "recall": 0.002003,
        "f1": 0.001336,
        "accuracy": 0.002003,
        "main_score": 0.001336,
        "hf_subset": "tir_Ethi-orm_Ethi",
        "languages": [
          "tir-Ethi",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.001252,
        "recall": 0.002003,
        "f1": 0.001336,
        "accuracy": 0.002003,
        "main_score": 0.001336,
        "hf_subset": "tir_Ethi-som_Latn",
        "languages": [
          "tir-Ethi",
          "som-Latn"
        ]
      },
      {
        "precision": 0.000502,
        "recall": 0.001002,
        "f1": 0.000503,
        "accuracy": 0.001002,
        "main_score": 0.000503,
        "hf_subset": "tir_Ethi-ssw_Latn",
        "languages": [
          "tir-Ethi",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.001085,
        "recall": 0.001502,
        "f1": 0.001145,
        "accuracy": 0.001502,
        "main_score": 0.001145,
        "hf_subset": "tir_Ethi-swa_Latn",
        "languages": [
          "tir-Ethi",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000938,
        "recall": 0.003005,
        "f1": 0.001123,
        "accuracy": 0.003005,
        "main_score": 0.001123,
        "hf_subset": "tir_Ethi-tsn_Latn",
        "languages": [
          "tir-Ethi",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.001669,
        "recall": 0.002504,
        "f1": 0.001753,
        "accuracy": 0.002504,
        "main_score": 0.001753,
        "hf_subset": "tir_Ethi-wol_Latn",
        "languages": [
          "tir-Ethi",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "tir_Ethi-xho_Latn",
        "languages": [
          "tir-Ethi",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "tir_Ethi-yor_Latn",
        "languages": [
          "tir-Ethi",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000501,
        "accuracy": 0.001002,
        "main_score": 0.000501,
        "hf_subset": "tir_Ethi-zul_Latn",
        "languages": [
          "tir-Ethi",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.003012,
        "recall": 0.005008,
        "f1": 0.003186,
        "accuracy": 0.005008,
        "main_score": 0.003186,
        "hf_subset": "ton_Latn-eng_Latn",
        "languages": [
          "ton-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.001291,
        "recall": 0.003005,
        "f1": 0.001408,
        "accuracy": 0.003005,
        "main_score": 0.001408,
        "hf_subset": "ton_Latn-fij_Latn",
        "languages": [
          "ton-Latn",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.002325,
        "recall": 0.004507,
        "f1": 0.002465,
        "accuracy": 0.004507,
        "main_score": 0.002465,
        "hf_subset": "ton_Latn-fil_Latn",
        "languages": [
          "ton-Latn",
          "fil-Latn"
        ]
      },
      {
        "precision": 0.002172,
        "recall": 0.003505,
        "f1": 0.002258,
        "accuracy": 0.003505,
        "main_score": 0.002258,
        "hf_subset": "ton_Latn-ind_Latn",
        "languages": [
          "ton-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001003,
        "accuracy": 0.001502,
        "main_score": 0.001003,
        "hf_subset": "ton_Latn-mal_Mlym",
        "languages": [
          "ton-Latn",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.001772,
        "recall": 0.003505,
        "f1": 0.001873,
        "accuracy": 0.003505,
        "main_score": 0.001873,
        "hf_subset": "ton_Latn-mlg_Latn",
        "languages": [
          "ton-Latn",
          "mlg-Latn"
        ]
      },
      {
        "precision": 0.001011,
        "recall": 0.002003,
        "f1": 0.001021,
        "accuracy": 0.002003,
        "main_score": 0.001021,
        "hf_subset": "ton_Latn-mri_Latn",
        "languages": [
          "ton-Latn",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.003579,
        "recall": 0.005008,
        "f1": 0.003635,
        "accuracy": 0.005008,
        "main_score": 0.003635,
        "hf_subset": "ton_Latn-msa_Latn",
        "languages": [
          "ton-Latn",
          "msa-Latn"
        ]
      },
      {
        "precision": 0.002268,
        "recall": 0.003005,
        "f1": 0.002365,
        "accuracy": 0.003005,
        "main_score": 0.002365,
        "hf_subset": "ton_Latn-smo_Latn",
        "languages": [
          "ton-Latn",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.002549,
        "recall": 0.003505,
        "f1": 0.002591,
        "accuracy": 0.003505,
        "main_score": 0.002591,
        "hf_subset": "ton_Latn-tah_Latn",
        "languages": [
          "ton-Latn",
          "tah-Latn"
        ]
      },
      {
        "precision": 0.000503,
        "recall": 0.001502,
        "f1": 0.000505,
        "accuracy": 0.001502,
        "main_score": 0.000505,
        "hf_subset": "tsn_Latn-amh_Ethi",
        "languages": [
          "tsn-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.034629,
        "recall": 0.054582,
        "f1": 0.039005,
        "accuracy": 0.054582,
        "main_score": 0.039005,
        "hf_subset": "tsn_Latn-eng_Latn",
        "languages": [
          "tsn-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.030858,
        "recall": 0.048072,
        "f1": 0.034876,
        "accuracy": 0.048072,
        "main_score": 0.034876,
        "hf_subset": "tsn_Latn-hau_Latn",
        "languages": [
          "tsn-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.036768,
        "recall": 0.051577,
        "f1": 0.039831,
        "accuracy": 0.051577,
        "main_score": 0.039831,
        "hf_subset": "tsn_Latn-ibo_Latn",
        "languages": [
          "tsn-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.074085,
        "recall": 0.104657,
        "f1": 0.082009,
        "accuracy": 0.104657,
        "main_score": 0.082009,
        "hf_subset": "tsn_Latn-nso_Latn",
        "languages": [
          "tsn-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.017583,
        "recall": 0.029044,
        "f1": 0.019924,
        "accuracy": 0.029044,
        "main_score": 0.019924,
        "hf_subset": "tsn_Latn-orm_Ethi",
        "languages": [
          "tsn-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.019139,
        "recall": 0.041062,
        "f1": 0.023163,
        "accuracy": 0.041062,
        "main_score": 0.023163,
        "hf_subset": "tsn_Latn-som_Latn",
        "languages": [
          "tsn-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.021547,
        "recall": 0.041062,
        "f1": 0.025393,
        "accuracy": 0.041062,
        "main_score": 0.025393,
        "hf_subset": "tsn_Latn-ssw_Latn",
        "languages": [
          "tsn-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.048965,
        "recall": 0.069604,
        "f1": 0.053945,
        "accuracy": 0.069604,
        "main_score": 0.053945,
        "hf_subset": "tsn_Latn-swa_Latn",
        "languages": [
          "tsn-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001002,
        "recall": 0.001502,
        "f1": 0.001002,
        "accuracy": 0.001502,
        "main_score": 0.001002,
        "hf_subset": "tsn_Latn-tir_Ethi",
        "languages": [
          "tsn-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.016892,
        "recall": 0.028042,
        "f1": 0.018828,
        "accuracy": 0.028042,
        "main_score": 0.018828,
        "hf_subset": "tsn_Latn-wol_Latn",
        "languages": [
          "tsn-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.015964,
        "recall": 0.027041,
        "f1": 0.01823,
        "accuracy": 0.027041,
        "main_score": 0.01823,
        "hf_subset": "tsn_Latn-xho_Latn",
        "languages": [
          "tsn-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.008544,
        "recall": 0.021532,
        "f1": 0.010519,
        "accuracy": 0.021532,
        "main_score": 0.010519,
        "hf_subset": "tsn_Latn-yor_Latn",
        "languages": [
          "tsn-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.021683,
        "recall": 0.034552,
        "f1": 0.023984,
        "accuracy": 0.034552,
        "main_score": 0.023984,
        "hf_subset": "tsn_Latn-zul_Latn",
        "languages": [
          "tsn-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.014334,
        "recall": 0.022033,
        "f1": 0.015964,
        "accuracy": 0.022033,
        "main_score": 0.015964,
        "hf_subset": "tuk_Latn-aze_Latn",
        "languages": [
          "tuk-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.00121,
        "recall": 0.003005,
        "f1": 0.001355,
        "accuracy": 0.003005,
        "main_score": 0.001355,
        "hf_subset": "tuk_Latn-bak_Cyrl",
        "languages": [
          "tuk-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.02686,
        "recall": 0.037056,
        "f1": 0.028974,
        "accuracy": 0.037056,
        "main_score": 0.028974,
        "hf_subset": "tuk_Latn-eng_Latn",
        "languages": [
          "tuk-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.006828,
        "recall": 0.011017,
        "f1": 0.007656,
        "accuracy": 0.011017,
        "main_score": 0.007656,
        "hf_subset": "tuk_Latn-kaz_Cyrl",
        "languages": [
          "tuk-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.004634,
        "recall": 0.007011,
        "f1": 0.004959,
        "accuracy": 0.007011,
        "main_score": 0.004959,
        "hf_subset": "tuk_Latn-kir_Cyrl",
        "languages": [
          "tuk-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.00277,
        "recall": 0.005508,
        "f1": 0.003146,
        "accuracy": 0.005508,
        "main_score": 0.003146,
        "hf_subset": "tuk_Latn-tat_Cyrl",
        "languages": [
          "tuk-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.024271,
        "recall": 0.032048,
        "f1": 0.026316,
        "accuracy": 0.032048,
        "main_score": 0.026316,
        "hf_subset": "tuk_Latn-tur_Latn",
        "languages": [
          "tuk-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.001528,
        "recall": 0.003505,
        "f1": 0.00181,
        "accuracy": 0.003505,
        "main_score": 0.00181,
        "hf_subset": "tuk_Latn-uig_Arab",
        "languages": [
          "tuk-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.02018,
        "recall": 0.030045,
        "f1": 0.022455,
        "accuracy": 0.030045,
        "main_score": 0.022455,
        "hf_subset": "tuk_Latn-uzb_Latn",
        "languages": [
          "tuk-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.007335,
        "recall": 0.017526,
        "f1": 0.00898,
        "accuracy": 0.017526,
        "main_score": 0.00898,
        "hf_subset": "tur_Latn-arb_Arab",
        "languages": [
          "tur-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.026593,
        "recall": 0.047571,
        "f1": 0.030639,
        "accuracy": 0.047571,
        "main_score": 0.030639,
        "hf_subset": "tur_Latn-aze_Latn",
        "languages": [
          "tur-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.000839,
        "recall": 0.002003,
        "f1": 0.001011,
        "accuracy": 0.002003,
        "main_score": 0.001011,
        "hf_subset": "tur_Latn-bak_Cyrl",
        "languages": [
          "tur-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.003436,
        "recall": 0.007011,
        "f1": 0.003852,
        "accuracy": 0.007011,
        "main_score": 0.003852,
        "hf_subset": "tur_Latn-ben_Beng",
        "languages": [
          "tur-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.035619,
        "recall": 0.057586,
        "f1": 0.040558,
        "accuracy": 0.057586,
        "main_score": 0.040558,
        "hf_subset": "tur_Latn-deu_Latn",
        "languages": [
          "tur-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.010399,
        "recall": 0.019029,
        "f1": 0.011802,
        "accuracy": 0.019029,
        "main_score": 0.011802,
        "hf_subset": "tur_Latn-ell_Grek",
        "languages": [
          "tur-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.054269,
        "recall": 0.081622,
        "f1": 0.060995,
        "accuracy": 0.081622,
        "main_score": 0.060995,
        "hf_subset": "tur_Latn-eng_Latn",
        "languages": [
          "tur-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.020251,
        "recall": 0.037556,
        "f1": 0.023832,
        "accuracy": 0.037556,
        "main_score": 0.023832,
        "hf_subset": "tur_Latn-fas_Arab",
        "languages": [
          "tur-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.022179,
        "recall": 0.042063,
        "f1": 0.026334,
        "accuracy": 0.042063,
        "main_score": 0.026334,
        "hf_subset": "tur_Latn-fin_Latn",
        "languages": [
          "tur-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.012079,
        "recall": 0.022534,
        "f1": 0.014232,
        "accuracy": 0.022534,
        "main_score": 0.014232,
        "hf_subset": "tur_Latn-fra_Latn",
        "languages": [
          "tur-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.006653,
        "recall": 0.016024,
        "f1": 0.007909,
        "accuracy": 0.016024,
        "main_score": 0.007909,
        "hf_subset": "tur_Latn-heb_Hebr",
        "languages": [
          "tur-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.007741,
        "recall": 0.016024,
        "f1": 0.009296,
        "accuracy": 0.016024,
        "main_score": 0.009296,
        "hf_subset": "tur_Latn-hin_Deva",
        "languages": [
          "tur-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.027884,
        "recall": 0.044066,
        "f1": 0.031487,
        "accuracy": 0.044066,
        "main_score": 0.031487,
        "hf_subset": "tur_Latn-hun_Latn",
        "languages": [
          "tur-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.056286,
        "recall": 0.083625,
        "f1": 0.062899,
        "accuracy": 0.083625,
        "main_score": 0.062899,
        "hf_subset": "tur_Latn-ind_Latn",
        "languages": [
          "tur-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.004065,
        "recall": 0.010516,
        "f1": 0.004848,
        "accuracy": 0.010516,
        "main_score": 0.004848,
        "hf_subset": "tur_Latn-jpn_Jpan",
        "languages": [
          "tur-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.010718,
        "recall": 0.017526,
        "f1": 0.012,
        "accuracy": 0.017526,
        "main_score": 0.012,
        "hf_subset": "tur_Latn-kaz_Cyrl",
        "languages": [
          "tur-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.008769,
        "recall": 0.015523,
        "f1": 0.009821,
        "accuracy": 0.015523,
        "main_score": 0.009821,
        "hf_subset": "tur_Latn-kir_Cyrl",
        "languages": [
          "tur-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.008945,
        "recall": 0.018027,
        "f1": 0.010532,
        "accuracy": 0.018027,
        "main_score": 0.010532,
        "hf_subset": "tur_Latn-kor_Hang",
        "languages": [
          "tur-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.017741,
        "recall": 0.030546,
        "f1": 0.020736,
        "accuracy": 0.030546,
        "main_score": 0.020736,
        "hf_subset": "tur_Latn-lit_Latn",
        "languages": [
          "tur-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.034336,
        "recall": 0.059589,
        "f1": 0.039884,
        "accuracy": 0.059589,
        "main_score": 0.039884,
        "hf_subset": "tur_Latn-nld_Latn",
        "languages": [
          "tur-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.020561,
        "recall": 0.036054,
        "f1": 0.023506,
        "accuracy": 0.036054,
        "main_score": 0.023506,
        "hf_subset": "tur_Latn-pol_Latn",
        "languages": [
          "tur-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.029983,
        "recall": 0.055083,
        "f1": 0.03514,
        "accuracy": 0.055083,
        "main_score": 0.03514,
        "hf_subset": "tur_Latn-por_Latn",
        "languages": [
          "tur-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.013411,
        "recall": 0.025038,
        "f1": 0.015478,
        "accuracy": 0.025038,
        "main_score": 0.015478,
        "hf_subset": "tur_Latn-rus_Cyrl",
        "languages": [
          "tur-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.035917,
        "recall": 0.061092,
        "f1": 0.041409,
        "accuracy": 0.061092,
        "main_score": 0.041409,
        "hf_subset": "tur_Latn-spa_Latn",
        "languages": [
          "tur-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.039649,
        "recall": 0.063095,
        "f1": 0.045012,
        "accuracy": 0.063095,
        "main_score": 0.045012,
        "hf_subset": "tur_Latn-swa_Latn",
        "languages": [
          "tur-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.037458,
        "recall": 0.062093,
        "f1": 0.042356,
        "accuracy": 0.062093,
        "main_score": 0.042356,
        "hf_subset": "tur_Latn-swe_Latn",
        "languages": [
          "tur-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.002883,
        "recall": 0.005008,
        "f1": 0.00306,
        "accuracy": 0.005008,
        "main_score": 0.00306,
        "hf_subset": "tur_Latn-tam_Taml",
        "languages": [
          "tur-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.002216,
        "recall": 0.008012,
        "f1": 0.0029,
        "accuracy": 0.008012,
        "main_score": 0.0029,
        "hf_subset": "tur_Latn-tat_Cyrl",
        "languages": [
          "tur-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.012818,
        "recall": 0.023535,
        "f1": 0.014441,
        "accuracy": 0.023535,
        "main_score": 0.014441,
        "hf_subset": "tur_Latn-tuk_Latn",
        "languages": [
          "tur-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.001989,
        "recall": 0.003505,
        "f1": 0.002216,
        "accuracy": 0.003505,
        "main_score": 0.002216,
        "hf_subset": "tur_Latn-uig_Arab",
        "languages": [
          "tur-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.018962,
        "recall": 0.035053,
        "f1": 0.022073,
        "accuracy": 0.035053,
        "main_score": 0.022073,
        "hf_subset": "tur_Latn-uzb_Latn",
        "languages": [
          "tur-Latn",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.037167,
        "recall": 0.061592,
        "f1": 0.042707,
        "accuracy": 0.061592,
        "main_score": 0.042707,
        "hf_subset": "tur_Latn-vie_Latn",
        "languages": [
          "tur-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.016775,
        "recall": 0.028543,
        "f1": 0.019047,
        "accuracy": 0.028543,
        "main_score": 0.019047,
        "hf_subset": "tur_Latn-zho_Hant",
        "languages": [
          "tur-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.01779,
        "recall": 0.031547,
        "f1": 0.02084,
        "accuracy": 0.031547,
        "main_score": 0.02084,
        "hf_subset": "tur_Latn-zul_Latn",
        "languages": [
          "tur-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.002369,
        "recall": 0.005008,
        "f1": 0.002792,
        "accuracy": 0.005008,
        "main_score": 0.002792,
        "hf_subset": "uig_Arab-aze_Latn",
        "languages": [
          "uig-Arab",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.002392,
        "recall": 0.004006,
        "f1": 0.002747,
        "accuracy": 0.004006,
        "main_score": 0.002747,
        "hf_subset": "uig_Arab-bak_Cyrl",
        "languages": [
          "uig-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.002401,
        "recall": 0.004006,
        "f1": 0.002601,
        "accuracy": 0.004006,
        "main_score": 0.002601,
        "hf_subset": "uig_Arab-eng_Latn",
        "languages": [
          "uig-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.003426,
        "recall": 0.004507,
        "f1": 0.003598,
        "accuracy": 0.004507,
        "main_score": 0.003598,
        "hf_subset": "uig_Arab-kaz_Cyrl",
        "languages": [
          "uig-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.003466,
        "recall": 0.00651,
        "f1": 0.003942,
        "accuracy": 0.00651,
        "main_score": 0.003942,
        "hf_subset": "uig_Arab-kir_Cyrl",
        "languages": [
          "uig-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001796,
        "recall": 0.003005,
        "f1": 0.001916,
        "accuracy": 0.003005,
        "main_score": 0.001916,
        "hf_subset": "uig_Arab-tat_Cyrl",
        "languages": [
          "uig-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.001257,
        "recall": 0.002003,
        "f1": 0.001346,
        "accuracy": 0.002003,
        "main_score": 0.001346,
        "hf_subset": "uig_Arab-tuk_Latn",
        "languages": [
          "uig-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.001821,
        "recall": 0.003005,
        "f1": 0.001959,
        "accuracy": 0.003005,
        "main_score": 0.001959,
        "hf_subset": "uig_Arab-tur_Latn",
        "languages": [
          "uig-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.002262,
        "recall": 0.003505,
        "f1": 0.00244,
        "accuracy": 0.003505,
        "main_score": 0.00244,
        "hf_subset": "uig_Arab-uzb_Latn",
        "languages": [
          "uig-Arab",
          "uzb-Latn"
        ]
      },
      {
        "precision": 0.058003,
        "recall": 0.087631,
        "f1": 0.064528,
        "accuracy": 0.087631,
        "main_score": 0.064528,
        "hf_subset": "ukr_Cyrl-bel_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.012586,
        "recall": 0.021532,
        "f1": 0.014536,
        "accuracy": 0.021532,
        "main_score": 0.014536,
        "hf_subset": "ukr_Cyrl-bos_Latn",
        "languages": [
          "ukr-Cyrl",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.04282,
        "recall": 0.066099,
        "f1": 0.048211,
        "accuracy": 0.066099,
        "main_score": 0.048211,
        "hf_subset": "ukr_Cyrl-bul_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.01583,
        "recall": 0.025038,
        "f1": 0.017883,
        "accuracy": 0.025038,
        "main_score": 0.017883,
        "hf_subset": "ukr_Cyrl-ces_Latn",
        "languages": [
          "ukr-Cyrl",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.01481,
        "recall": 0.02654,
        "f1": 0.017304,
        "accuracy": 0.02654,
        "main_score": 0.017304,
        "hf_subset": "ukr_Cyrl-eng_Latn",
        "languages": [
          "ukr-Cyrl",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.015663,
        "recall": 0.025538,
        "f1": 0.017696,
        "accuracy": 0.025538,
        "main_score": 0.017696,
        "hf_subset": "ukr_Cyrl-hrv_Latn",
        "languages": [
          "ukr-Cyrl",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.026969,
        "recall": 0.040561,
        "f1": 0.030037,
        "accuracy": 0.040561,
        "main_score": 0.030037,
        "hf_subset": "ukr_Cyrl-mkd_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.012741,
        "recall": 0.023035,
        "f1": 0.015023,
        "accuracy": 0.023035,
        "main_score": 0.015023,
        "hf_subset": "ukr_Cyrl-pol_Latn",
        "languages": [
          "ukr-Cyrl",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.077098,
        "recall": 0.10666,
        "f1": 0.08457,
        "accuracy": 0.10666,
        "main_score": 0.08457,
        "hf_subset": "ukr_Cyrl-rus_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.007862,
        "recall": 0.018528,
        "f1": 0.009892,
        "accuracy": 0.018528,
        "main_score": 0.009892,
        "hf_subset": "ukr_Cyrl-slk_Latn",
        "languages": [
          "ukr-Cyrl",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.013471,
        "recall": 0.021032,
        "f1": 0.015133,
        "accuracy": 0.021032,
        "main_score": 0.015133,
        "hf_subset": "ukr_Cyrl-slv_Latn",
        "languages": [
          "ukr-Cyrl",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.021479,
        "recall": 0.031047,
        "f1": 0.023753,
        "accuracy": 0.031047,
        "main_score": 0.023753,
        "hf_subset": "ukr_Cyrl-srp_Cyrl",
        "languages": [
          "ukr-Cyrl",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.010901,
        "recall": 0.019029,
        "f1": 0.012577,
        "accuracy": 0.019029,
        "main_score": 0.012577,
        "hf_subset": "ukr_Cyrl-srp_Latn",
        "languages": [
          "ukr-Cyrl",
          "srp-Latn"
        ]
      },
      {
        "precision": 1.7e-05,
        "recall": 0.000501,
        "f1": 3.2e-05,
        "accuracy": 0.000501,
        "main_score": 3.2e-05,
        "hf_subset": "urd_Arab-ben_Beng",
        "languages": [
          "urd-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.002295,
        "recall": 0.003505,
        "f1": 0.002454,
        "accuracy": 0.003505,
        "main_score": 0.002454,
        "hf_subset": "urd_Arab-div_Thaa",
        "languages": [
          "urd-Arab",
          "div-Thaa"
        ]
      },
      {
        "precision": 0.025009,
        "recall": 0.038558,
        "f1": 0.027865,
        "accuracy": 0.038558,
        "main_score": 0.027865,
        "hf_subset": "urd_Arab-eng_Latn",
        "languages": [
          "urd-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.016227,
        "recall": 0.029044,
        "f1": 0.018581,
        "accuracy": 0.029044,
        "main_score": 0.018581,
        "hf_subset": "urd_Arab-eus_Latn",
        "languages": [
          "urd-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.001503,
        "recall": 0.002003,
        "f1": 0.001503,
        "accuracy": 0.002003,
        "main_score": 0.001503,
        "hf_subset": "urd_Arab-guj_Gujr",
        "languages": [
          "urd-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.009584,
        "recall": 0.019529,
        "f1": 0.011103,
        "accuracy": 0.019529,
        "main_score": 0.011103,
        "hf_subset": "urd_Arab-hin_Deva",
        "languages": [
          "urd-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.003005,
        "recall": 0.004006,
        "f1": 0.003172,
        "accuracy": 0.004006,
        "main_score": 0.003172,
        "hf_subset": "urd_Arab-kan_Knda",
        "languages": [
          "urd-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.003084,
        "recall": 0.00651,
        "f1": 0.003556,
        "accuracy": 0.00651,
        "main_score": 0.003556,
        "hf_subset": "urd_Arab-mar_Deva",
        "languages": [
          "urd-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.005158,
        "recall": 0.010516,
        "f1": 0.006004,
        "accuracy": 0.010516,
        "main_score": 0.006004,
        "hf_subset": "urd_Arab-nep_Deva",
        "languages": [
          "urd-Arab",
          "nep-Deva"
        ]
      },
      {
        "precision": 0.003909,
        "recall": 0.007011,
        "f1": 0.004515,
        "accuracy": 0.007011,
        "main_score": 0.004515,
        "hf_subset": "urd_Arab-pan_Guru",
        "languages": [
          "urd-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.00168,
        "recall": 0.003005,
        "f1": 0.001774,
        "accuracy": 0.003005,
        "main_score": 0.001774,
        "hf_subset": "urd_Arab-sin_Sinh",
        "languages": [
          "urd-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.005059,
        "recall": 0.008513,
        "f1": 0.005689,
        "accuracy": 0.008513,
        "main_score": 0.005689,
        "hf_subset": "urd_Arab-snd_Arab",
        "languages": [
          "urd-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.003027,
        "recall": 0.004006,
        "f1": 0.003047,
        "accuracy": 0.004006,
        "main_score": 0.003047,
        "hf_subset": "urd_Arab-tam_Taml",
        "languages": [
          "urd-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.006025,
        "recall": 0.010516,
        "f1": 0.006777,
        "accuracy": 0.010516,
        "main_score": 0.006777,
        "hf_subset": "urd_Arab-tel_Telu",
        "languages": [
          "urd-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.017119,
        "recall": 0.03355,
        "f1": 0.020459,
        "accuracy": 0.03355,
        "main_score": 0.020459,
        "hf_subset": "uzb_Latn-aze_Latn",
        "languages": [
          "uzb-Latn",
          "aze-Latn"
        ]
      },
      {
        "precision": 0.00106,
        "recall": 0.002504,
        "f1": 0.001318,
        "accuracy": 0.002504,
        "main_score": 0.001318,
        "hf_subset": "uzb_Latn-bak_Cyrl",
        "languages": [
          "uzb-Latn",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.022977,
        "recall": 0.036054,
        "f1": 0.02611,
        "accuracy": 0.036054,
        "main_score": 0.02611,
        "hf_subset": "uzb_Latn-eng_Latn",
        "languages": [
          "uzb-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.007976,
        "recall": 0.016525,
        "f1": 0.009341,
        "accuracy": 0.016525,
        "main_score": 0.009341,
        "hf_subset": "uzb_Latn-kaz_Cyrl",
        "languages": [
          "uzb-Latn",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.005362,
        "recall": 0.008513,
        "f1": 0.006097,
        "accuracy": 0.008513,
        "main_score": 0.006097,
        "hf_subset": "uzb_Latn-kir_Cyrl",
        "languages": [
          "uzb-Latn",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001367,
        "recall": 0.003505,
        "f1": 0.00173,
        "accuracy": 0.003505,
        "main_score": 0.00173,
        "hf_subset": "uzb_Latn-tat_Cyrl",
        "languages": [
          "uzb-Latn",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.015229,
        "recall": 0.024537,
        "f1": 0.017043,
        "accuracy": 0.024537,
        "main_score": 0.017043,
        "hf_subset": "uzb_Latn-tuk_Latn",
        "languages": [
          "uzb-Latn",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.022685,
        "recall": 0.040561,
        "f1": 0.026445,
        "accuracy": 0.040561,
        "main_score": 0.026445,
        "hf_subset": "uzb_Latn-tur_Latn",
        "languages": [
          "uzb-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.000956,
        "recall": 0.003005,
        "f1": 0.001348,
        "accuracy": 0.003005,
        "main_score": 0.001348,
        "hf_subset": "uzb_Latn-uig_Arab",
        "languages": [
          "uzb-Latn",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.030648,
        "recall": 0.045068,
        "f1": 0.034032,
        "accuracy": 0.045068,
        "main_score": 0.034032,
        "hf_subset": "ven_Latn-bem_Latn",
        "languages": [
          "ven-Latn",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.041465,
        "recall": 0.057086,
        "f1": 0.044776,
        "accuracy": 0.057086,
        "main_score": 0.044776,
        "hf_subset": "ven_Latn-eng_Latn",
        "languages": [
          "ven-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.002458,
        "recall": 0.005008,
        "f1": 0.002878,
        "accuracy": 0.005008,
        "main_score": 0.002878,
        "hf_subset": "ven_Latn-ewe_Latn",
        "languages": [
          "ven-Latn",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.04179,
        "recall": 0.055083,
        "f1": 0.044823,
        "accuracy": 0.055083,
        "main_score": 0.044823,
        "hf_subset": "ven_Latn-fuc_Latn",
        "languages": [
          "ven-Latn",
          "fuc-Latn"
        ]
      },
      {
        "precision": 0.03374,
        "recall": 0.048072,
        "f1": 0.037317,
        "accuracy": 0.048072,
        "main_score": 0.037317,
        "hf_subset": "ven_Latn-kin_Latn",
        "languages": [
          "ven-Latn",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.018496,
        "recall": 0.024036,
        "f1": 0.019734,
        "accuracy": 0.024036,
        "main_score": 0.019734,
        "hf_subset": "ven_Latn-nde_Latn",
        "languages": [
          "ven-Latn",
          "nde-Latn"
        ]
      },
      {
        "precision": 0.039095,
        "recall": 0.05358,
        "f1": 0.042364,
        "accuracy": 0.05358,
        "main_score": 0.042364,
        "hf_subset": "ven_Latn-nya_Latn",
        "languages": [
          "ven-Latn",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.029294,
        "recall": 0.040561,
        "f1": 0.032085,
        "accuracy": 0.040561,
        "main_score": 0.032085,
        "hf_subset": "ven_Latn-sna_Latn",
        "languages": [
          "ven-Latn",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.006081,
        "recall": 0.014021,
        "f1": 0.006968,
        "accuracy": 0.014021,
        "main_score": 0.006968,
        "hf_subset": "vie_Latn-arb_Arab",
        "languages": [
          "vie-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.001259,
        "recall": 0.004507,
        "f1": 0.001458,
        "accuracy": 0.004507,
        "main_score": 0.001458,
        "hf_subset": "vie_Latn-ben_Beng",
        "languages": [
          "vie-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.043796,
        "recall": 0.065598,
        "f1": 0.048425,
        "accuracy": 0.065598,
        "main_score": 0.048425,
        "hf_subset": "vie_Latn-deu_Latn",
        "languages": [
          "vie-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.005244,
        "recall": 0.016024,
        "f1": 0.006745,
        "accuracy": 0.016024,
        "main_score": 0.006745,
        "hf_subset": "vie_Latn-ell_Grek",
        "languages": [
          "vie-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.044915,
        "recall": 0.065098,
        "f1": 0.049225,
        "accuracy": 0.065098,
        "main_score": 0.049225,
        "hf_subset": "vie_Latn-eng_Latn",
        "languages": [
          "vie-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028982,
        "recall": 0.050075,
        "f1": 0.033015,
        "accuracy": 0.050075,
        "main_score": 0.033015,
        "hf_subset": "vie_Latn-fas_Arab",
        "languages": [
          "vie-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.022299,
        "recall": 0.040561,
        "f1": 0.02624,
        "accuracy": 0.040561,
        "main_score": 0.02624,
        "hf_subset": "vie_Latn-fin_Latn",
        "languages": [
          "vie-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.007614,
        "recall": 0.015023,
        "f1": 0.008663,
        "accuracy": 0.015023,
        "main_score": 0.008663,
        "hf_subset": "vie_Latn-fra_Latn",
        "languages": [
          "vie-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.003937,
        "recall": 0.012018,
        "f1": 0.004956,
        "accuracy": 0.012018,
        "main_score": 0.004956,
        "hf_subset": "vie_Latn-heb_Hebr",
        "languages": [
          "vie-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004811,
        "recall": 0.012519,
        "f1": 0.005721,
        "accuracy": 0.012519,
        "main_score": 0.005721,
        "hf_subset": "vie_Latn-hin_Deva",
        "languages": [
          "vie-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.028794,
        "recall": 0.047571,
        "f1": 0.032484,
        "accuracy": 0.047571,
        "main_score": 0.032484,
        "hf_subset": "vie_Latn-hun_Latn",
        "languages": [
          "vie-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.068182,
        "recall": 0.099149,
        "f1": 0.074763,
        "accuracy": 0.099149,
        "main_score": 0.074763,
        "hf_subset": "vie_Latn-ind_Latn",
        "languages": [
          "vie-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.003301,
        "recall": 0.010015,
        "f1": 0.003844,
        "accuracy": 0.010015,
        "main_score": 0.003844,
        "hf_subset": "vie_Latn-jpn_Jpan",
        "languages": [
          "vie-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.006778,
        "recall": 0.016024,
        "f1": 0.008082,
        "accuracy": 0.016024,
        "main_score": 0.008082,
        "hf_subset": "vie_Latn-kor_Hang",
        "languages": [
          "vie-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.023621,
        "recall": 0.038558,
        "f1": 0.026861,
        "accuracy": 0.038558,
        "main_score": 0.026861,
        "hf_subset": "vie_Latn-lit_Latn",
        "languages": [
          "vie-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.033498,
        "recall": 0.06009,
        "f1": 0.038774,
        "accuracy": 0.06009,
        "main_score": 0.038774,
        "hf_subset": "vie_Latn-nld_Latn",
        "languages": [
          "vie-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.01397,
        "recall": 0.028042,
        "f1": 0.016255,
        "accuracy": 0.028042,
        "main_score": 0.016255,
        "hf_subset": "vie_Latn-pol_Latn",
        "languages": [
          "vie-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.021444,
        "recall": 0.038057,
        "f1": 0.024316,
        "accuracy": 0.038057,
        "main_score": 0.024316,
        "hf_subset": "vie_Latn-por_Latn",
        "languages": [
          "vie-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.010163,
        "recall": 0.021032,
        "f1": 0.011619,
        "accuracy": 0.021032,
        "main_score": 0.011619,
        "hf_subset": "vie_Latn-rus_Cyrl",
        "languages": [
          "vie-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.035999,
        "recall": 0.059089,
        "f1": 0.040783,
        "accuracy": 0.059089,
        "main_score": 0.040783,
        "hf_subset": "vie_Latn-spa_Latn",
        "languages": [
          "vie-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.044455,
        "recall": 0.078117,
        "f1": 0.05205,
        "accuracy": 0.078117,
        "main_score": 0.05205,
        "hf_subset": "vie_Latn-swa_Latn",
        "languages": [
          "vie-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.034385,
        "recall": 0.055583,
        "f1": 0.038755,
        "accuracy": 0.055583,
        "main_score": 0.038755,
        "hf_subset": "vie_Latn-swe_Latn",
        "languages": [
          "vie-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001525,
        "recall": 0.002504,
        "f1": 0.001545,
        "accuracy": 0.002504,
        "main_score": 0.001545,
        "hf_subset": "vie_Latn-tam_Taml",
        "languages": [
          "vie-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027907,
        "recall": 0.04657,
        "f1": 0.031591,
        "accuracy": 0.04657,
        "main_score": 0.031591,
        "hf_subset": "vie_Latn-tur_Latn",
        "languages": [
          "vie-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.005812,
        "recall": 0.015023,
        "f1": 0.007258,
        "accuracy": 0.015023,
        "main_score": 0.007258,
        "hf_subset": "vie_Latn-yue_Hant",
        "languages": [
          "vie-Latn",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.010194,
        "recall": 0.016525,
        "f1": 0.011562,
        "accuracy": 0.016525,
        "main_score": 0.011562,
        "hf_subset": "vie_Latn-zho_Hans",
        "languages": [
          "vie-Latn",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.009722,
        "recall": 0.018528,
        "f1": 0.011315,
        "accuracy": 0.018528,
        "main_score": 0.011315,
        "hf_subset": "vie_Latn-zho_Hant",
        "languages": [
          "vie-Latn",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.019524,
        "recall": 0.039559,
        "f1": 0.022711,
        "accuracy": 0.039559,
        "main_score": 0.022711,
        "hf_subset": "vie_Latn-zul_Latn",
        "languages": [
          "vie-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000501,
        "recall": 0.001002,
        "f1": 0.000502,
        "accuracy": 0.001002,
        "main_score": 0.000502,
        "hf_subset": "wol_Latn-amh_Ethi",
        "languages": [
          "wol-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.051962,
        "recall": 0.07361,
        "f1": 0.056869,
        "accuracy": 0.07361,
        "main_score": 0.056869,
        "hf_subset": "wol_Latn-eng_Latn",
        "languages": [
          "wol-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.031646,
        "recall": 0.044567,
        "f1": 0.034759,
        "accuracy": 0.044567,
        "main_score": 0.034759,
        "hf_subset": "wol_Latn-hau_Latn",
        "languages": [
          "wol-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.034303,
        "recall": 0.04657,
        "f1": 0.037136,
        "accuracy": 0.04657,
        "main_score": 0.037136,
        "hf_subset": "wol_Latn-ibo_Latn",
        "languages": [
          "wol-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.028874,
        "recall": 0.044066,
        "f1": 0.032336,
        "accuracy": 0.044066,
        "main_score": 0.032336,
        "hf_subset": "wol_Latn-nso_Latn",
        "languages": [
          "wol-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.014962,
        "recall": 0.02654,
        "f1": 0.017357,
        "accuracy": 0.02654,
        "main_score": 0.017357,
        "hf_subset": "wol_Latn-orm_Ethi",
        "languages": [
          "wol-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.017955,
        "recall": 0.030546,
        "f1": 0.02027,
        "accuracy": 0.030546,
        "main_score": 0.02027,
        "hf_subset": "wol_Latn-som_Latn",
        "languages": [
          "wol-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.0187,
        "recall": 0.030546,
        "f1": 0.021196,
        "accuracy": 0.030546,
        "main_score": 0.021196,
        "hf_subset": "wol_Latn-ssw_Latn",
        "languages": [
          "wol-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.031692,
        "recall": 0.047571,
        "f1": 0.035157,
        "accuracy": 0.047571,
        "main_score": 0.035157,
        "hf_subset": "wol_Latn-swa_Latn",
        "languages": [
          "wol-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.000918,
        "recall": 0.002003,
        "f1": 0.001086,
        "accuracy": 0.002003,
        "main_score": 0.001086,
        "hf_subset": "wol_Latn-tir_Ethi",
        "languages": [
          "wol-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.034501,
        "recall": 0.048072,
        "f1": 0.037638,
        "accuracy": 0.048072,
        "main_score": 0.037638,
        "hf_subset": "wol_Latn-tsn_Latn",
        "languages": [
          "wol-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.012263,
        "recall": 0.025038,
        "f1": 0.01472,
        "accuracy": 0.025038,
        "main_score": 0.01472,
        "hf_subset": "wol_Latn-xho_Latn",
        "languages": [
          "wol-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.0136,
        "recall": 0.024036,
        "f1": 0.015758,
        "accuracy": 0.024036,
        "main_score": 0.015758,
        "hf_subset": "wol_Latn-yor_Latn",
        "languages": [
          "wol-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.020044,
        "recall": 0.032549,
        "f1": 0.023027,
        "accuracy": 0.032549,
        "main_score": 0.023027,
        "hf_subset": "wol_Latn-zul_Latn",
        "languages": [
          "wol-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000752,
        "recall": 0.001502,
        "f1": 0.000835,
        "accuracy": 0.001502,
        "main_score": 0.000835,
        "hf_subset": "xho_Latn-amh_Ethi",
        "languages": [
          "xho-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.021524,
        "recall": 0.037556,
        "f1": 0.024488,
        "accuracy": 0.037556,
        "main_score": 0.024488,
        "hf_subset": "xho_Latn-eng_Latn",
        "languages": [
          "xho-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014922,
        "recall": 0.02654,
        "f1": 0.017196,
        "accuracy": 0.02654,
        "main_score": 0.017196,
        "hf_subset": "xho_Latn-hau_Latn",
        "languages": [
          "xho-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.019067,
        "recall": 0.030546,
        "f1": 0.021239,
        "accuracy": 0.030546,
        "main_score": 0.021239,
        "hf_subset": "xho_Latn-ibo_Latn",
        "languages": [
          "xho-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.020892,
        "recall": 0.031047,
        "f1": 0.023095,
        "accuracy": 0.031047,
        "main_score": 0.023095,
        "hf_subset": "xho_Latn-nso_Latn",
        "languages": [
          "xho-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.009862,
        "recall": 0.016525,
        "f1": 0.011149,
        "accuracy": 0.016525,
        "main_score": 0.011149,
        "hf_subset": "xho_Latn-orm_Ethi",
        "languages": [
          "xho-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.012575,
        "recall": 0.020531,
        "f1": 0.014117,
        "accuracy": 0.020531,
        "main_score": 0.014117,
        "hf_subset": "xho_Latn-som_Latn",
        "languages": [
          "xho-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.044388,
        "recall": 0.061092,
        "f1": 0.048877,
        "accuracy": 0.061092,
        "main_score": 0.048877,
        "hf_subset": "xho_Latn-ssw_Latn",
        "languages": [
          "xho-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.02382,
        "recall": 0.03355,
        "f1": 0.025945,
        "accuracy": 0.03355,
        "main_score": 0.025945,
        "hf_subset": "xho_Latn-swa_Latn",
        "languages": [
          "xho-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.001294,
        "recall": 0.002504,
        "f1": 0.001453,
        "accuracy": 0.002504,
        "main_score": 0.001453,
        "hf_subset": "xho_Latn-tir_Ethi",
        "languages": [
          "xho-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.024251,
        "recall": 0.036555,
        "f1": 0.026894,
        "accuracy": 0.036555,
        "main_score": 0.026894,
        "hf_subset": "xho_Latn-tsn_Latn",
        "languages": [
          "xho-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.014862,
        "recall": 0.020531,
        "f1": 0.016235,
        "accuracy": 0.020531,
        "main_score": 0.016235,
        "hf_subset": "xho_Latn-wol_Latn",
        "languages": [
          "xho-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.006601,
        "recall": 0.015023,
        "f1": 0.008176,
        "accuracy": 0.015023,
        "main_score": 0.008176,
        "hf_subset": "xho_Latn-yor_Latn",
        "languages": [
          "xho-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.054709,
        "recall": 0.077116,
        "f1": 0.060264,
        "accuracy": 0.077116,
        "main_score": 0.060264,
        "hf_subset": "xho_Latn-zul_Latn",
        "languages": [
          "xho-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000501,
        "f1": 2e-06,
        "accuracy": 0.000501,
        "main_score": 2e-06,
        "hf_subset": "yor_Latn-amh_Ethi",
        "languages": [
          "yor-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.014138,
        "recall": 0.018528,
        "f1": 0.014922,
        "accuracy": 0.018528,
        "main_score": 0.014922,
        "hf_subset": "yor_Latn-eng_Latn",
        "languages": [
          "yor-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011383,
        "recall": 0.016525,
        "f1": 0.012512,
        "accuracy": 0.016525,
        "main_score": 0.012512,
        "hf_subset": "yor_Latn-hau_Latn",
        "languages": [
          "yor-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.01544,
        "recall": 0.018027,
        "f1": 0.016032,
        "accuracy": 0.018027,
        "main_score": 0.016032,
        "hf_subset": "yor_Latn-ibo_Latn",
        "languages": [
          "yor-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.013522,
        "recall": 0.018027,
        "f1": 0.014489,
        "accuracy": 0.018027,
        "main_score": 0.014489,
        "hf_subset": "yor_Latn-nso_Latn",
        "languages": [
          "yor-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.008242,
        "recall": 0.010015,
        "f1": 0.008708,
        "accuracy": 0.010015,
        "main_score": 0.008708,
        "hf_subset": "yor_Latn-orm_Ethi",
        "languages": [
          "yor-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.008676,
        "recall": 0.01302,
        "f1": 0.009507,
        "accuracy": 0.01302,
        "main_score": 0.009507,
        "hf_subset": "yor_Latn-som_Latn",
        "languages": [
          "yor-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.007129,
        "recall": 0.011517,
        "f1": 0.007995,
        "accuracy": 0.011517,
        "main_score": 0.007995,
        "hf_subset": "yor_Latn-ssw_Latn",
        "languages": [
          "yor-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.01111,
        "recall": 0.016024,
        "f1": 0.011863,
        "accuracy": 0.016024,
        "main_score": 0.011863,
        "hf_subset": "yor_Latn-swa_Latn",
        "languages": [
          "yor-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 5e-06,
        "recall": 0.000501,
        "f1": 9e-06,
        "accuracy": 0.000501,
        "main_score": 9e-06,
        "hf_subset": "yor_Latn-tir_Ethi",
        "languages": [
          "yor-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.018225,
        "recall": 0.022534,
        "f1": 0.019145,
        "accuracy": 0.022534,
        "main_score": 0.019145,
        "hf_subset": "yor_Latn-tsn_Latn",
        "languages": [
          "yor-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.009987,
        "recall": 0.012519,
        "f1": 0.010576,
        "accuracy": 0.012519,
        "main_score": 0.010576,
        "hf_subset": "yor_Latn-wol_Latn",
        "languages": [
          "yor-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.003616,
        "recall": 0.00651,
        "f1": 0.003933,
        "accuracy": 0.00651,
        "main_score": 0.003933,
        "hf_subset": "yor_Latn-xho_Latn",
        "languages": [
          "yor-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.009004,
        "recall": 0.012018,
        "f1": 0.009642,
        "accuracy": 0.012018,
        "main_score": 0.009642,
        "hf_subset": "yor_Latn-zul_Latn",
        "languages": [
          "yor-Latn",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.011743,
        "recall": 0.018528,
        "f1": 0.013039,
        "accuracy": 0.018528,
        "main_score": 0.013039,
        "hf_subset": "yue_Hant-eng_Latn",
        "languages": [
          "yue-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.014884,
        "recall": 0.027541,
        "f1": 0.017234,
        "accuracy": 0.027541,
        "main_score": 0.017234,
        "hf_subset": "yue_Hant-jpn_Jpan",
        "languages": [
          "yue-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.004757,
        "recall": 0.010516,
        "f1": 0.005643,
        "accuracy": 0.010516,
        "main_score": 0.005643,
        "hf_subset": "yue_Hant-kor_Hang",
        "languages": [
          "yue-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.012343,
        "recall": 0.02003,
        "f1": 0.013787,
        "accuracy": 0.02003,
        "main_score": 0.013787,
        "hf_subset": "yue_Hant-vie_Latn",
        "languages": [
          "yue-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.075271,
        "recall": 0.117677,
        "f1": 0.085663,
        "accuracy": 0.117677,
        "main_score": 0.085663,
        "hf_subset": "yue_Hant-zho_Hans",
        "languages": [
          "yue-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.097678,
        "recall": 0.134702,
        "f1": 0.106458,
        "accuracy": 0.134702,
        "main_score": 0.106458,
        "hf_subset": "yue_Hant-zho_Hant",
        "languages": [
          "yue-Hant",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.013566,
        "recall": 0.022033,
        "f1": 0.015396,
        "accuracy": 0.022033,
        "main_score": 0.015396,
        "hf_subset": "zho_Hans-eng_Latn",
        "languages": [
          "zho-Hans",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.008765,
        "recall": 0.017526,
        "f1": 0.010209,
        "accuracy": 0.017526,
        "main_score": 0.010209,
        "hf_subset": "zho_Hans-jpn_Jpan",
        "languages": [
          "zho-Hans",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.006847,
        "recall": 0.012519,
        "f1": 0.007577,
        "accuracy": 0.012519,
        "main_score": 0.007577,
        "hf_subset": "zho_Hans-kor_Hang",
        "languages": [
          "zho-Hans",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.014009,
        "recall": 0.024537,
        "f1": 0.016303,
        "accuracy": 0.024537,
        "main_score": 0.016303,
        "hf_subset": "zho_Hans-vie_Latn",
        "languages": [
          "zho-Hans",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.066635,
        "recall": 0.102654,
        "f1": 0.075158,
        "accuracy": 0.102654,
        "main_score": 0.075158,
        "hf_subset": "zho_Hans-yue_Hant",
        "languages": [
          "zho-Hans",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.054756,
        "recall": 0.089634,
        "f1": 0.062592,
        "accuracy": 0.089634,
        "main_score": 0.062592,
        "hf_subset": "zho_Hans-zho_Hant",
        "languages": [
          "zho-Hans",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.009341,
        "recall": 0.018528,
        "f1": 0.011185,
        "accuracy": 0.018528,
        "main_score": 0.011185,
        "hf_subset": "zho_Hant-arb_Arab",
        "languages": [
          "zho-Hant",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.00214,
        "recall": 0.005508,
        "f1": 0.002588,
        "accuracy": 0.005508,
        "main_score": 0.002588,
        "hf_subset": "zho_Hant-ben_Beng",
        "languages": [
          "zho-Hant",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.022711,
        "recall": 0.037556,
        "f1": 0.025854,
        "accuracy": 0.037556,
        "main_score": 0.025854,
        "hf_subset": "zho_Hant-deu_Latn",
        "languages": [
          "zho-Hant",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.008956,
        "recall": 0.016525,
        "f1": 0.01023,
        "accuracy": 0.016525,
        "main_score": 0.01023,
        "hf_subset": "zho_Hant-ell_Grek",
        "languages": [
          "zho-Hant",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.034237,
        "recall": 0.052078,
        "f1": 0.038432,
        "accuracy": 0.052078,
        "main_score": 0.038432,
        "hf_subset": "zho_Hant-eng_Latn",
        "languages": [
          "zho-Hant",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.011027,
        "recall": 0.022033,
        "f1": 0.013085,
        "accuracy": 0.022033,
        "main_score": 0.013085,
        "hf_subset": "zho_Hant-fas_Arab",
        "languages": [
          "zho-Hant",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.017311,
        "recall": 0.029044,
        "f1": 0.019548,
        "accuracy": 0.029044,
        "main_score": 0.019548,
        "hf_subset": "zho_Hant-fin_Latn",
        "languages": [
          "zho-Hant",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.011335,
        "recall": 0.021032,
        "f1": 0.013092,
        "accuracy": 0.021032,
        "main_score": 0.013092,
        "hf_subset": "zho_Hant-fra_Latn",
        "languages": [
          "zho-Hant",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.006995,
        "recall": 0.014522,
        "f1": 0.008362,
        "accuracy": 0.014522,
        "main_score": 0.008362,
        "hf_subset": "zho_Hant-heb_Hebr",
        "languages": [
          "zho-Hant",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.009428,
        "recall": 0.015023,
        "f1": 0.01052,
        "accuracy": 0.015023,
        "main_score": 0.01052,
        "hf_subset": "zho_Hant-hin_Deva",
        "languages": [
          "zho-Hant",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.020108,
        "recall": 0.030045,
        "f1": 0.022192,
        "accuracy": 0.030045,
        "main_score": 0.022192,
        "hf_subset": "zho_Hant-hun_Latn",
        "languages": [
          "zho-Hant",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.027764,
        "recall": 0.040561,
        "f1": 0.030934,
        "accuracy": 0.040561,
        "main_score": 0.030934,
        "hf_subset": "zho_Hant-ind_Latn",
        "languages": [
          "zho-Hant",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.017854,
        "recall": 0.036054,
        "f1": 0.021324,
        "accuracy": 0.036054,
        "main_score": 0.021324,
        "hf_subset": "zho_Hant-jpn_Jpan",
        "languages": [
          "zho-Hant",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.007653,
        "recall": 0.016024,
        "f1": 0.009154,
        "accuracy": 0.016024,
        "main_score": 0.009154,
        "hf_subset": "zho_Hant-kor_Hang",
        "languages": [
          "zho-Hant",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.016586,
        "recall": 0.027541,
        "f1": 0.018829,
        "accuracy": 0.027541,
        "main_score": 0.018829,
        "hf_subset": "zho_Hant-lit_Latn",
        "languages": [
          "zho-Hant",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.02139,
        "recall": 0.029544,
        "f1": 0.023253,
        "accuracy": 0.029544,
        "main_score": 0.023253,
        "hf_subset": "zho_Hant-nld_Latn",
        "languages": [
          "zho-Hant",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.012575,
        "recall": 0.019529,
        "f1": 0.014132,
        "accuracy": 0.019529,
        "main_score": 0.014132,
        "hf_subset": "zho_Hant-pol_Latn",
        "languages": [
          "zho-Hant",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.022684,
        "recall": 0.035053,
        "f1": 0.025697,
        "accuracy": 0.035053,
        "main_score": 0.025697,
        "hf_subset": "zho_Hant-por_Latn",
        "languages": [
          "zho-Hant",
          "por-Latn"
        ]
      },
      {
        "precision": 0.009603,
        "recall": 0.017526,
        "f1": 0.011063,
        "accuracy": 0.017526,
        "main_score": 0.011063,
        "hf_subset": "zho_Hant-rus_Cyrl",
        "languages": [
          "zho-Hant",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.02111,
        "recall": 0.030045,
        "f1": 0.023144,
        "accuracy": 0.030045,
        "main_score": 0.023144,
        "hf_subset": "zho_Hant-spa_Latn",
        "languages": [
          "zho-Hant",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.021684,
        "recall": 0.034552,
        "f1": 0.024415,
        "accuracy": 0.034552,
        "main_score": 0.024415,
        "hf_subset": "zho_Hant-swa_Latn",
        "languages": [
          "zho-Hant",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.026402,
        "recall": 0.04006,
        "f1": 0.029248,
        "accuracy": 0.04006,
        "main_score": 0.029248,
        "hf_subset": "zho_Hant-swe_Latn",
        "languages": [
          "zho-Hant",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.005874,
        "recall": 0.008513,
        "f1": 0.006313,
        "accuracy": 0.008513,
        "main_score": 0.006313,
        "hf_subset": "zho_Hant-tam_Taml",
        "languages": [
          "zho-Hant",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.027978,
        "recall": 0.042063,
        "f1": 0.03106,
        "accuracy": 0.042063,
        "main_score": 0.03106,
        "hf_subset": "zho_Hant-tur_Latn",
        "languages": [
          "zho-Hant",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.02478,
        "recall": 0.036555,
        "f1": 0.027302,
        "accuracy": 0.036555,
        "main_score": 0.027302,
        "hf_subset": "zho_Hant-vie_Latn",
        "languages": [
          "zho-Hant",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.106527,
        "recall": 0.150225,
        "f1": 0.117462,
        "accuracy": 0.150225,
        "main_score": 0.117462,
        "hf_subset": "zho_Hant-yue_Hant",
        "languages": [
          "zho-Hant",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.062128,
        "recall": 0.097146,
        "f1": 0.069898,
        "accuracy": 0.097146,
        "main_score": 0.069898,
        "hf_subset": "zho_Hant-zho_Hans",
        "languages": [
          "zho-Hant",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.012906,
        "recall": 0.022534,
        "f1": 0.014772,
        "accuracy": 0.022534,
        "main_score": 0.014772,
        "hf_subset": "zho_Hant-zul_Latn",
        "languages": [
          "zho-Hant",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.000919,
        "recall": 0.002003,
        "f1": 0.001086,
        "accuracy": 0.002003,
        "main_score": 0.001086,
        "hf_subset": "zul_Latn-amh_Ethi",
        "languages": [
          "zul-Latn",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.002045,
        "recall": 0.004507,
        "f1": 0.00268,
        "accuracy": 0.004507,
        "main_score": 0.00268,
        "hf_subset": "zul_Latn-arb_Arab",
        "languages": [
          "zul-Latn",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.000967,
        "recall": 0.003505,
        "f1": 0.001369,
        "accuracy": 0.003505,
        "main_score": 0.001369,
        "hf_subset": "zul_Latn-ben_Beng",
        "languages": [
          "zul-Latn",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.016636,
        "recall": 0.029044,
        "f1": 0.018914,
        "accuracy": 0.029044,
        "main_score": 0.018914,
        "hf_subset": "zul_Latn-deu_Latn",
        "languages": [
          "zul-Latn",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.004863,
        "recall": 0.011517,
        "f1": 0.006189,
        "accuracy": 0.011517,
        "main_score": 0.006189,
        "hf_subset": "zul_Latn-ell_Grek",
        "languages": [
          "zul-Latn",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.03251,
        "recall": 0.051077,
        "f1": 0.036016,
        "accuracy": 0.051077,
        "main_score": 0.036016,
        "hf_subset": "zul_Latn-eng_Latn",
        "languages": [
          "zul-Latn",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.012926,
        "recall": 0.022534,
        "f1": 0.014502,
        "accuracy": 0.022534,
        "main_score": 0.014502,
        "hf_subset": "zul_Latn-fas_Arab",
        "languages": [
          "zul-Latn",
          "fas-Arab"
        ]
      },
      {
        "precision": 0.014791,
        "recall": 0.026039,
        "f1": 0.017006,
        "accuracy": 0.026039,
        "main_score": 0.017006,
        "hf_subset": "zul_Latn-fin_Latn",
        "languages": [
          "zul-Latn",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.007348,
        "recall": 0.010516,
        "f1": 0.008105,
        "accuracy": 0.010516,
        "main_score": 0.008105,
        "hf_subset": "zul_Latn-fra_Latn",
        "languages": [
          "zul-Latn",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.017437,
        "recall": 0.031547,
        "f1": 0.02006,
        "accuracy": 0.031547,
        "main_score": 0.02006,
        "hf_subset": "zul_Latn-hau_Latn",
        "languages": [
          "zul-Latn",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.002695,
        "recall": 0.00651,
        "f1": 0.003434,
        "accuracy": 0.00651,
        "main_score": 0.003434,
        "hf_subset": "zul_Latn-heb_Hebr",
        "languages": [
          "zul-Latn",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.003004,
        "recall": 0.009514,
        "f1": 0.003619,
        "accuracy": 0.009514,
        "main_score": 0.003619,
        "hf_subset": "zul_Latn-hin_Deva",
        "languages": [
          "zul-Latn",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.012707,
        "recall": 0.021032,
        "f1": 0.014274,
        "accuracy": 0.021032,
        "main_score": 0.014274,
        "hf_subset": "zul_Latn-hun_Latn",
        "languages": [
          "zul-Latn",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.02385,
        "recall": 0.035553,
        "f1": 0.026278,
        "accuracy": 0.035553,
        "main_score": 0.026278,
        "hf_subset": "zul_Latn-ibo_Latn",
        "languages": [
          "zul-Latn",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.030843,
        "recall": 0.044066,
        "f1": 0.033695,
        "accuracy": 0.044066,
        "main_score": 0.033695,
        "hf_subset": "zul_Latn-ind_Latn",
        "languages": [
          "zul-Latn",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.002017,
        "recall": 0.005008,
        "f1": 0.002358,
        "accuracy": 0.005008,
        "main_score": 0.002358,
        "hf_subset": "zul_Latn-jpn_Jpan",
        "languages": [
          "zul-Latn",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.005294,
        "recall": 0.011017,
        "f1": 0.006033,
        "accuracy": 0.011017,
        "main_score": 0.006033,
        "hf_subset": "zul_Latn-kor_Hang",
        "languages": [
          "zul-Latn",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.015153,
        "recall": 0.025038,
        "f1": 0.017373,
        "accuracy": 0.025038,
        "main_score": 0.017373,
        "hf_subset": "zul_Latn-lit_Latn",
        "languages": [
          "zul-Latn",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.015622,
        "recall": 0.024537,
        "f1": 0.017477,
        "accuracy": 0.024537,
        "main_score": 0.017477,
        "hf_subset": "zul_Latn-nld_Latn",
        "languages": [
          "zul-Latn",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.021183,
        "recall": 0.034051,
        "f1": 0.024078,
        "accuracy": 0.034051,
        "main_score": 0.024078,
        "hf_subset": "zul_Latn-nso_Latn",
        "languages": [
          "zul-Latn",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.011457,
        "recall": 0.018027,
        "f1": 0.012913,
        "accuracy": 0.018027,
        "main_score": 0.012913,
        "hf_subset": "zul_Latn-orm_Ethi",
        "languages": [
          "zul-Latn",
          "orm-Ethi"
        ]
      },
      {
        "precision": 0.00815,
        "recall": 0.017526,
        "f1": 0.009791,
        "accuracy": 0.017526,
        "main_score": 0.009791,
        "hf_subset": "zul_Latn-pol_Latn",
        "languages": [
          "zul-Latn",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.013116,
        "recall": 0.020531,
        "f1": 0.014622,
        "accuracy": 0.020531,
        "main_score": 0.014622,
        "hf_subset": "zul_Latn-por_Latn",
        "languages": [
          "zul-Latn",
          "por-Latn"
        ]
      },
      {
        "precision": 0.004277,
        "recall": 0.010516,
        "f1": 0.005369,
        "accuracy": 0.010516,
        "main_score": 0.005369,
        "hf_subset": "zul_Latn-rus_Cyrl",
        "languages": [
          "zul-Latn",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.01297,
        "recall": 0.023535,
        "f1": 0.01488,
        "accuracy": 0.023535,
        "main_score": 0.01488,
        "hf_subset": "zul_Latn-som_Latn",
        "languages": [
          "zul-Latn",
          "som-Latn"
        ]
      },
      {
        "precision": 0.018113,
        "recall": 0.031047,
        "f1": 0.020442,
        "accuracy": 0.031047,
        "main_score": 0.020442,
        "hf_subset": "zul_Latn-spa_Latn",
        "languages": [
          "zul-Latn",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.048801,
        "recall": 0.074111,
        "f1": 0.054595,
        "accuracy": 0.074111,
        "main_score": 0.054595,
        "hf_subset": "zul_Latn-ssw_Latn",
        "languages": [
          "zul-Latn",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.030007,
        "recall": 0.042063,
        "f1": 0.032668,
        "accuracy": 0.042063,
        "main_score": 0.032668,
        "hf_subset": "zul_Latn-swa_Latn",
        "languages": [
          "zul-Latn",
          "swa-Latn"
        ]
      },
      {
        "precision": 0.017094,
        "recall": 0.025038,
        "f1": 0.018584,
        "accuracy": 0.025038,
        "main_score": 0.018584,
        "hf_subset": "zul_Latn-swe_Latn",
        "languages": [
          "zul-Latn",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001553,
        "recall": 0.002504,
        "f1": 0.001596,
        "accuracy": 0.002504,
        "main_score": 0.001596,
        "hf_subset": "zul_Latn-tam_Taml",
        "languages": [
          "zul-Latn",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.000251,
        "recall": 0.001002,
        "f1": 0.000335,
        "accuracy": 0.001002,
        "main_score": 0.000335,
        "hf_subset": "zul_Latn-tir_Ethi",
        "languages": [
          "zul-Latn",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.026254,
        "recall": 0.042063,
        "f1": 0.029591,
        "accuracy": 0.042063,
        "main_score": 0.029591,
        "hf_subset": "zul_Latn-tsn_Latn",
        "languages": [
          "zul-Latn",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.016352,
        "recall": 0.025538,
        "f1": 0.01811,
        "accuracy": 0.025538,
        "main_score": 0.01811,
        "hf_subset": "zul_Latn-tur_Latn",
        "languages": [
          "zul-Latn",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.025306,
        "recall": 0.037556,
        "f1": 0.027801,
        "accuracy": 0.037556,
        "main_score": 0.027801,
        "hf_subset": "zul_Latn-vie_Latn",
        "languages": [
          "zul-Latn",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.012787,
        "recall": 0.021532,
        "f1": 0.014508,
        "accuracy": 0.021532,
        "main_score": 0.014508,
        "hf_subset": "zul_Latn-wol_Latn",
        "languages": [
          "zul-Latn",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.052591,
        "recall": 0.081122,
        "f1": 0.059809,
        "accuracy": 0.081122,
        "main_score": 0.059809,
        "hf_subset": "zul_Latn-xho_Latn",
        "languages": [
          "zul-Latn",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.006878,
        "recall": 0.016525,
        "f1": 0.008822,
        "accuracy": 0.016525,
        "main_score": 0.008822,
        "hf_subset": "zul_Latn-yor_Latn",
        "languages": [
          "zul-Latn",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.006044,
        "recall": 0.01352,
        "f1": 0.007433,
        "accuracy": 0.01352,
        "main_score": 0.007433,
        "hf_subset": "zul_Latn-zho_Hant",
        "languages": [
          "zul-Latn",
          "zho-Hant"
        ]
      }
    ]
  },
  "evaluation_time": 54.62569308280945,
  "kg_co2_emissions": null
}